{"db":[{"meta":{"exported_on":1509559741641,"version":"009"},"data":{"posts":[{"id":2,"uuid":"3954d38e-553b-4c9d-8c5a-57072b41c7fa","title":"About Me","slug":"about","markdown":"Hello! I'm Owen, I've been studying Software Engineering in the the beautiful town of Aberystwyth for the last few years, now I'm working in Switzerland! I mainly code in NodeJS, Python and C, although I am open to trying out new things like Haskell, Rust and Go. \n\n![me](https://i.imgur.com/cGC2UoI.jpg?1)\n\n\nLast year I worked at [Clock Ltd](https://clock.co.uk), and learned a whole lot of new tech that I had never even considered before; as well as making some amazing friends.\n\nI'm also really passionate about Swing Dance, in all it's forms. So I've spent the last few summers at [Herrang Dance Camp](http://herrang.com), having the time of my life. If you want to talk Trad Jazz, let me know! \n\nOne thing I am really proud of is my Linux and Vim setups, I've actually done a few talks on Vim at BCS meetings and you can find my vimrc [here](https://github.com/bag-man/dotfiles/blob/master/vimrc). If you have any questions or comments let me know I love a chance to nerd out on it.\n\nHere are some of my side projects:\n\n  *  [*It's back*](http://alpha.itsback.at)  **-** Written in NodeJS, this is a website that alerts users in real time when a site comes back up after being offline. \n  *  [*Daily Mail Bot*](http://reddit.com/u/DailMail_Bot) **-**  Protest bot written in Python, that mirrors Daily Mail & Sun articles posted to reddit. \n  *  [*Process Game*](https://github.com/bag-man/process-game) **-** A small C game I made as a learning exercise. Find a way to kill the game without it knowing. \n  *  [*OandXs*](https://github.com/bag-man/oandxs) **-** Noughts and crosses in a recursive manner, so that the game can be played multiple layers deep.\n  * [*Gists*](https://gist.github.com/bag-man) - A few nice snippets of code that I was particularly proud of.\n\nIf you like what I do, and want to send me a beer you can donate crypto to me at these addresses:\n\nBTC | 15FYeMgQsETViUcc8JtSmoHmCAmADy2Ymn\nLTC | LVdVyd3R1S719ZRApaAY1RgLJ5vYgEGGxW\nARK | ANKmYTHV7QdkcLz2R65uMzEvcRRdz2iRQm \n\n:wq","mobiledoc":null,"html":"<p>Hello! I'm Owen, I've been studying Software Engineering in the the beautiful town of Aberystwyth for the last few years, now I'm working in Switzerland! I mainly code in NodeJS, Python and C, although I am open to trying out new things like Haskell, Rust and Go. </p>\n\n<p><img src=\"https://i.imgur.com/cGC2UoI.jpg?1\" alt=\"me\" /></p>\n\n<p>Last year I worked at <a href=\"https://clock.co.uk\">Clock Ltd</a>, and learned a whole lot of new tech that I had never even considered before; as well as making some amazing friends.</p>\n\n<p>I'm also really passionate about Swing Dance, in all it's forms. So I've spent the last few summers at <a href=\"http://herrang.com\">Herrang Dance Camp</a>, having the time of my life. If you want to talk Trad Jazz, let me know! </p>\n\n<p>One thing I am really proud of is my Linux and Vim setups, I've actually done a few talks on Vim at BCS meetings and you can find my vimrc <a href=\"https://github.com/bag-man/dotfiles/blob/master/vimrc\">here</a>. If you have any questions or comments let me know I love a chance to nerd out on it.</p>\n\n<p>Here are some of my side projects:</p>\n\n<ul>\n<li><a href=\"http://alpha.itsback.at\"><em>It's back</em></a>  <strong>-</strong> Written in NodeJS, this is a website that alerts users in real time when a site comes back up after being offline. </li>\n<li><a href=\"http://reddit.com/u/DailMail_Bot\"><em>Daily Mail Bot</em></a> <strong>-</strong>  Protest bot written in Python, that mirrors Daily Mail &amp; Sun articles posted to reddit. </li>\n<li><a href=\"https://github.com/bag-man/process-game\"><em>Process Game</em></a> <strong>-</strong> A small C game I made as a learning exercise. Find a way to kill the game without it knowing. </li>\n<li><a href=\"https://github.com/bag-man/oandxs\"><em>OandXs</em></a> <strong>-</strong> Noughts and crosses in a recursive manner, so that the game can be played multiple layers deep.</li>\n<li><a href=\"https://gist.github.com/bag-man\"><em>Gists</em></a> - A few nice snippets of code that I was particularly proud of.</li>\n</ul>\n\n<p>If you like what I do, and want to send me a beer you can donate crypto to me at these addresses:</p>\n\n<p>BTC | 15FYeMgQsETViUcc8JtSmoHmCAmADy2Ymn <br />\nLTC | LVdVyd3R1S719ZRApaAY1RgLJ5vYgEGGxW <br />\nARK | ANKmYTHV7QdkcLz2R65uMzEvcRRdz2iRQm </p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-12 15:14:11","created_by":1,"updated_at":"2017-11-01 18:08:08","updated_by":1,"published_at":"2017-02-12 15:21:46","published_by":1},{"id":3,"uuid":"0ab125b8-f557-4296-9fe5-ecd9d8e59246","title":"FZF & RipGrep - Navigate with bash faster than ever before","slug":"fzf-ripgrep-navigate-with-bash-faster-than-ever-before","markdown":"I've always had [fzf](https://github.com/junegunn/fzf) and [ripgrep](https://github.com/BurntSushi/ripgrep) on my radar, and I've finally gotten around to using them together. Good lord it makes a world of difference, especially when added to Vim as well as Bash. \n\nAdd the following snippet to your ~/.bashrc, this add's fzf keybindings to bash and gets fzf to use ripgrep by default for faster searching.\n\n    [ -f ~/.fzf.bash ] && source ~/.fzf.bash\n    export FZF_DEFAULT_COMMAND='rg --files --no-ignore --hidden --follow -g \"!{.git,node_modules}/*\" 2> /dev/null'\n    export FZF_CTRL_T_COMMAND=\"$FZF_DEFAULT_COMMAND\"\n    bind -x '\"\\C-p\": vim $(fzf);'\n\nOkay now what can you do? \n\n* **Ctrl + r** - search through bash history with fzf\n* **Ctrl + p** - edit a file in vim from fzf\n* **mv dir/**** - expand a directory with (\\*\\*) and select from fzf\n* **Alt + c** - change directory from fzf - see the update at the bottom for faster search with `bfs`.\n* **Ctrl + t** - insert file from fzf into command\n\nNeat right! Now if you are a vim user there is more, add the fzf plugin to your ~/.vimrc, along with this snippet. Obviously  customise the bindings, and excludes / includes to your workflows!\n\n    let g:rg_command = '\n      \\ rg --column --line-number --no-heading --fixed-strings --ignore-case --no-ignore --hidden --follow --color \"always\"\n      \\ -g \"*.{js,json,php,md,styl,jade,html,config,py,cpp,c,go,hs,rb,conf}\"\n      \\ -g \"!{.git,node_modules,vendor}/*\" '\n\n    command! -bang -nargs=* F call fzf#vim#grep(g:rg_command .shellescape(<q-args>), 1, <bang>0)\n\n\nYou now have a killer free text search with `:F` that uses ripgrep and is faster than any I've seen before.\n\nI've done more with this, but want to leave it there for now. There are even more goodies in my [.vimrc](https://github.com/bag-man/dotfiles/blob/master/vimrc), and in my [.bashrc](https://github.com/bag-man/dotfiles/blob/master/bashrc), including auto installing fzf and ripgrep (admittedly hackily) from the .vimrc and a nice snippet that uses fzf for git logs. \n\n## Update\nJust made this nice snippet for tmux:\n\n    tm() {\n      [[ -n \"$TMUX\" ]] && change=\"switch-client\" || change=\"attach-session\"\n      if [ $1 ]; then \n         tmux $change -t \"$1\" 2>/dev/null || (tmux new-session -d -s $1 && tmux $change -t \"$1\"); return\n      fi\n      session=$(tmux list-sessions -F \"#{session_name}\" 2>/dev/null | fzf --exit-0) &&  tmux $change -t \"$session\" || echo \"No sessions found.\"\n    }\n\n* `tm irc` it will attach to the irc session (if it exists), else it will create it.\n* `tm` will open fzf and let you select the session\n\nWhat is awesome is this lets you switch and create sessions from inside of other sessions.\n\nAnd here is a nice snippet for looking through git logs:\n\n```\nfzf_log() {\n  hash=$(git log --color=always --format=\"%C(auto)%h%d %s %C(black)%C(bold)%cr\" \"$@\" |  fzf | awk '{print $1}')\n  echo $hash | xclip\n  git showtool $hash\n}\n```\n\nIt will let you select a commit, and display the diff off it, and put the commit hash on your clipboard using xclip. I also have it set to use icdiff via `git showtool`.\n\n## Update update...\nA few people have pointed out that doing this doesn't work for fzf's Ctrl+T completion or the Alt+C completion. Thanks to [@mikepqr](https://twitter.com/mikepqr), for letting me know the work around for Ctrl+T. I have updated the configurations at the top of the post with what he sent me. \n\nAlt+C has proved a bit tricky to get working with ripgrep, as rg doesn't natively support searching just for directories. Instead I have been using [bfs](https://github.com/tavianator/bfs) by adding the following to me config. \n\n```\nexport FZF_ALT_C_COMMAND=\"cd ~/; bfs -type d -nohidden | sed s/^\\./\\~/\"\n```\n\nAfter a bit of quick testing it appears to run faster and give slightly nicer results that the [ripgrep solutions](https://github.com/BurntSushi/ripgrep/issues/388) I've tried, although it does mean installing another tool!\n\n:wq","mobiledoc":null,"html":"<p>I've always had <a href=\"https://github.com/junegunn/fzf\">fzf</a> and <a href=\"https://github.com/BurntSushi/ripgrep\">ripgrep</a> on my radar, and I've finally gotten around to using them together. Good lord it makes a world of difference, especially when added to Vim as well as Bash. </p>\n\n<p>Add the following snippet to your ~/.bashrc, this add's fzf keybindings to bash and gets fzf to use ripgrep by default for faster searching.</p>\n\n<pre><code>[ -f ~/.fzf.bash ] &amp;&amp; source ~/.fzf.bash\nexport FZF_DEFAULT_COMMAND='rg --files --no-ignore --hidden --follow -g \"!{.git,node_modules}/*\" 2&gt; /dev/null'\nexport FZF_CTRL_T_COMMAND=\"$FZF_DEFAULT_COMMAND\"\nbind -x '\"\\C-p\": vim $(fzf);'\n</code></pre>\n\n<p>Okay now what can you do? </p>\n\n<ul>\n<li><strong>Ctrl + r</strong> - search through bash history with fzf</li>\n<li><strong>Ctrl + p</strong> - edit a file in vim from fzf</li>\n<li><strong>mv dir/**</strong> - expand a directory with (**) and select from fzf</li>\n<li><strong>Alt + c</strong> - change directory from fzf - see the update at the bottom for faster search with <code>bfs</code>.</li>\n<li><strong>Ctrl + t</strong> - insert file from fzf into command</li>\n</ul>\n\n<p>Neat right! Now if you are a vim user there is more, add the fzf plugin to your ~/.vimrc, along with this snippet. Obviously  customise the bindings, and excludes / includes to your workflows!</p>\n\n<pre><code>let g:rg_command = '\n  \\ rg --column --line-number --no-heading --fixed-strings --ignore-case --no-ignore --hidden --follow --color \"always\"\n  \\ -g \"*.{js,json,php,md,styl,jade,html,config,py,cpp,c,go,hs,rb,conf}\"\n  \\ -g \"!{.git,node_modules,vendor}/*\" '\n\ncommand! -bang -nargs=* F call fzf#vim#grep(g:rg_command .shellescape(&lt;q-args&gt;), 1, &lt;bang&gt;0)\n</code></pre>\n\n<p>You now have a killer free text search with <code>:F</code> that uses ripgrep and is faster than any I've seen before.</p>\n\n<p>I've done more with this, but want to leave it there for now. There are even more goodies in my <a href=\"https://github.com/bag-man/dotfiles/blob/master/vimrc\">.vimrc</a>, and in my <a href=\"https://github.com/bag-man/dotfiles/blob/master/bashrc\">.bashrc</a>, including auto installing fzf and ripgrep (admittedly hackily) from the .vimrc and a nice snippet that uses fzf for git logs. </p>\n\n<h2 id=\"update\">Update</h2>\n\n<p>Just made this nice snippet for tmux:</p>\n\n<pre><code>tm() {\n  [[ -n \"$TMUX\" ]] &amp;&amp; change=\"switch-client\" || change=\"attach-session\"\n  if [ $1 ]; then \n     tmux $change -t \"$1\" 2&gt;/dev/null || (tmux new-session -d -s $1 &amp;&amp; tmux $change -t \"$1\"); return\n  fi\n  session=$(tmux list-sessions -F \"#{session_name}\" 2&gt;/dev/null | fzf --exit-0) &amp;&amp;  tmux $change -t \"$session\" || echo \"No sessions found.\"\n}\n</code></pre>\n\n<ul>\n<li><code>tm irc</code> it will attach to the irc session (if it exists), else it will create it.</li>\n<li><code>tm</code> will open fzf and let you select the session</li>\n</ul>\n\n<p>What is awesome is this lets you switch and create sessions from inside of other sessions.</p>\n\n<p>And here is a nice snippet for looking through git logs:</p>\n\n<pre><code>fzf_log() {  \n  hash=$(git log --color=always --format=\"%C(auto)%h%d %s %C(black)%C(bold)%cr\" \"$@\" |  fzf | awk '{print $1}')\n  echo $hash | xclip\n  git showtool $hash\n}\n</code></pre>\n\n<p>It will let you select a commit, and display the diff off it, and put the commit hash on your clipboard using xclip. I also have it set to use icdiff via <code>git showtool</code>.</p>\n\n<h2 id=\"updateupdate\">Update update...</h2>\n\n<p>A few people have pointed out that doing this doesn't work for fzf's Ctrl+T completion or the Alt+C completion. Thanks to <a href=\"https://twitter.com/mikepqr\">@mikepqr</a>, for letting me know the work around for Ctrl+T. I have updated the configurations at the top of the post with what he sent me. </p>\n\n<p>Alt+C has proved a bit tricky to get working with ripgrep, as rg doesn't natively support searching just for directories. Instead I have been using <a href=\"https://github.com/tavianator/bfs\">bfs</a> by adding the following to me config. </p>\n\n<pre><code>export FZF_ALT_C_COMMAND=\"cd ~/; bfs -type d -nohidden | sed s/^\\./~/\"  \n</code></pre>\n\n<p>After a bit of quick testing it appears to run faster and give slightly nicer results that the <a href=\"https://github.com/BurntSushi/ripgrep/issues/388\">ripgrep solutions</a> I've tried, although it does mean installing another tool!</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":1,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-12 15:23:48","created_by":1,"updated_at":"2017-10-20 13:30:12","updated_by":1,"published_at":"2017-02-12 15:23:54","published_by":1},{"id":4,"uuid":"2c321f40-c2c5-4fd9-a8ca-0daa624b8990","title":"MongoDB Performance on ZFS and Linux","slug":"mongodb-performance-on-zfs-and-linux","markdown":"*This was written during my time at Clock.*\n\nHere at Clock we love ZFS, and have been running it in production on our Linux file servers for several years. It provides us with [numerous excellent features](https://wiki.ubuntu.com/ZFS), such as snapshotting, incremental send/receive, and transparent compression. With the recent release of [Ubuntu Xenial 16.04](https://wiki.ubuntu.com/XenialXerus/ReleaseNotes) official support for [ZFS is now here](https://insights.ubuntu.com/2016/02/16/zfs-is-the-fs-for-containers-in-ubuntu-16-04/), and we are keen to integrate it fully into our next generation hosting stack.\n\nAs a Node.js and MongoDB house, one of our main concerns has been how MongoDB will perform on ZFS on Linux, especially after reading about [potential problems](http://serverfault.com/questions/583688/mongodb-and-zfs-bad-performance-disk-always-busy-with-reads-while-doing-only-wr) other people have faced. There really isn't much data out there to put our minds at rest.\n\nWe decided to setup a method of benchmarking MongoDB with the supported EXT4 and XFS, then compare against ZFS with different options enabled. The idea being that we can hopefully figure out how ZFS compares, and if there are any options we can set that will impact the performance in any noticeable way. \n\nThere are a few caveats to our testing, so we are aware that these results need to be taken with a pinch of salt. They are aimed at just providing an indicator as to the performance between the file systems, not being a definitive guide to which is best to use.\n\n## Setup\n\nThe main variable that may affect the results was the hardware that we chose to use. We spun up a 4GB Linode instance with four cores, and four virtual disks: one for the latest Ubuntu 15.10 image (which we then upgraded to 16.04), and one disk for each of the file systems that we intended to test, EXT4, XFS and ZFS.\n\nThe issue with this approach is that the system is running on a virtualised machine with shared hardware, so there may be variations in the performance available to the machine. In an ideal world we would run this on a physical machine with identical disks, but that wasn't feasible for this investigation.\n\nWe decided to use the latest stable version of MongoDB 3.2.5, ZFS was at version 0.6.5.6 provided by the zfsutils-linux package for Xenial.\n\nTo benchmark the performance we investigated a few options, such as [YCSB](https://github.com/brianfrankcooper/YCSB), and even writing our own benchmark based on examples of our real world data and queries. However we settled on using a Java-based tool, [sysbench-mongodb](https://github.com/tmcallaghan/sysbench-mongodb). This made it easy to configure and run consistent and repeatable tests that would push the database to its limits. \n\n## Methodology\n\nFirst the drives were mounted to directories reflecting their filesystems, this made it easy to switch the file system that MongoDB was using.\n\n```\nFilesystem  Type  Size  Used  Avail  Use%  Mounted on\n/dev/sda    ext4  7.7G  1.8G  5.5G   25%   /\n/dev/sdc    ext4   20G  44M   19G    1%    /ext4\n/dev/sdd    xfs    20G  33M   20G    1%    /xfs\ntank        zfs    19G  0M    19G    0%    /zfs\n```\n\nThe drives were setup and formatted with the default options of `mkfs.ext4` and `mkfs.xfs` and `zpool create`. I then wrote a script, [that can be found here](https://gist.github.com/bag-man/95cc7cc7ad7046bbe2bc30f01c0f73bd), to utilise these disks with the sysbench-mongodb utility, and log the results. If you want to see the specific commands that we used, please have a look at the script.\n\nThe way the script works is by destroying and recreating the ZFS volume with the option that is being tested, then starting a mongod instance, using the filesystems mount point as the dbpath. For example `mongod --directoryperdb --dbpath /zfs`. Then we simply run the sysbench-mongo script, and pull out the results of the run.\n\nThe parameters we decided to test for ZFS are listed below:\n\n```\nDefaults (ashift = 0, recordsize = 128K, compression = off)\nDefaults & ashift = {9,12}        \nDefaults & recordsize = {8KB,64KB}        \nDefaults & compression = {lz4,gzip}        \n```\n\nWe also edited the sysbench-mongodb config ever so slightly. We opted to use the `FSYNC_SAFE` write concern to ensure that the data was getting written to disk, and not just stored in RAM. We also reduced the number of documents per collection to `1,000,000` tenfold less than the default `10,000,000`. This was simply to save time on each “Load” step, something we aren't too concerned with as our applications are principally read-heavy.\n\nAfter running the benchmarks for each of the separate filesystems ten times and recording the  last cumulative average of the inserts per second for the “Load” stage of the benchmark, and the last cumulative average of the transactions per second for the “Execute” stage, we could create a representative average of the performance for each filesystem. \n\n\n## Results\n![Results](https://i.imgur.com/or6Lskm.png)\n\n\nYou can download the [raw data here](http://downloads.clock.co.uk/mongo_on_zol-results.tar.xz) if you want to perform your own analysis of the results.\n\nAs we suspected, ZFS doesn’t perform quite as well as the other filesystems, but it is worth noting that with the default settings it is only slightly slower. Most importantly, we didn’t uncover any show-stopping performance issues, as hinted in the discussions that are linked above. Unless you are looking to get the utmost performance in your queries, then ZFS certainly looks to be a viable option. Moreover, we feel that the benefits gained by utilising ZFS are more than worth the minor performance penalties. \n\nThis investigation has been far from definitive, but hopefully has provided you with a rough overview of how these filesystems perform. If you know of ways to help us improve the results, or performance of MongoDB on ZFS, please do let us know, we are keen to hear your experiences!\n\n:wq","mobiledoc":null,"html":"<p><em>This was written during my time at Clock.</em></p>\n\n<p>Here at Clock we love ZFS, and have been running it in production on our Linux file servers for several years. It provides us with <a href=\"https://wiki.ubuntu.com/ZFS\">numerous excellent features</a>, such as snapshotting, incremental send/receive, and transparent compression. With the recent release of <a href=\"https://wiki.ubuntu.com/XenialXerus/ReleaseNotes\">Ubuntu Xenial 16.04</a> official support for <a href=\"https://insights.ubuntu.com/2016/02/16/zfs-is-the-fs-for-containers-in-ubuntu-16-04/\">ZFS is now here</a>, and we are keen to integrate it fully into our next generation hosting stack.</p>\n\n<p>As a Node.js and MongoDB house, one of our main concerns has been how MongoDB will perform on ZFS on Linux, especially after reading about <a href=\"http://serverfault.com/questions/583688/mongodb-and-zfs-bad-performance-disk-always-busy-with-reads-while-doing-only-wr\">potential problems</a> other people have faced. There really isn't much data out there to put our minds at rest.</p>\n\n<p>We decided to setup a method of benchmarking MongoDB with the supported EXT4 and XFS, then compare against ZFS with different options enabled. The idea being that we can hopefully figure out how ZFS compares, and if there are any options we can set that will impact the performance in any noticeable way. </p>\n\n<p>There are a few caveats to our testing, so we are aware that these results need to be taken with a pinch of salt. They are aimed at just providing an indicator as to the performance between the file systems, not being a definitive guide to which is best to use.</p>\n\n<h2 id=\"setup\">Setup</h2>\n\n<p>The main variable that may affect the results was the hardware that we chose to use. We spun up a 4GB Linode instance with four cores, and four virtual disks: one for the latest Ubuntu 15.10 image (which we then upgraded to 16.04), and one disk for each of the file systems that we intended to test, EXT4, XFS and ZFS.</p>\n\n<p>The issue with this approach is that the system is running on a virtualised machine with shared hardware, so there may be variations in the performance available to the machine. In an ideal world we would run this on a physical machine with identical disks, but that wasn't feasible for this investigation.</p>\n\n<p>We decided to use the latest stable version of MongoDB 3.2.5, ZFS was at version 0.6.5.6 provided by the zfsutils-linux package for Xenial.</p>\n\n<p>To benchmark the performance we investigated a few options, such as <a href=\"https://github.com/brianfrankcooper/YCSB\">YCSB</a>, and even writing our own benchmark based on examples of our real world data and queries. However we settled on using a Java-based tool, <a href=\"https://github.com/tmcallaghan/sysbench-mongodb\">sysbench-mongodb</a>. This made it easy to configure and run consistent and repeatable tests that would push the database to its limits. </p>\n\n<h2 id=\"methodology\">Methodology</h2>\n\n<p>First the drives were mounted to directories reflecting their filesystems, this made it easy to switch the file system that MongoDB was using.</p>\n\n<pre><code>Filesystem  Type  Size  Used  Avail  Use%  Mounted on  \n/dev/sda    ext4  7.7G  1.8G  5.5G   25%   /\n/dev/sdc    ext4   20G  44M   19G    1%    /ext4\n/dev/sdd    xfs    20G  33M   20G    1%    /xfs\ntank        zfs    19G  0M    19G    0%    /zfs  \n</code></pre>\n\n<p>The drives were setup and formatted with the default options of <code>mkfs.ext4</code> and <code>mkfs.xfs</code> and <code>zpool create</code>. I then wrote a script, <a href=\"https://gist.github.com/bag-man/95cc7cc7ad7046bbe2bc30f01c0f73bd\">that can be found here</a>, to utilise these disks with the sysbench-mongodb utility, and log the results. If you want to see the specific commands that we used, please have a look at the script.</p>\n\n<p>The way the script works is by destroying and recreating the ZFS volume with the option that is being tested, then starting a mongod instance, using the filesystems mount point as the dbpath. For example <code>mongod --directoryperdb --dbpath /zfs</code>. Then we simply run the sysbench-mongo script, and pull out the results of the run.</p>\n\n<p>The parameters we decided to test for ZFS are listed below:</p>\n\n<pre><code>Defaults (ashift = 0, recordsize = 128K, compression = off)  \nDefaults &amp; ashift = {9,12}  \nDefaults &amp; recordsize = {8KB,64KB}  \nDefaults &amp; compression = {lz4,gzip}  \n</code></pre>\n\n<p>We also edited the sysbench-mongodb config ever so slightly. We opted to use the <code>FSYNC_SAFE</code> write concern to ensure that the data was getting written to disk, and not just stored in RAM. We also reduced the number of documents per collection to <code>1,000,000</code> tenfold less than the default <code>10,000,000</code>. This was simply to save time on each “Load” step, something we aren't too concerned with as our applications are principally read-heavy.</p>\n\n<p>After running the benchmarks for each of the separate filesystems ten times and recording the  last cumulative average of the inserts per second for the “Load” stage of the benchmark, and the last cumulative average of the transactions per second for the “Execute” stage, we could create a representative average of the performance for each filesystem. </p>\n\n<h2 id=\"results\">Results</h2>\n\n<p><img src=\"https://i.imgur.com/or6Lskm.png\" alt=\"Results\" /></p>\n\n<p>You can download the <a href=\"http://downloads.clock.co.uk/mongo_on_zol-results.tar.xz\">raw data here</a> if you want to perform your own analysis of the results.</p>\n\n<p>As we suspected, ZFS doesn’t perform quite as well as the other filesystems, but it is worth noting that with the default settings it is only slightly slower. Most importantly, we didn’t uncover any show-stopping performance issues, as hinted in the discussions that are linked above. Unless you are looking to get the utmost performance in your queries, then ZFS certainly looks to be a viable option. Moreover, we feel that the benefits gained by utilising ZFS are more than worth the minor performance penalties. </p>\n\n<p>This investigation has been far from definitive, but hopefully has provided you with a rough overview of how these filesystems perform. If you know of ways to help us improve the results, or performance of MongoDB on ZFS, please do let us know, we are keen to hear your experiences!</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-12 15:24:11","created_by":1,"updated_at":"2017-02-16 15:02:32","updated_by":1,"published_at":"2017-02-12 15:24:39","published_by":1},{"id":5,"uuid":"27b2c942-58b0-4233-a026-68f1f7a6c559","title":"Mixxx for Swing DJ's - A quick guide","slug":"mixxx-for-swing-djs-a-quick-guide","markdown":"[Mixxx](http://www.mixxx.org/) is an open source program designed for electronic DJ's, and has a lot of features for specialist DJ hardware, and live mixing. Which is great and all, but for jazz music at a dance event all that stuff isn't really necessary. However it is great to be able to take advantage of some of the more basic functions that Mixxx provides that you won't find in other music players.\n\n### Installation\nMixxx is open source and available for all platforms, you can download it [here](http://www.mixxx.org/download/#stable) or install it via your package manager if you are on Linux. \n\n### Appearance\nOnce you have it installed it is easy to get put off by the large amount of buttons and options, however bear with it, we can make the UI a lot nicer to work with. \n\n![Default Mixxx skin](http://i.imgur.com/8GI3vtR.png)\n\nI recommend installing the [FlatNite theme](https://www.mixxx.org/forums/viewtopic.php?f=8&t=8578) by ronso, and then clicking the hamburger menu by the clock to toggle off the panels that you don't need, then you can make it look like this.\n\n![FlatNite Theme in minimal mode](http://i.imgur.com/OEMTqIc.png)\n\n\n### Usage\nThe way I organise my music on Mixxx is to create .m3u8 playlists, for each genre of music. This lets me manage my library really easily, and make it quick to find tracks for the right moments. \n\nFor the actual playing of the music I use the \"Auto DJ\" to queue up music. This means you don't have to worry about manually hitting play on tracks and managing the decks. Just find the track you want and right click > \"Add to Auto-DJ Queue (bottom)\". Then you can open the Auto-DJ tab and order the tracks in response to the dance floor.\n\nYou can also set a negative fade value to give a pause in between tracks so that dancers can find a new partner.\n\n![Auto-DJ in action](http://i.imgur.com/9fnZ5fs.png)\n\n### Previewing tracks\nOne of the most useful features of Mixxx is the ability to preview a track on a separate device. To do this you need to get a USB audio device for your laptop. I bought [this](https://www.amazon.co.uk/gp/product/B01J3QGU50/ref=oh_aui_detailpage_o00_s00?ie=UTF8&psc=1), which allows me to use my wired headphones to preview music and the laptops line out to play music on the venues system. \n\nTo set this up you need to configure your two audio devices to output the channels. Go to Options > Preferences > Sound Hardware, and select the headphone device.\n\n![Audio settings](http://i.imgur.com/NqFei1U.png)\n\nIf you enable the preview track panel in the FlatNite theme you will get an area above the search where you can scrub through the previewed track and adjust the volume. \n\n### BPM Detection, or lack of\nOne thing you might be tempted to do (as I was) is to use Mixxx's auto BPM detection to fill in the meta data of your jazz library for you. The issue with this is that Mixxx is designed for electronic music with fixed a BPM throughout the track, which means BPM detection doesn't really work for Jazz unfortunately. \n\n### EQ and Gain\nMixxx also lets you easily tweak the EQ and gain for the currently playing track. This is handy if you need to boost the treble or volume on an old recording. \n\n### Conclusion\nHopefully this has given you some reasons to try out Mixxx, I think for me the most daunting thing was the sheer number of options to worry about and having to manually manage the decks. Thankfully with the FlatNite theme, and the Auto-DJ feature it works really nicely for the basic needs of a Jazz DJ. \n\nIf you have any questions please let me know on the reddit thread in [/r/SwingDancing.](https://redd.it/5tiogq)\n\n:wq","mobiledoc":null,"html":"<p><a href=\"http://www.mixxx.org/\">Mixxx</a> is an open source program designed for electronic DJ's, and has a lot of features for specialist DJ hardware, and live mixing. Which is great and all, but for jazz music at a dance event all that stuff isn't really necessary. However it is great to be able to take advantage of some of the more basic functions that Mixxx provides that you won't find in other music players.</p>\n\n<h3 id=\"installation\">Installation</h3>\n\n<p>Mixxx is open source and available for all platforms, you can download it <a href=\"http://www.mixxx.org/download/#stable\">here</a> or install it via your package manager if you are on Linux. </p>\n\n<h3 id=\"appearance\">Appearance</h3>\n\n<p>Once you have it installed it is easy to get put off by the large amount of buttons and options, however bear with it, we can make the UI a lot nicer to work with. </p>\n\n<p><img src=\"http://i.imgur.com/8GI3vtR.png\" alt=\"Default Mixxx skin\" /></p>\n\n<p>I recommend installing the <a href=\"https://www.mixxx.org/forums/viewtopic.php?f=8&amp;t=8578\">FlatNite theme</a> by ronso, and then clicking the hamburger menu by the clock to toggle off the panels that you don't need, then you can make it look like this.</p>\n\n<p><img src=\"http://i.imgur.com/OEMTqIc.png\" alt=\"FlatNite Theme in minimal mode\" /></p>\n\n<h3 id=\"usage\">Usage</h3>\n\n<p>The way I organise my music on Mixxx is to create .m3u8 playlists, for each genre of music. This lets me manage my library really easily, and make it quick to find tracks for the right moments. </p>\n\n<p>For the actual playing of the music I use the \"Auto DJ\" to queue up music. This means you don't have to worry about manually hitting play on tracks and managing the decks. Just find the track you want and right click > \"Add to Auto-DJ Queue (bottom)\". Then you can open the Auto-DJ tab and order the tracks in response to the dance floor.</p>\n\n<p>You can also set a negative fade value to give a pause in between tracks so that dancers can find a new partner.</p>\n\n<p><img src=\"http://i.imgur.com/9fnZ5fs.png\" alt=\"Auto-DJ in action\" /></p>\n\n<h3 id=\"previewingtracks\">Previewing tracks</h3>\n\n<p>One of the most useful features of Mixxx is the ability to preview a track on a separate device. To do this you need to get a USB audio device for your laptop. I bought <a href=\"https://www.amazon.co.uk/gp/product/B01J3QGU50/ref=oh_aui_detailpage_o00_s00?ie=UTF8&amp;psc=1\">this</a>, which allows me to use my wired headphones to preview music and the laptops line out to play music on the venues system. </p>\n\n<p>To set this up you need to configure your two audio devices to output the channels. Go to Options > Preferences > Sound Hardware, and select the headphone device.</p>\n\n<p><img src=\"http://i.imgur.com/NqFei1U.png\" alt=\"Audio settings\" /></p>\n\n<p>If you enable the preview track panel in the FlatNite theme you will get an area above the search where you can scrub through the previewed track and adjust the volume. </p>\n\n<h3 id=\"bpmdetectionorlackof\">BPM Detection, or lack of</h3>\n\n<p>One thing you might be tempted to do (as I was) is to use Mixxx's auto BPM detection to fill in the meta data of your jazz library for you. The issue with this is that Mixxx is designed for electronic music with fixed a BPM throughout the track, which means BPM detection doesn't really work for Jazz unfortunately. </p>\n\n<h3 id=\"eqandgain\">EQ and Gain</h3>\n\n<p>Mixxx also lets you easily tweak the EQ and gain for the currently playing track. This is handy if you need to boost the treble or volume on an old recording. </p>\n\n<h3 id=\"conclusion\">Conclusion</h3>\n\n<p>Hopefully this has given you some reasons to try out Mixxx, I think for me the most daunting thing was the sheer number of options to worry about and having to manually manage the decks. Thankfully with the FlatNite theme, and the Auto-DJ feature it works really nicely for the basic needs of a Jazz DJ. </p>\n\n<p>If you have any questions please let me know on the reddit thread in <a href=\"https://redd.it/5tiogq\">/r/SwingDancing.</a></p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-12 15:25:17","created_by":1,"updated_at":"2017-02-16 15:02:20","updated_by":1,"published_at":"2017-02-12 15:25:26","published_by":1},{"id":6,"uuid":"ccc04a13-9061-44fe-aaa7-4acb991648f9","title":"Traditional Jazz Primer","slug":"traditional-jazz-primer","markdown":"I'm a Lindy Hop dancer and thankfully that has exposed me to the very niche genre of Traditional Jazz, Trad for short. It can also be referred to as Hot Jazz, Dixieland Jazz or NOLA / New Orleans Jazz, although the latter is usually a slightly different sound. Trad Jazz appears to be the most agreed upon term though. I'd also like to say, I'm not an expert, just some guy that loves listening and dancing to some of the best musicians in the world. \n\n## History\nTrad Jazz is the original Jazz that was first played in the early 1900's, some songs even going back to the 1890's such as [Maple Leaf Rag](https://www.youtube.com/watch?v=pMAtL7n_-rc) which was recorded in 1899! These early songs became [Jazz Standards](https://en.wikipedia.org/wiki/Jazz_standard) which are quite universally known by Jazz musicians today. For example here is Maple Leaf Rag [being played by the wonderful Tuba Skinny](https://youtu.be/kYJhgz4L3UU?t=22) a couple of years ago.\n\nPart of the iconic roaring 20's sound was the American Jazz, made popular by artists such as [Bix Beiderbecke](https://en.wikipedia.org/wiki/Bix_Beiderbecke) and [King Oliver](https://en.wikipedia.org/wiki/King_Oliver). \n\n![King Oliver](http://img.timeinc.net/time/2002/bhm/history/images/armstrong.jpg)\n\nAs the popularity of Jazz grew in the 30's, it strayed further from it's roots in New Orleans, and started to grow into bigger bands that could fill much larger venues. This was the start of the Big Band sound, however musicians like [Sidney Bechet](https://en.wikipedia.org/wiki/Sidney_Bechet) still kept the Trad sound with wild solo's and improvisations. \n\nAs we enter the 40's the popular music of the time had transitioned into full a Big Band sound, with the likes of [Glenn Miller](https://en.wikipedia.org/wiki/Glenn_Miller) and [Benny Goodman](https://en.wikipedia.org/wiki/Benny_Goodman). This to me is where Trad Jazz became sidelined to the big bands of the time. \n\nToday, there is a resurgence of Trad Jazz bands, a lot of them cater specifically to the dancing community, and very few get any recognition outside of it. The upside to that is if you go to see a band there is a good chance you can have a beer with them afterwards!\n\n## Recommendations\nIf you want the best of modern recordings and New Orleans style, about as traditional as you can get, [Tuba Skinny](https://tubaskinny.bandcamp.com/) is the place to go. They have an extensive catalogue, and are to me, one of the best bands currently performing. This clip has some mad washboard solo's, which isn't everyone's cup of tea, but it has grown on me!\n\n[![Tuba Skinny Live](https://img.youtube.com/vi/FFChHrOP3D8/0.jpg)](https://www.youtube.com/watch?v=FFChHrOP3D8)\n\nThe video that got me into this style of music was a battle of the bands between the Stockholm Swing All Stars and The Gordon Webster Band at Snowball. \n\n[![Snowball Battle of the bands](https://img.youtube.com/vi/IWr_miwwE3w/0.jpg)](https://www.youtube.com/watch?v=IWr_miwwE3w&feature=youtu.be&t=43m23s)\n\nMy favourite clip is of Gentlemen and Gangsters, jamming with Shirt Tail Stompers, at a Lindy Exchange in Copenhagen. It happens to be my favourite song, and the solos are just so perfect. It is amazing to see them improvising so naturally.\n\n[![CLX Battle of the bands](https://img.youtube.com/vi/QLhcXJ9XBAE/0.jpg)](https://www.youtube.com/watch?v=QLhcXJ9XBAE)\n\n## Listening Resources\nFor original recordings from the era, the best place to look is [Jazz On Line](http://www.jazz-on-line.com/). It has a huge database of music that has been taken from 78's and uploaded to the site. Thankfully the music is (mostly) in the public domain now so it is free to access and use. However the site is rather old and unfriendly to use, so it make take some patience!\n\nModern bands tend to have their music on [bandcamp](https://bandcamp.com/), which is a great way to get DRM free music and directly support the bands that you love. The bands that aren't on it tend to have their music for sale physically via their website or CD reselling sites. \n\nIf you are interested in seeing a band live (I highly recommend it!) you should see if there is a Lindy Hop or Swing Dance event near you (There probably is), as a good event will have drawn out some quality musicians. \n\n## Musicians\nThis is a list of the bands that I listen to most, I've tried to link directly to their music, but often it is quite difficult so where I wasn't able to, I've linked to YouTube.\n\n* **[Aurora Nealand](http://auroranealand.bandcamp.com)** \n* **[Hot Jazz Aliance](https://barkingmadmusic.bandcamp.com/)** \n* **[Bix Beiderbecke](http://jazz-on-line.com/artists/Bix_Beiderbecke.htm)** \n* **[Vince Giordano](https://www.youtube.com/watch?v=8-mw6_W5Vqk)**\n* **[Dizzy Birds](https://dizzybirds.bandcamp.com/)**\n* **[Duke Ellington](http://jazz-on-line.com/artists/Duke_Ellington.htm)**\n* **[Eddie Condon](https://www.youtube.com/watch?v=OZnHaXgVFJY)**\n* **[Gentlemen and Gangsters](https://gentlemenandgangsters.bandcamp.com/)**\n* **[Carling Family Band](https://www.youtube.com/user/CarlingJazz)**\n* **[Gordon Webster](https://www.cdbaby.com/Search/R29yZG9uIFdlYnN0ZXI%3d/0)**\n* **[Stockholm Swing All Stars](http://www.stockholmswingallstars.com/listen/)**\n* **[Kid Ory](http://jazz-on-line.com/artists/Kid_Ory.htm)**\n* **[King Oliver](http://jazz-on-line.com/artists/King_Oliver.htm)**\n* **[Naomi and Her Handsome Devils](http://naomisdevils.bandcamp.com/)**\n* **[Patty and the Buttons](https://pattyandthebuttons.bandcamp.com/)**\n* **[Perseverance Jazz Band](https://perseverancejazzband.bandcamp.com/)**\n* **[Preservation Hall Jazz Band](https://www.preservationhalljazzband.com/releases)**\n* **[Shirt Tail Stompers](https://shirttailstompers.bandcamp.com/album/milenburg-joys)**\n* **[Shotgun Jazz Band](https://shotgunjazzband.bandcamp.com/)**\n* **[Sidney Bechet](https://www.youtube.com/watch?v=m-ZLsyc8EhM)**\n* **[Southside Aces](https://southsideaces.bandcamp.com/)**\n* **[The Fat Babies](http://www.thefatbabies.com/)**\n* **[The Harlem Hamfats](https://www.youtube.com/watch?v=XPNS3ACP9Kw)**\n* **[Thrift Set Orchestra](https://thriftset.bandcamp.com/releases)**\n* **[Tuba Skinny](https://tubaskinny.bandcamp.com/)**\n\nI hope this has been useful to you if you are exploring the world of Trad, or even better it has been eye opening to a whole world of new music to investigate!\n\nDrop a comment on the [reddit thread](https://redd.it/5tmw5h) if you have questions!\n\n:wq","mobiledoc":null,"html":"<p>I'm a Lindy Hop dancer and thankfully that has exposed me to the very niche genre of Traditional Jazz, Trad for short. It can also be referred to as Hot Jazz, Dixieland Jazz or NOLA / New Orleans Jazz, although the latter is usually a slightly different sound. Trad Jazz appears to be the most agreed upon term though. I'd also like to say, I'm not an expert, just some guy that loves listening and dancing to some of the best musicians in the world. </p>\n\n<h2 id=\"history\">History</h2>\n\n<p>Trad Jazz is the original Jazz that was first played in the early 1900's, some songs even going back to the 1890's such as <a href=\"https://www.youtube.com/watch?v=pMAtL7n_-rc\">Maple Leaf Rag</a> which was recorded in 1899! These early songs became <a href=\"https://en.wikipedia.org/wiki/Jazz_standard\">Jazz Standards</a> which are quite universally known by Jazz musicians today. For example here is Maple Leaf Rag <a href=\"https://youtu.be/kYJhgz4L3UU?t=22\">being played by the wonderful Tuba Skinny</a> a couple of years ago.</p>\n\n<p>Part of the iconic roaring 20's sound was the American Jazz, made popular by artists such as <a href=\"https://en.wikipedia.org/wiki/Bix_Beiderbecke\">Bix Beiderbecke</a> and <a href=\"https://en.wikipedia.org/wiki/King_Oliver\">King Oliver</a>. </p>\n\n<p><img src=\"http://img.timeinc.net/time/2002/bhm/history/images/armstrong.jpg\" alt=\"King Oliver\" /></p>\n\n<p>As the popularity of Jazz grew in the 30's, it strayed further from it's roots in New Orleans, and started to grow into bigger bands that could fill much larger venues. This was the start of the Big Band sound, however musicians like <a href=\"https://en.wikipedia.org/wiki/Sidney_Bechet\">Sidney Bechet</a> still kept the Trad sound with wild solo's and improvisations. </p>\n\n<p>As we enter the 40's the popular music of the time had transitioned into full a Big Band sound, with the likes of <a href=\"https://en.wikipedia.org/wiki/Glenn_Miller\">Glenn Miller</a> and <a href=\"https://en.wikipedia.org/wiki/Benny_Goodman\">Benny Goodman</a>. This to me is where Trad Jazz became sidelined to the big bands of the time. </p>\n\n<p>Today, there is a resurgence of Trad Jazz bands, a lot of them cater specifically to the dancing community, and very few get any recognition outside of it. The upside to that is if you go to see a band there is a good chance you can have a beer with them afterwards!</p>\n\n<h2 id=\"recommendations\">Recommendations</h2>\n\n<p>If you want the best of modern recordings and New Orleans style, about as traditional as you can get, <a href=\"https://tubaskinny.bandcamp.com/\">Tuba Skinny</a> is the place to go. They have an extensive catalogue, and are to me, one of the best bands currently performing. This clip has some mad washboard solo's, which isn't everyone's cup of tea, but it has grown on me!</p>\n\n<p><a href=\"https://www.youtube.com/watch?v=FFChHrOP3D8\"><img src=\"https://img.youtube.com/vi/FFChHrOP3D8/0.jpg\" alt=\"Tuba Skinny Live\" title=\"\" /></a></p>\n\n<p>The video that got me into this style of music was a battle of the bands between the Stockholm Swing All Stars and The Gordon Webster Band at Snowball. </p>\n\n<p><a href=\"https://www.youtube.com/watch?v=IWr_miwwE3w&amp;feature=youtu.be&amp;t=43m23s\"><img src=\"https://img.youtube.com/vi/IWr_miwwE3w/0.jpg\" alt=\"Snowball Battle of the bands\" title=\"\" /></a></p>\n\n<p>My favourite clip is of Gentlemen and Gangsters, jamming with Shirt Tail Stompers, at a Lindy Exchange in Copenhagen. It happens to be my favourite song, and the solos are just so perfect. It is amazing to see them improvising so naturally.</p>\n\n<p><a href=\"https://www.youtube.com/watch?v=QLhcXJ9XBAE\"><img src=\"https://img.youtube.com/vi/QLhcXJ9XBAE/0.jpg\" alt=\"CLX Battle of the bands\" title=\"\" /></a></p>\n\n<h2 id=\"listeningresources\">Listening Resources</h2>\n\n<p>For original recordings from the era, the best place to look is <a href=\"http://www.jazz-on-line.com/\">Jazz On Line</a>. It has a huge database of music that has been taken from 78's and uploaded to the site. Thankfully the music is (mostly) in the public domain now so it is free to access and use. However the site is rather old and unfriendly to use, so it make take some patience!</p>\n\n<p>Modern bands tend to have their music on <a href=\"https://bandcamp.com/\">bandcamp</a>, which is a great way to get DRM free music and directly support the bands that you love. The bands that aren't on it tend to have their music for sale physically via their website or CD reselling sites. </p>\n\n<p>If you are interested in seeing a band live (I highly recommend it!) you should see if there is a Lindy Hop or Swing Dance event near you (There probably is), as a good event will have drawn out some quality musicians. </p>\n\n<h2 id=\"musicians\">Musicians</h2>\n\n<p>This is a list of the bands that I listen to most, I've tried to link directly to their music, but often it is quite difficult so where I wasn't able to, I've linked to YouTube.</p>\n\n<ul>\n<li><strong><a href=\"http://auroranealand.bandcamp.com\">Aurora Nealand</a></strong> </li>\n<li><strong><a href=\"https://barkingmadmusic.bandcamp.com/\">Hot Jazz Aliance</a></strong> </li>\n<li><strong><a href=\"http://jazz-on-line.com/artists/Bix_Beiderbecke.htm\">Bix Beiderbecke</a></strong> </li>\n<li><strong><a href=\"https://www.youtube.com/watch?v=8-mw6_W5Vqk\">Vince Giordano</a></strong></li>\n<li><strong><a href=\"https://dizzybirds.bandcamp.com/\">Dizzy Birds</a></strong></li>\n<li><strong><a href=\"http://jazz-on-line.com/artists/Duke_Ellington.htm\">Duke Ellington</a></strong></li>\n<li><strong><a href=\"https://www.youtube.com/watch?v=OZnHaXgVFJY\">Eddie Condon</a></strong></li>\n<li><strong><a href=\"https://gentlemenandgangsters.bandcamp.com/\">Gentlemen and Gangsters</a></strong></li>\n<li><strong><a href=\"https://www.youtube.com/user/CarlingJazz\">Carling Family Band</a></strong></li>\n<li><strong><a href=\"https://www.cdbaby.com/Search/R29yZG9uIFdlYnN0ZXI%3d/0\">Gordon Webster</a></strong></li>\n<li><strong><a href=\"http://www.stockholmswingallstars.com/listen/\">Stockholm Swing All Stars</a></strong></li>\n<li><strong><a href=\"http://jazz-on-line.com/artists/Kid_Ory.htm\">Kid Ory</a></strong></li>\n<li><strong><a href=\"http://jazz-on-line.com/artists/King_Oliver.htm\">King Oliver</a></strong></li>\n<li><strong><a href=\"http://naomisdevils.bandcamp.com/\">Naomi and Her Handsome Devils</a></strong></li>\n<li><strong><a href=\"https://pattyandthebuttons.bandcamp.com/\">Patty and the Buttons</a></strong></li>\n<li><strong><a href=\"https://perseverancejazzband.bandcamp.com/\">Perseverance Jazz Band</a></strong></li>\n<li><strong><a href=\"https://www.preservationhalljazzband.com/releases\">Preservation Hall Jazz Band</a></strong></li>\n<li><strong><a href=\"https://shirttailstompers.bandcamp.com/album/milenburg-joys\">Shirt Tail Stompers</a></strong></li>\n<li><strong><a href=\"https://shotgunjazzband.bandcamp.com/\">Shotgun Jazz Band</a></strong></li>\n<li><strong><a href=\"https://www.youtube.com/watch?v=m-ZLsyc8EhM\">Sidney Bechet</a></strong></li>\n<li><strong><a href=\"https://southsideaces.bandcamp.com/\">Southside Aces</a></strong></li>\n<li><strong><a href=\"http://www.thefatbabies.com/\">The Fat Babies</a></strong></li>\n<li><strong><a href=\"https://www.youtube.com/watch?v=XPNS3ACP9Kw\">The Harlem Hamfats</a></strong></li>\n<li><strong><a href=\"https://thriftset.bandcamp.com/releases\">Thrift Set Orchestra</a></strong></li>\n<li><strong><a href=\"https://tubaskinny.bandcamp.com/\">Tuba Skinny</a></strong></li>\n</ul>\n\n<p>I hope this has been useful to you if you are exploring the world of Trad, or even better it has been eye opening to a whole world of new music to investigate!</p>\n\n<p>Drop a comment on the <a href=\"https://redd.it/5tmw5h\">reddit thread</a> if you have questions!</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-12 16:00:55","created_by":1,"updated_at":"2017-02-16 15:01:42","updated_by":1,"published_at":"2017-02-12 17:59:24","published_by":1},{"id":7,"uuid":"6ae462b2-56f8-446d-966f-16c9d6dd3131","title":"HJKL all the things!","slug":"hjkl-all-the-things","markdown":"If you are a Vim user, you will hopefully have been using HJKL and to navigate your documents, rather than the arrow keys. However I like to take this idea a little further. Well, a lot further. \n\n## But why? \nIt can seem like an odd thing to someone who has never tried it, however the more you use it the more you notice the micro inefficiencies that come from reaching for a mouse, or even the arrow keys. \n\nMy thinking is, if I can save a few seconds every day from having my fingertips where they need to be, over a life time that makes a difference! Plus it looks cool to whizz around your system without moving a muscle from your keyboard.\n\nOn my Chromebook I have three modifier keys, Ctrl + Alt + Shift, when we combine those with HJKL we end up with 32 key combinations. Add to that different contexts in different applications, there should never be a reason to leave the home row!\n\n\n## Vimium / VimFX\nTo use HJKL in your browser, doesn't require that much of a configuration or change to your system at all. Just install [Vimium](https://chrome.google.com/webstore/detail/vimium/dbepggeogbaibhgnhhndojpepiihcmeb?hl=en) for Chrome, or [VimFX](https://addons.mozilla.org/en-GB/firefox/addon/vimfx/) for Firefox. \n\nNow you can scroll pages with `hjkl`, go backwards and forwards with `H` & `L`, and switch tab with `J` and `K`. To click links, you use `f` for current tab or `F` for new tab. Then you type the letters that are on the link that you want to go to. \n\n![Vimium links](/content/images/2017/02/shot-2.png)\n\nIt takes a bit of getting used to, but once you get the hang of it, you can navigate so much quicker for most basic web browsing. It helps you practice touch typing too!\n\n\n\n## Vim\nEveryone's vim setup and workflow is different, but to tie in with my HJKL theme, I've tweaked a few things. Firstly, I mapped `J` and `K` to mimic the changing of tabs in Vimium. This is probably a controversial move, as you have to rebind the `J` key, I chose to use `M`erge lines.\n\n    nnoremap J :tabprev<CR>\n    nnoremap K :tabnext<CR>\n    nnoremap M J\n\nThe next thing I did was to enable `j` & `k` to work in drop down auto complete lists. This makes it easier to select items without moving your fingers.\n\n    inoremap <expr> j ((pumvisible())?(\"\\<C-n>\"):(\"j\"))\n    inoremap <expr> k ((pumvisible())?(\"\\<C-p>\"):(\"k\"))\n    inoremap <expr> <tab> ((pumvisible())?(\"\\<Cr>\"):(\"<Cr>\"))\n\n![Vim auto complete menu](/content/images/2017/02/shot-3.png)\n\nI also found it really handy to map `H` & `L` to jump to the beginning and ends of lines. \n\n    nnoremap H ^\n    nnoremap L $\n\n## Tiling Window Manager / Xmonad\nOn my systems I run a tiling window manager called Xmonad. Below I will give the bindings specific to Xmonad, but hopefully you can see the idea I'm getting at and apply it to your own DE / WM if you  fancy giving this a try. \n\n    -- Adjust split\n    ((mod1Mask, xK_j), sendMessage MirrorShrink),\n    ((mod1Mask, xK_k), sendMessage MirrorExpand),\n    \n    -- Workspaces\n    ((controlMask .|. mod1Mask, xK_l), nextWS),\n    ((controlMask .|. mod1Mask, xK_h), prevWS),\n    ((mod1Mask .|. shiftMask, xK_l), shiftToNext >> nextWS),\n    ((mod1Mask .|. shiftMask, xK_h), shiftToPrev >> prevWS),\n\nWhat this lets me do is resize my current window with `Alt` + `h/j/k/l`, move the current window around the workspace with `Shift` + `Alt` + `J/K`, or move it to another workspace with `Shift` + `Alt` + `H/L`. I can then also shift workspaces with `Ctrl` + `h/l`.\n\nThis means that if I have Vim on one workspace, and Chrome on the other, I can seamlessly move between them and interact with them, without moving my fingers at all! \n\n## Conclusion\nAfter having lived with this setup for the better part of two years, I am pretty happy with it, although I'm always looking for some ways to improve it, as well as a few bugs to solve. One of the most rage inducing bugs is in Chrome, viewing a PDF will stop Vimium from running, meaning you can get stuck on a tab. \n\nIf you give this a try, I'd be interested to hear how you find it, hopefully you will really notice those times you are forced to use the mouse or arrow keys. \n\nMy [dotfiles](https://github.com/bag-man/dotfiles) have a lot more configurations, so if you want to get the bigger picture check them out. \n\n:wq","mobiledoc":null,"html":"<p>If you are a Vim user, you will hopefully have been using HJKL and to navigate your documents, rather than the arrow keys. However I like to take this idea a little further. Well, a lot further. </p>\n\n<h2 id=\"butwhy\">But why?</h2>\n\n<p>It can seem like an odd thing to someone who has never tried it, however the more you use it the more you notice the micro inefficiencies that come from reaching for a mouse, or even the arrow keys. </p>\n\n<p>My thinking is, if I can save a few seconds every day from having my fingertips where they need to be, over a life time that makes a difference! Plus it looks cool to whizz around your system without moving a muscle from your keyboard.</p>\n\n<p>On my Chromebook I have three modifier keys, Ctrl + Alt + Shift, when we combine those with HJKL we end up with 32 key combinations. Add to that different contexts in different applications, there should never be a reason to leave the home row!</p>\n\n<h2 id=\"vimiumvimfx\">Vimium / VimFX</h2>\n\n<p>To use HJKL in your browser, doesn't require that much of a configuration or change to your system at all. Just install <a href=\"https://chrome.google.com/webstore/detail/vimium/dbepggeogbaibhgnhhndojpepiihcmeb?hl=en\">Vimium</a> for Chrome, or <a href=\"https://addons.mozilla.org/en-GB/firefox/addon/vimfx/\">VimFX</a> for Firefox. </p>\n\n<p>Now you can scroll pages with <code>hjkl</code>, go backwards and forwards with <code>H</code> &amp; <code>L</code>, and switch tab with <code>J</code> and <code>K</code>. To click links, you use <code>f</code> for current tab or <code>F</code> for new tab. Then you type the letters that are on the link that you want to go to. </p>\n\n<p><img src=\"/content/images/2017/02/shot-2.png\" alt=\"Vimium links\" /></p>\n\n<p>It takes a bit of getting used to, but once you get the hang of it, you can navigate so much quicker for most basic web browsing. It helps you practice touch typing too!</p>\n\n<h2 id=\"vim\">Vim</h2>\n\n<p>Everyone's vim setup and workflow is different, but to tie in with my HJKL theme, I've tweaked a few things. Firstly, I mapped <code>J</code> and <code>K</code> to mimic the changing of tabs in Vimium. This is probably a controversial move, as you have to rebind the <code>J</code> key, I chose to use <code>M</code>erge lines.</p>\n\n<pre><code>nnoremap J :tabprev&lt;CR&gt;\nnnoremap K :tabnext&lt;CR&gt;\nnnoremap M J\n</code></pre>\n\n<p>The next thing I did was to enable <code>j</code> &amp; <code>k</code> to work in drop down auto complete lists. This makes it easier to select items without moving your fingers.</p>\n\n<pre><code>inoremap &lt;expr&gt; j ((pumvisible())?(\"\\&lt;C-n&gt;\"):(\"j\"))\ninoremap &lt;expr&gt; k ((pumvisible())?(\"\\&lt;C-p&gt;\"):(\"k\"))\ninoremap &lt;expr&gt; &lt;tab&gt; ((pumvisible())?(\"\\&lt;Cr&gt;\"):(\"&lt;Cr&gt;\"))\n</code></pre>\n\n<p><img src=\"/content/images/2017/02/shot-3.png\" alt=\"Vim auto complete menu\" /></p>\n\n<p>I also found it really handy to map <code>H</code> &amp; <code>L</code> to jump to the beginning and ends of lines. </p>\n\n<pre><code>nnoremap H ^\nnnoremap L $\n</code></pre>\n\n<h2 id=\"tilingwindowmanagerxmonad\">Tiling Window Manager / Xmonad</h2>\n\n<p>On my systems I run a tiling window manager called Xmonad. Below I will give the bindings specific to Xmonad, but hopefully you can see the idea I'm getting at and apply it to your own DE / WM if you  fancy giving this a try. </p>\n\n<pre><code>-- Adjust split\n((mod1Mask, xK_j), sendMessage MirrorShrink),\n((mod1Mask, xK_k), sendMessage MirrorExpand),\n\n-- Workspaces\n((controlMask .|. mod1Mask, xK_l), nextWS),\n((controlMask .|. mod1Mask, xK_h), prevWS),\n((mod1Mask .|. shiftMask, xK_l), shiftToNext &gt;&gt; nextWS),\n((mod1Mask .|. shiftMask, xK_h), shiftToPrev &gt;&gt; prevWS),\n</code></pre>\n\n<p>What this lets me do is resize my current window with <code>Alt</code> + <code>h/j/k/l</code>, move the current window around the workspace with <code>Shift</code> + <code>Alt</code> + <code>J/K</code>, or move it to another workspace with <code>Shift</code> + <code>Alt</code> + <code>H/L</code>. I can then also shift workspaces with <code>Ctrl</code> + <code>h/l</code>.</p>\n\n<p>This means that if I have Vim on one workspace, and Chrome on the other, I can seamlessly move between them and interact with them, without moving my fingers at all! </p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>After having lived with this setup for the better part of two years, I am pretty happy with it, although I'm always looking for some ways to improve it, as well as a few bugs to solve. One of the most rage inducing bugs is in Chrome, viewing a PDF will stop Vimium from running, meaning you can get stuck on a tab. </p>\n\n<p>If you give this a try, I'd be interested to hear how you find it, hopefully you will really notice those times you are forced to use the mouse or arrow keys. </p>\n\n<p>My <a href=\"https://github.com/bag-man/dotfiles\">dotfiles</a> have a lot more configurations, so if you want to get the bigger picture check them out. </p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-12 19:09:52","created_by":1,"updated_at":"2017-02-16 15:01:28","updated_by":1,"published_at":"2017-02-12 19:48:57","published_by":1},{"id":8,"uuid":"924af795-a774-440d-9d65-2b90b0a41abf","title":"[Project Log #1] Today I found out rm can only take 100,000 arguments at a time...","slug":"project-log-today-i-found-out-rm-can-only-take-100-000-arguments-at-a-time","markdown":"I've just began working on my final year project, and was advised to document my progress in a diary or blog, so here we go. \n\nMy project is going to be based around genomic data that has been sequenced from three strains of yeast. The plan is to annotate the sequenced contigs of DNA, and then compare them against each other to see where the genes of the yeasts differ. \n\n![Candida Tropicalis](https://classconnection.s3.amazonaws.com/192/flashcards/1534192/png/screen_shot_2013-04-22_at_80924_pm1366675786179.png)\n\nThis will hopefully help the researchers understand what genes are responsible for certain characteristics of the yeasts, and enable them to modify one of the species to perform a more useful function. \n\n## Playing with alignment tools\nAfter getting the data, I began to experiment with different tools and getting used to working with the [fasta](https://en.wikipedia.org/wiki/FASTA_format) format. \n\nThe most commonly used tool for gene alignment is [blast](https://blast.ncbi.nlm.nih.gov/Blast.cgi), however it was written in 1990 originally and is over 600MB's to install. So I would like to look into more modern tools, in the hopes of speeding up the time it takes to align the sequences. \n\nI started by downloading the 66GB [NCBI nr database](https://www.ncbi.nlm.nih.gov/refseq/about/nonredundantproteins), it is a fasta file that contains a collection of known genes that have been annotated. This is what I will use to query the yeast contigs against. \n\nI started out by using [diamond](https://github.com/bbuchfink/diamond), which works just like blast, however it is much more modern and runs a claimed 20,000 times faster! The first step in using diamond for alignment is to take your reference sequences and create a database from that for your queries to be ran against.\n\n![Running diamond on the makedb 33Mins](/content/images/2017/02/shot-4.png)\n\nThis took me 33 minutes to do for the whole NCBI nr database, which didn't seem too bad. I then ran an alignment with the 16MB of sequenced yeast contigs, against this database.\n\n![Running diamond against Candida_Y4 for the first time 75mins](/content/images/2017/02/shot-5.png)\n\nThat took 75 minutes to run and produced some useful (I hope!) data. \n\nI should mention the hardware that I am running this on, as the times are meaningless with out that. My home PC has a i7-6700k @ 4.6Ghz, 16GB of RAM, a GTX 980 and unfortunately I didn't have an SSD big enough for this data, so I'm having to use my HDD which is probably causing a lot of bottlenecks.\n\nNow that I know I can run an alignment with diamond in a reasonable time, I wanted to explore the options of using a GPU accelerated alignment tool in the hopes that this would allow for much faster alignment times. I first tried [BarraCUDA](http://seqbarracuda.sourceforge.net/), it installed fine but would appear to try and read the entire reference database (64GB) into my 16GB of RAM, and then crash, so this wasn't a good start. \n\nI then tried [CLAST](https://github.com/masayano/CLAST), but was unable to successfully compile due to a C++ error that looked like a rabbit hole I really didn't want to go down. Next up was [cudasw++](cudasw.sourceforge.net/), this installed fine but again, like BarraCUDA, it would attempt to read the whole reference file into memory. \n\nStarting to see a theme here... Perhaps having one monolithic 64GB file isn't the best way to go about business. I decided to split the file up into six chunks to make it more manageable. Oddly this proved a lot more difficult than you would think. Several of the solutions I tried like pyfasta would read the whole file into memory again, which seems like a slight design oversight.\n\nI then tried [faSplit](https://github.com/jstjohn/KentLib/blob/master/examples/faSplit/faSplit.c), which appeared to be working well, it created three 12GB files, and then hundreds of thousands of ~300byte files. This is how I found out that `rm` can only take 100,000 arguments at a time. Not wanting to deal with cleaning up nearly a million files again I decided to try and use [genome tools](genometools.org/).\n\nMercifully, it worked perfectly. Although it did take quite a long time, but writing 64GB's to disk is never going to be fast with a mechanical drive. \n\nI now had 11GB chunks of the nr database, so I decided to try cudasw++ again, however it segfaulted as it did before. I then went back to BarraCUDA and it also segfaulted. In one last ditch effort I split one of the 11GB files in half and tried again, but it still segfaulted in both applications.\n\nLooks like there is a lot more work to go into getting GPU accelerated alignment than I had hoped. I'll probably just stick with diamond because of this.\n\n:wq","mobiledoc":null,"html":"<p>I've just began working on my final year project, and was advised to document my progress in a diary or blog, so here we go. </p>\n\n<p>My project is going to be based around genomic data that has been sequenced from three strains of yeast. The plan is to annotate the sequenced contigs of DNA, and then compare them against each other to see where the genes of the yeasts differ. </p>\n\n<p><img src=\"https://classconnection.s3.amazonaws.com/192/flashcards/1534192/png/screen_shot_2013-04-22_at_80924_pm1366675786179.png\" alt=\"Candida Tropicalis\" /></p>\n\n<p>This will hopefully help the researchers understand what genes are responsible for certain characteristics of the yeasts, and enable them to modify one of the species to perform a more useful function. </p>\n\n<h2 id=\"playingwithalignmenttools\">Playing with alignment tools</h2>\n\n<p>After getting the data, I began to experiment with different tools and getting used to working with the <a href=\"https://en.wikipedia.org/wiki/FASTA_format\">fasta</a> format. </p>\n\n<p>The most commonly used tool for gene alignment is <a href=\"https://blast.ncbi.nlm.nih.gov/Blast.cgi\">blast</a>, however it was written in 1990 originally and is over 600MB's to install. So I would like to look into more modern tools, in the hopes of speeding up the time it takes to align the sequences. </p>\n\n<p>I started by downloading the 66GB <a href=\"https://www.ncbi.nlm.nih.gov/refseq/about/nonredundantproteins\">NCBI nr database</a>, it is a fasta file that contains a collection of known genes that have been annotated. This is what I will use to query the yeast contigs against. </p>\n\n<p>I started out by using <a href=\"https://github.com/bbuchfink/diamond\">diamond</a>, which works just like blast, however it is much more modern and runs a claimed 20,000 times faster! The first step in using diamond for alignment is to take your reference sequences and create a database from that for your queries to be ran against.</p>\n\n<p><img src=\"/content/images/2017/02/shot-4.png\" alt=\"Running diamond on the makedb 33Mins\" /></p>\n\n<p>This took me 33 minutes to do for the whole NCBI nr database, which didn't seem too bad. I then ran an alignment with the 16MB of sequenced yeast contigs, against this database.</p>\n\n<p><img src=\"/content/images/2017/02/shot-5.png\" alt=\"Running diamond against Candida_Y4 for the first time 75mins\" /></p>\n\n<p>That took 75 minutes to run and produced some useful (I hope!) data. </p>\n\n<p>I should mention the hardware that I am running this on, as the times are meaningless with out that. My home PC has a i7-6700k @ 4.6Ghz, 16GB of RAM, a GTX 980 and unfortunately I didn't have an SSD big enough for this data, so I'm having to use my HDD which is probably causing a lot of bottlenecks.</p>\n\n<p>Now that I know I can run an alignment with diamond in a reasonable time, I wanted to explore the options of using a GPU accelerated alignment tool in the hopes that this would allow for much faster alignment times. I first tried <a href=\"http://seqbarracuda.sourceforge.net/\">BarraCUDA</a>, it installed fine but would appear to try and read the entire reference database (64GB) into my 16GB of RAM, and then crash, so this wasn't a good start. </p>\n\n<p>I then tried <a href=\"https://github.com/masayano/CLAST\">CLAST</a>, but was unable to successfully compile due to a C++ error that looked like a rabbit hole I really didn't want to go down. Next up was <a href=\"cudasw.sourceforge.net/\">cudasw++</a>, this installed fine but again, like BarraCUDA, it would attempt to read the whole reference file into memory. </p>\n\n<p>Starting to see a theme here... Perhaps having one monolithic 64GB file isn't the best way to go about business. I decided to split the file up into six chunks to make it more manageable. Oddly this proved a lot more difficult than you would think. Several of the solutions I tried like pyfasta would read the whole file into memory again, which seems like a slight design oversight.</p>\n\n<p>I then tried <a href=\"https://github.com/jstjohn/KentLib/blob/master/examples/faSplit/faSplit.c\">faSplit</a>, which appeared to be working well, it created three 12GB files, and then hundreds of thousands of ~300byte files. This is how I found out that <code>rm</code> can only take 100,000 arguments at a time. Not wanting to deal with cleaning up nearly a million files again I decided to try and use <a href=\"genometools.org/\">genome tools</a>.</p>\n\n<p>Mercifully, it worked perfectly. Although it did take quite a long time, but writing 64GB's to disk is never going to be fast with a mechanical drive. </p>\n\n<p>I now had 11GB chunks of the nr database, so I decided to try cudasw++ again, however it segfaulted as it did before. I then went back to BarraCUDA and it also segfaulted. In one last ditch effort I split one of the 11GB files in half and tried again, but it still segfaulted in both applications.</p>\n\n<p>Looks like there is a lot more work to go into getting GPU accelerated alignment than I had hoped. I'll probably just stick with diamond because of this.</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-13 13:03:57","created_by":1,"updated_at":"2017-04-05 13:34:44","updated_by":1,"published_at":"2017-02-15 19:45:51","published_by":1},{"id":9,"uuid":"442a3e73-b7a7-44ae-8cab-0642fee126c8","title":"ES6 boilerplate, with Webpack, Mongoose, Pug, Stylus and a bunch of other goodies","slug":"nodejs-es6-boiler-plate","markdown":"During my industrial year at [Clock Limited](http://clock.co.uk) I was exposed to a lot of new javascript technologies, however working on an existing code base means you can't always use the latest and greatest tools that you want to.\n\nAs a side project myself, [Kenan](https://kyusuf.com/), [Ben](https://github.com/benjaminparnell) and [Matt](https://github.com/maael) decided to work on something a little bit different on friday afternoons to keep the noodles ticking over. \n\nWe came up with [itsback.at](http://alpha.itsback.at), which sadly never got finished; but it did allow us to play with a whole host of new technologies that we hadn't had the chance to use before, including ES6.\n\nFrom that I've extracted the core boilerplate and made a repository for future projects. You can find it all on [Github](https://github.com/bag-man/nodestack).\n\n### Technologies\nHere are some of the core technologies utilised in this boilerplate.\n\n[Node 6.9.0](http://nodejs.org) - Lets us use ES6 on the server side.\n\n[MongoDB 3.2](http://mongodb.com) - NoSQL isn't for everyone but we find it works nicely with Node.\n\n[Webpack](https://webpack.github.io/) - Builds all of our code into production ready bundles.\n\n[SocketIO](http://socket.io) - Web sockets made easy.\n\n[Mongoose](http://mongoosejs.com/) - Database controller.\n\n[Pug](https://pugjs.org/api/getting-started.html) - HTML templating language.\n\n[Stylus](http://stylus-lang.com/) - Minimal CSS.\n\n[ESlint](http://eslint.org/) - Modern linting that supports ES6.\n\n### Build scripts\n\n`npm test` - check that the code passes linting, using [Clock's eslint preset](https://www.npmjs.com/package/eslint-config-clock), run all the tests in the test folder, and produce a coverage report with istanbul.\n\n`npm run build` - builds the project for production, it will trans-compile the stylus down to CSS, and the client side JS to ES5, and then minify it. \n\n`npm run watch` - this does the same as the build, however it will not minify the clientside JS, but will set the project up to rebuild on any changes to JS or Jade files.\n\n### External services\nThe project is designed to be used with [Travis CI](https://travis-ci.org/), [Codecov](https://codecov.io/) and [Heroku](heroku.com). All you need to do to get it up and running is link your Github repository with these services, and set it to build on push. \n\nThis means that when you update your code and push it to Github, it will then build the application and run its tests in Travis CI. If it is successful it will upload the coverage statistics of the tests to Codecov, and then deploy the new build to Heroku for all to see. \n\nI've even included some snazzy badges in the readme, you just need to change the repository links. Click a badge to see what the service looks like!\n\n[![Build Status](https://img.shields.io/travis/bag-man/nodestack.svg?style=flat-square)](https://travis-ci.org/bag-man/nodestack)\n[![Coverage](https://img.shields.io/codecov/c/github/bag-man/nodestack.svg?style=flat-square)](https://codecov.io/github/bag-man/nodestack)\n[![Dependencies](https://img.shields.io/david/bag-man/nodestack.svg?style=flat-square)](https://david-dm.org/bag-man/nodestack)\n[![Code Climate](https://img.shields.io/codeclimate/github/bag-man/nodestack.svg?style=flat-square)](https://codeclimate.com/github/bag-man/nodestack)\n[![Known Vulnerabilities](https://snyk.io/test/github/bag-man/nodestack/badge.svg?style=flat-square)](https://snyk.io/test/github/bag-man/nodestack)\n[![Stories in Backlog](https://img.shields.io/waffle/label/bag-man/nodestack.svg?label=Backlog&title=Backlog&style=flat-square)](http://waffle.io/bag-man/nodestack)\n\n### Thanks, and alternatives\n\nA lot of credit needs to go to the people at Clock as well as those co-workers mentioned above for developing this stack, so please go check them out. This isn't the most polished boilerplate, as it is rather bare bones and doesn't include an MVC framework so it might not be for you. \n\nOne alternative to check out is [Mega Boilerplate](http://megaboilerplate.com/), it allows you to select what technologies you want to use for each part of the stack and bundles it all up for you. My only gripe with it is the generated code isn't ES6 and is a bit oddly laid out. \n\nIf you want to ask me any questions feel free to [email](mailto://garland.owen@gmail.com) me, or comment on a reddit thread.\n\n:wq","mobiledoc":null,"html":"<p>During my industrial year at <a href=\"http://clock.co.uk\">Clock Limited</a> I was exposed to a lot of new javascript technologies, however working on an existing code base means you can't always use the latest and greatest tools that you want to.</p>\n\n<p>As a side project myself, <a href=\"https://kyusuf.com/\">Kenan</a>, <a href=\"https://github.com/benjaminparnell\">Ben</a> and <a href=\"https://github.com/maael\">Matt</a> decided to work on something a little bit different on friday afternoons to keep the noodles ticking over. </p>\n\n<p>We came up with <a href=\"http://alpha.itsback.at\">itsback.at</a>, which sadly never got finished; but it did allow us to play with a whole host of new technologies that we hadn't had the chance to use before, including ES6.</p>\n\n<p>From that I've extracted the core boilerplate and made a repository for future projects. You can find it all on <a href=\"https://github.com/bag-man/nodestack\">Github</a>.</p>\n\n<h3 id=\"technologies\">Technologies</h3>\n\n<p>Here are some of the core technologies utilised in this boilerplate.</p>\n\n<p><a href=\"http://nodejs.org\">Node 6.9.0</a> - Lets us use ES6 on the server side.</p>\n\n<p><a href=\"http://mongodb.com\">MongoDB 3.2</a> - NoSQL isn't for everyone but we find it works nicely with Node.</p>\n\n<p><a href=\"https://webpack.github.io/\">Webpack</a> - Builds all of our code into production ready bundles.</p>\n\n<p><a href=\"http://socket.io\">SocketIO</a> - Web sockets made easy.</p>\n\n<p><a href=\"http://mongoosejs.com/\">Mongoose</a> - Database controller.</p>\n\n<p><a href=\"https://pugjs.org/api/getting-started.html\">Pug</a> - HTML templating language.</p>\n\n<p><a href=\"http://stylus-lang.com/\">Stylus</a> - Minimal CSS.</p>\n\n<p><a href=\"http://eslint.org/\">ESlint</a> - Modern linting that supports ES6.</p>\n\n<h3 id=\"buildscripts\">Build scripts</h3>\n\n<p><code>npm test</code> - check that the code passes linting, using <a href=\"https://www.npmjs.com/package/eslint-config-clock\">Clock's eslint preset</a>, run all the tests in the test folder, and produce a coverage report with istanbul.</p>\n\n<p><code>npm run build</code> - builds the project for production, it will trans-compile the stylus down to CSS, and the client side JS to ES5, and then minify it. </p>\n\n<p><code>npm run watch</code> - this does the same as the build, however it will not minify the clientside JS, but will set the project up to rebuild on any changes to JS or Jade files.</p>\n\n<h3 id=\"externalservices\">External services</h3>\n\n<p>The project is designed to be used with <a href=\"https://travis-ci.org/\">Travis CI</a>, <a href=\"https://codecov.io/\">Codecov</a> and <a href=\"heroku.com\">Heroku</a>. All you need to do to get it up and running is link your Github repository with these services, and set it to build on push. </p>\n\n<p>This means that when you update your code and push it to Github, it will then build the application and run its tests in Travis CI. If it is successful it will upload the coverage statistics of the tests to Codecov, and then deploy the new build to Heroku for all to see. </p>\n\n<p>I've even included some snazzy badges in the readme, you just need to change the repository links. Click a badge to see what the service looks like!</p>\n\n<p><a href=\"https://travis-ci.org/bag-man/nodestack\"><img src=\"https://img.shields.io/travis/bag-man/nodestack.svg?style=flat-square\" alt=\"Build Status\" title=\"\" /></a>\n<a href=\"https://codecov.io/github/bag-man/nodestack\"><img src=\"https://img.shields.io/codecov/c/github/bag-man/nodestack.svg?style=flat-square\" alt=\"Coverage\" title=\"\" /></a>\n<a href=\"https://david-dm.org/bag-man/nodestack\"><img src=\"https://img.shields.io/david/bag-man/nodestack.svg?style=flat-square\" alt=\"Dependencies\" title=\"\" /></a>\n<a href=\"https://codeclimate.com/github/bag-man/nodestack\"><img src=\"https://img.shields.io/codeclimate/github/bag-man/nodestack.svg?style=flat-square\" alt=\"Code Climate\" title=\"\" /></a>\n<a href=\"https://snyk.io/test/github/bag-man/nodestack\"><img src=\"https://snyk.io/test/github/bag-man/nodestack/badge.svg?style=flat-square\" alt=\"Known Vulnerabilities\" title=\"\" /></a>\n<a href=\"http://waffle.io/bag-man/nodestack\"><img src=\"https://img.shields.io/waffle/label/bag-man/nodestack.svg?label=Backlog&amp;title=Backlog&amp;style=flat-square\" alt=\"Stories in Backlog\" title=\"\" /></a></p>\n\n<h3 id=\"thanksandalternatives\">Thanks, and alternatives</h3>\n\n<p>A lot of credit needs to go to the people at Clock as well as those co-workers mentioned above for developing this stack, so please go check them out. This isn't the most polished boilerplate, as it is rather bare bones and doesn't include an MVC framework so it might not be for you. </p>\n\n<p>One alternative to check out is <a href=\"http://megaboilerplate.com/\">Mega Boilerplate</a>, it allows you to select what technologies you want to use for each part of the stack and bundles it all up for you. My only gripe with it is the generated code isn't ES6 and is a bit oddly laid out. </p>\n\n<p>If you want to ask me any questions feel free to <a href=\"mailto://garland.owen@gmail.com\">email</a> me, or comment on a reddit thread.</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":1,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-16 14:19:29","created_by":1,"updated_at":"2017-04-05 17:24:32","updated_by":1,"published_at":"2017-02-16 15:00:50","published_by":1},{"id":10,"uuid":"c035b75e-71bf-409d-ae75-f59a659ecd3b","title":"Evaluate a URL to get it's domain and port","slug":"evaluate-a-url-to-get-its-domain-and-port","markdown":"In NodeJS if you need to take a URL and extract the domain, protocol and port out, you may have noticed it is harder than it sounds. \n\nWe came across this problem when creating [itsback.at](http://alpha.itsback.at), and this is what we came up with. It currently only checks for http(s) and not other protocols like ftp links. It should return you the domain and port number, defaulting to port 80, if it isn't determinable what the port should be.\n\n```\n'use strict'\n\nconst url = require('url')\n\nfunction getUrl (dataUrl) {\n  if (dataUrl.split('://').length === 1 || dataUrl.startsWith('://')) {\n    dataUrl = `http://${dataUrl.replace('://', '')}`\n  }\n  return dataUrl\n}\n\nlet findUrlKey = (rawUrl) => {\n  rawUrl = getUrl(rawUrl)\n\n  let inputUrl = url.parse(rawUrl)\n    , domain = inputUrl.hostname || inputUrl.pathname.split('/')[0]\n    , protocol = inputUrl.protocol || 'http'\n    , port = inputUrl.port || (protocol.indexOf('https') > -1 ? '443' : '80')\n\n  return domain + ':' + port\n}\n\nmodule.exports = findUrlKey\n```\n\nWe did this in a test driven manner and the tests demonstrate quite clearly what this can and can't do. It isn't perfect, and there are some odd edge cases, although it could easily be expanded to include other protocols for example.\n\n```\nconst assert = require('assert')\n    , findUrlKey = require('../lib/find-url-key')\n    , fixtures =\n      [ { url: 'http://google.com', result: 'google.com:80' }\n      , { url: 'https://google.com', result: 'google.com:443' }\n      , { url: 'https://google.com:3000', result: 'google.com:3000' }\n      , { url: 'http://google.com:3000', result: 'google.com:3000' }\n      , { url: 'http://google.com:3000/path', result: 'google.com:3000' }\n      , { url: 'http://google.com:3000', result: 'google.com:3000' }\n      , { url: 'google.com', result: 'google.com:80' }\n      , { url: 'google.com/path', result: 'google.com:80' }\n      , { url: 'google.com:3000/path', result: 'google.com:3000' }\n      , { url: 'google.com:3000', result: 'google.com:3000' }\n      , { url: '://google.com:3000', result: 'google.com:3000' }\n      , { url: '://google.com', result: 'google.com:80' }\n      , { url: 'ftp://google.com:3000', result: 'google.com:3000' }\n      , { url: 'ftp://google.com', result: 'google.com:80' }\n      ]\n\ndescribe('Test URL parsing logic', () => {\n  fixtures.forEach((fixture) => {\n    it('should return: ' + JSON.stringify(fixture.result), (done) => {\n      assert.deepEqual(findUrlKey(fixture.url), fixture.result, 'incorrect domain or port')\n      done()\n    })\n  })\n})\n```\n\n:wq","mobiledoc":null,"html":"<p>In NodeJS if you need to take a URL and extract the domain, protocol and port out, you may have noticed it is harder than it sounds. </p>\n\n<p>We came across this problem when creating <a href=\"http://alpha.itsback.at\">itsback.at</a>, and this is what we came up with. It currently only checks for http(s) and not other protocols like ftp links. It should return you the domain and port number, defaulting to port 80, if it isn't determinable what the port should be.</p>\n\n<pre><code>'use strict'\n\nconst url = require('url')\n\nfunction getUrl (dataUrl) {  \n  if (dataUrl.split('://').length === 1 || dataUrl.startsWith('://')) {\n    dataUrl = `http://${dataUrl.replace('://', '')}`\n  }\n  return dataUrl\n}\n\nlet findUrlKey = (rawUrl) =&gt; {  \n  rawUrl = getUrl(rawUrl)\n\n  let inputUrl = url.parse(rawUrl)\n    , domain = inputUrl.hostname || inputUrl.pathname.split('/')[0]\n    , protocol = inputUrl.protocol || 'http'\n    , port = inputUrl.port || (protocol.indexOf('https') &gt; -1 ? '443' : '80')\n\n  return domain + ':' + port\n}\n\nmodule.exports = findUrlKey  \n</code></pre>\n\n<p>We did this in a test driven manner and the tests demonstrate quite clearly what this can and can't do. It isn't perfect, and there are some odd edge cases, although it could easily be expanded to include other protocols for example.</p>\n\n<pre><code>const assert = require('assert')  \n    , findUrlKey = require('../lib/find-url-key')\n    , fixtures =\n      [ { url: 'http://google.com', result: 'google.com:80' }\n      , { url: 'https://google.com', result: 'google.com:443' }\n      , { url: 'https://google.com:3000', result: 'google.com:3000' }\n      , { url: 'http://google.com:3000', result: 'google.com:3000' }\n      , { url: 'http://google.com:3000/path', result: 'google.com:3000' }\n      , { url: 'http://google.com:3000', result: 'google.com:3000' }\n      , { url: 'google.com', result: 'google.com:80' }\n      , { url: 'google.com/path', result: 'google.com:80' }\n      , { url: 'google.com:3000/path', result: 'google.com:3000' }\n      , { url: 'google.com:3000', result: 'google.com:3000' }\n      , { url: '://google.com:3000', result: 'google.com:3000' }\n      , { url: '://google.com', result: 'google.com:80' }\n      , { url: 'ftp://google.com:3000', result: 'google.com:3000' }\n      , { url: 'ftp://google.com', result: 'google.com:80' }\n      ]\n\ndescribe('Test URL parsing logic', () =&gt; {  \n  fixtures.forEach((fixture) =&gt; {\n    it('should return: ' + JSON.stringify(fixture.result), (done) =&gt; {\n      assert.deepEqual(findUrlKey(fixture.url), fixture.result, 'incorrect domain or port')\n      done()\n    })\n  })\n})\n</code></pre>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-16 16:13:52","created_by":1,"updated_at":"2017-02-20 15:08:37","updated_by":1,"published_at":"2017-02-16 16:23:46","published_by":1},{"id":11,"uuid":"43c4f13d-6cf5-440d-a14a-90cb7b02ea23","title":"[Project Log #2] A better understanding of the task at hand","slug":"project-log-2-a-better-understanding-of-the-task-at-hand","markdown":"Today I was able to meet with two of the researchers who are studying the yeasts that I will be working with. It was great to finally meet them, although they said a lot of long scary words, but were very reassuring!\n\nTheir research has been looking at three species of yeast, *Candida Tropicalis*, *Candida Boidinii*, and *Candida Shehatae*. *Candida Tropicalis* is very good at metabolising Arabinose & Xylose, however the two conflict and the end product isn't that useful. *Candida Boidinii* doesn't process Arabinose, for some unknown reason, but does metabolise Xylose just at a much slower rate. \n\nIf they can figure out what genetics cause *Candida Boidinii* to not react with Arabinose, and then modify *Candida Tropicalis* to have the same characteristics, then they would be able to produce Xylitol, an anti-bacterial sugar, cheaper and easier than before. One other exciting possibility is using it to create an artificial sweetener that can be used by diabetics.\n\n### How do we find this out? \nThe data I have been provided is sequenced and assembled [contigs](https://en.wikipedia.org/wiki/Contig), which are essentially random strings of DNA taken from the samples, for each of the three species. \n\nMy task will be to run analytical tools to compare these contigs against the known genes found in the NCBI non-redundant database. From there we can compare what genes are present in each of the species, and hopefully highlight any differences found. \n\nI'm still a little concerned about this stage of the process as there is a lot of knowledge that I need to extract from my tutors head, but I'm feeling positive that I'm on the right track to understanding the bits I need to. \n\n### What then? \nThe part of the project that I will feel the most comfortable in and be able to harness my skill set in, will be once we have the data in a database and ready to present in a meaningful way. \n\nThe plan at the moment is to produce a website for the researchers that will allow them to search, browse and compare genes between the species, I'm not too worried about this as there is already [database schema's](http://gmod.org/wiki/Main_Page) available as well as JavaScript libraries for [representing](https://github.com/hammerlab/pileup.js/) the data.\n\n","mobiledoc":null,"html":"<p>Today I was able to meet with two of the researchers who are studying the yeasts that I will be working with. It was great to finally meet them, although they said a lot of long scary words, but were very reassuring!</p>\n\n<p>Their research has been looking at three species of yeast, <em>Candida Tropicalis</em>, <em>Candida Boidinii</em>, and <em>Candida Shehatae</em>. <em>Candida Tropicalis</em> is very good at metabolising Arabinose &amp; Xylose, however the two conflict and the end product isn't that useful. <em>Candida Boidinii</em> doesn't process Arabinose, for some unknown reason, but does metabolise Xylose just at a much slower rate. </p>\n\n<p>If they can figure out what genetics cause <em>Candida Boidinii</em> to not react with Arabinose, and then modify <em>Candida Tropicalis</em> to have the same characteristics, then they would be able to produce Xylitol, an anti-bacterial sugar, cheaper and easier than before. One other exciting possibility is using it to create an artificial sweetener that can be used by diabetics.</p>\n\n<h3 id=\"howdowefindthisout\">How do we find this out?</h3>\n\n<p>The data I have been provided is sequenced and assembled <a href=\"https://en.wikipedia.org/wiki/Contig\">contigs</a>, which are essentially random strings of DNA taken from the samples, for each of the three species. </p>\n\n<p>My task will be to run analytical tools to compare these contigs against the known genes found in the NCBI non-redundant database. From there we can compare what genes are present in each of the species, and hopefully highlight any differences found. </p>\n\n<p>I'm still a little concerned about this stage of the process as there is a lot of knowledge that I need to extract from my tutors head, but I'm feeling positive that I'm on the right track to understanding the bits I need to. </p>\n\n<h3 id=\"whatthen\">What then?</h3>\n\n<p>The part of the project that I will feel the most comfortable in and be able to harness my skill set in, will be once we have the data in a database and ready to present in a meaningful way. </p>\n\n<p>The plan at the moment is to produce a website for the researchers that will allow them to search, browse and compare genes between the species, I'm not too worried about this as there is already <a href=\"http://gmod.org/wiki/Main_Page\">database schema's</a> available as well as JavaScript libraries for <a href=\"https://github.com/hammerlab/pileup.js/\">representing</a> the data.</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-17 14:25:51","created_by":1,"updated_at":"2017-03-03 13:02:54","updated_by":1,"published_at":"2017-03-03 13:02:29","published_by":1},{"id":12,"uuid":"78618715-c45c-408f-a632-56251654eda4","title":"Solving reddits missing features with simple PRAW scripts","slug":"solving-reddits-missing-features-with-simple-praw-scripts","markdown":"I love reddit, and let's be honest I'm probably a bit of an addict. When you come to use the site a lot, you will end up noticing that it is missing a few key features. \n\nThankfully with a little bit of Python and the amazing PRAW (Python Reddit API Wrapper) library, you can solve these problems really quickly.\n\n### Search saved links\nHave you ever wanted to search for that funny cat picture you saved a year ago which has suddenly become relevant to your current situation? \n\nWell reddit doesn't let you. You can go to [your saved links](http://reddit.com/u/m/saved), and then look through 25 posts at a time, having to click next each time. Or if you are the lucky owner of reddit gold you can filter by subreddit, which still isn't much use if you know what you are looking for, but not which subreddit.\n\nThis was frustrating me, so I wrote a small script to allow me to search through my saved links. It is a little slow as it gets all 1000 posts each time it runs, however as I run it so infrequently I don't mind waiting!\n\nThe script uses docopt and PRAW so you will need to install those via pip. This can be done with `pip install --user praw docopt`. The [repo](https://github.com/bag-man/savedLinks) has a requirements.txt if you find that easier.\n\n```\n\"\"\"\nUsage:\n  savedLinks [options]\n\nOptions:\n  -t, --title TITLE     Search for links based on link title\n  -d, --domain DOMAIN   Search for links from a certain domain\n  -r, --reddit REDDIT   Search for links based on subreddit\n\"\"\"\n\nfrom docopt import docopt\nimport praw\nimport sys\n\nif __name__ == \"__main__\":\n    args = docopt(__doc__)\n\ncriteria = sum(1 for v in args.values() if v is not None)\n\nif criteria == 0:\n    sys.exit(__doc__)\n\nr = praw.Reddit(user_agent='savedSearch',\n                client_id='OkDyg4-hOs-TbQ',\n                client_secret='******************',\n                username='Midasx',\n                password='**********',)\n\nfor post in r.redditor('Midasx').saved(limit=None):\n    count = 0\n    if not hasattr(post, 'domain'):\n        continue  # Filter out saved comments\n\n    if args['--domain']:\n        if args['--domain'].lower() == post.domain:\n            count += 1\n\n    if args['--reddit']:\n        if args['--reddit'].lower() == post.subreddit.display_name.lower():\n            count += 1\n\n    if args['--title']:\n        if args['--title'].lower() in post.title.lower():\n            count += 1\n\n    if count == criteria:\n        print(post.shortlink, \" \", post.title)\n```\n\nTo get this running you will need to make an app on your reddit account. Just go to [your apps](https://www.reddit.com/prefs/apps/), and hit `create another app...` then give it a name and a redirect URL (Can be anything, we aren't using it), then make sure to select that it is a Script for personal use.\n\n![Search results](/content/images/2017/02/shot-6.png)\n\n### Notifications for small subreddits\nIf you are really interested in a niche subreddit, it would be nice to know when someone posts there. A lot of my smaller subscriptions have posts go unanswered just because no one checks the sub frequently due to its inactivity. \n\nCurrently reddit doesn't offer a way to get alerted when a new post is made in a subreddit so that is why I came up with this nice [little bot](https://github.com/bag-man/NewPost) to do it for you. It only took an hour to write, and appears to work quite nicely. Once setup it will watch subreddits of your choice and PM you with a link to the new post when one is made.\n\n```\nimport sys\nimport praw\nimport time\n\nuser = 'Midasx'\nreddits = ['vim']\nseen = []\n\nr = praw.Reddit(user_agent='NewPost',\n                client_id='RGtz43e2ZuuuoA',\n                client_secret='*******************',\n                username='NewPostAlert',\n                password='***********',)\n\nprint(\"Logged in\")\n\nfirst = True\n\nwhile True:\n    try:\n        for sub in reddits:\n            for post in r.subreddit(sub).new(limit=10):\n                if first is True:\n                    seen.append(post.id)\n                if post.id not in seen:\n                    subject = 'New post in ' + str(post.subreddit)\n                    content = '[' + post.title + '](' + post.shortlink + ')'\n                    r.redditor(user).message(subject, content)\n                    print('New post! Sending PM.')\n                    seen.append(post.id)\n\n        time.sleep(5)\n        first = False\n    except KeyboardInterrupt:\n        print('\\n')\n        sys.exit(0)\n    except Exception as e:\n        print(e)\n```\n\nAgain, as with the saved links script you will need to create an app for a user, this time I decided to create a separate user for the bot as well. \n\nJust edit in the bots details, the user you want to message and the reddits you want it to watch. If I have time in the future I would love to make this an online service where a user can sign up for notifications on subreddits via a third party service. \n\n### Conclusion\nI wish reddit made these features standard and available to everyone, however I am really thankful that the PRAW library is so easy to use. It is a really nice feeling to find a problem in your day to day life, and solve it quickly and simply with a few lines of code!\n\n:wq","mobiledoc":null,"html":"<p>I love reddit, and let's be honest I'm probably a bit of an addict. When you come to use the site a lot, you will end up noticing that it is missing a few key features. </p>\n\n<p>Thankfully with a little bit of Python and the amazing PRAW (Python Reddit API Wrapper) library, you can solve these problems really quickly.</p>\n\n<h3 id=\"searchsavedlinks\">Search saved links</h3>\n\n<p>Have you ever wanted to search for that funny cat picture you saved a year ago which has suddenly become relevant to your current situation? </p>\n\n<p>Well reddit doesn't let you. You can go to <a href=\"http://reddit.com/u/m/saved\">your saved links</a>, and then look through 25 posts at a time, having to click next each time. Or if you are the lucky owner of reddit gold you can filter by subreddit, which still isn't much use if you know what you are looking for, but not which subreddit.</p>\n\n<p>This was frustrating me, so I wrote a small script to allow me to search through my saved links. It is a little slow as it gets all 1000 posts each time it runs, however as I run it so infrequently I don't mind waiting!</p>\n\n<p>The script uses docopt and PRAW so you will need to install those via pip. This can be done with <code>pip install --user praw docopt</code>. The <a href=\"https://github.com/bag-man/savedLinks\">repo</a> has a requirements.txt if you find that easier.</p>\n\n<pre><code>\"\"\"\nUsage:  \n  savedLinks [options]\n\nOptions:  \n  -t, --title TITLE     Search for links based on link title\n  -d, --domain DOMAIN   Search for links from a certain domain\n  -r, --reddit REDDIT   Search for links based on subreddit\n\"\"\"\n\nfrom docopt import docopt  \nimport praw  \nimport sys\n\nif __name__ == \"__main__\":  \n    args = docopt(__doc__)\n\ncriteria = sum(1 for v in args.values() if v is not None)\n\nif criteria == 0:  \n    sys.exit(__doc__)\n\nr = praw.Reddit(user_agent='savedSearch',  \n                client_id='OkDyg4-hOs-TbQ',\n                client_secret='******************',\n                username='Midasx',\n                password='**********',)\n\nfor post in r.redditor('Midasx').saved(limit=None):  \n    count = 0\n    if not hasattr(post, 'domain'):\n        continue  # Filter out saved comments\n\n    if args['--domain']:\n        if args['--domain'].lower() == post.domain:\n            count += 1\n\n    if args['--reddit']:\n        if args['--reddit'].lower() == post.subreddit.display_name.lower():\n            count += 1\n\n    if args['--title']:\n        if args['--title'].lower() in post.title.lower():\n            count += 1\n\n    if count == criteria:\n        print(post.shortlink, \" \", post.title)\n</code></pre>\n\n<p>To get this running you will need to make an app on your reddit account. Just go to <a href=\"https://www.reddit.com/prefs/apps/\">your apps</a>, and hit <code>create another app...</code> then give it a name and a redirect URL (Can be anything, we aren't using it), then make sure to select that it is a Script for personal use.</p>\n\n<p><img src=\"/content/images/2017/02/shot-6.png\" alt=\"Search results\" /></p>\n\n<h3 id=\"notificationsforsmallsubreddits\">Notifications for small subreddits</h3>\n\n<p>If you are really interested in a niche subreddit, it would be nice to know when someone posts there. A lot of my smaller subscriptions have posts go unanswered just because no one checks the sub frequently due to its inactivity. </p>\n\n<p>Currently reddit doesn't offer a way to get alerted when a new post is made in a subreddit so that is why I came up with this nice <a href=\"https://github.com/bag-man/NewPost\">little bot</a> to do it for you. It only took an hour to write, and appears to work quite nicely. Once setup it will watch subreddits of your choice and PM you with a link to the new post when one is made.</p>\n\n<pre><code>import sys  \nimport praw  \nimport time\n\nuser = 'Midasx'  \nreddits = ['vim']  \nseen = []\n\nr = praw.Reddit(user_agent='NewPost',  \n                client_id='RGtz43e2ZuuuoA',\n                client_secret='*******************',\n                username='NewPostAlert',\n                password='***********',)\n\nprint(\"Logged in\")\n\nfirst = True\n\nwhile True:  \n    try:\n        for sub in reddits:\n            for post in r.subreddit(sub).new(limit=10):\n                if first is True:\n                    seen.append(post.id)\n                if post.id not in seen:\n                    subject = 'New post in ' + str(post.subreddit)\n                    content = '[' + post.title + '](' + post.shortlink + ')'\n                    r.redditor(user).message(subject, content)\n                    print('New post! Sending PM.')\n                    seen.append(post.id)\n\n        time.sleep(5)\n        first = False\n    except KeyboardInterrupt:\n        print('\\n')\n        sys.exit(0)\n    except Exception as e:\n        print(e)\n</code></pre>\n\n<p>Again, as with the saved links script you will need to create an app for a user, this time I decided to create a separate user for the bot as well. </p>\n\n<p>Just edit in the bots details, the user you want to message and the reddits you want it to watch. If I have time in the future I would love to make this an online service where a user can sign up for notifications on subreddits via a third party service. </p>\n\n<h3 id=\"conclusion\">Conclusion</h3>\n\n<p>I wish reddit made these features standard and available to everyone, however I am really thankful that the PRAW library is so easy to use. It is a really nice feeling to find a problem in your day to day life, and solve it quickly and simply with a few lines of code!</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-20 11:50:51","created_by":1,"updated_at":"2017-02-25 14:25:09","updated_by":1,"published_at":"2017-02-20 12:50:00","published_by":1},{"id":13,"uuid":"25e7419c-a1f1-426c-9372-9d41161e7d2a","title":"[Project Log #3] Pipeline for annotating DNA contigs","slug":"project-log-3-pipeline-for-annotating-dna-contigs","markdown":"This is the set of steps I have followed in an attempt to annotate the data I have been given, and put it into a database. At the moment is is almost entirely a manual task, but if the scope for my project allows I would like to make this into a fully automated process that is compatible with the web front end that I produce. \n\n## Raw contigs\nFirst set of data is the reads from the sequencer, assembled into many contigs.\n\nThis produces `candida_boidinii.fa`.\n\n## Diamond blast against NCBI non-redundant database\nSecond set of data is generated by using diamond to compare the contigs you have against the nr database to find known genes.\n\n```\n./diamond makedb --in nr -d nr_ref\n./diamond blastx -d nr_ref.dmnd -q candida_boidinii.fa -o blastx_nr_boidinii.m8 -p 8\n```\n\nThis produces `blastx_nr_boidinii.m8`.\n\n## Select best matches from blast\nUsing awk pull out only the best matches from diamond. I need a proper bioinformatician to tell me if this is okay or not.\n\n```\nawk '!_[$1]++ {print}' blastx_nr_boidinii.m8 > boidinii_best.m8\n```\nThis produces `boidinii_best.m8`.\n\n##  Get uniprot & Kegg IDs and proteins\nUse awk to get the list of RefSeq protein IDs from the blast results\n\n```\nawk '{print $2}' boidinii_best.m8 | xclip\n```\n\nThen paste it into the [uniprot look up](http://www.uniprot.org/uploadlists/) and search for RefSeq Protein -> UniProtKB \n\nDownload the Mapping Table file, to get a list of the IDs that correspond to uniprot IDs.\n\nAlso download the fasta format of all the proteins found.\n\nThis produces `boidinii_uniprot.fa` & `boidinii_uniprot_ids.lst`.\n\nTake the uniprot ids and get the conversion to kegg Id's in the same way. This produces `boidinii_kegg_ids.lst`.\n\n## Merge the data into a working file\nUsing Vim macro's it is simple to combine the found data into a copy of the original fasta file.\n\nThe gene is now annotated with the original scaffold, the blast result, and the uniprot & kegg ID.\n\n```\n>C76265 63.0 | XP_002553495.1 23.7  219 154 5 696 1331  25  237 4.1e-05 58.9 | C5DFV2 | lth:KLTH0D18194g\nAAAAAAAAAAAAATGTTCAGTCAAAAATAAGCTAATTTACCGTACAATGGCATGCATATGCGACAAGGTTCTTTTTTTCTGTTGTTTAGCAAATGCAGTA\nAACCAGTGGTTATACATTCATCATTAGGTGGTACTCTAAATCTGTCTTTATAATCCATCTTTTATCCATAAGTGAAGCTGAAAAGGCTGAAAGTCCTTTT\n```\n\nThis produces `boidinii_working.fa`.\n\n## Create a database with the found data\nNow we have two files that need to be ingested into a database. The `boidinii_working.fa` & `boidinii_uniprot.fa` files should contain all the data that the website needs. \n\nI have created a quick and nasty script to put this data into MongoDB. \n\n```\nconst fasta2json = require('fasta2json')\n    , MongoClient = require('mongodb').MongoClient\n    , url = 'mongodb://localhost:27017/candida'\n\nlet proteins = fasta2json.ReadFasta('../data/boidinii/boidinii_uniprot.fa')\n  , species = []\n\nfasta2json.ParseFasta = (str) => {\n  let fasta = []\n    , seqs = str.split('>')\n\n  for (let i = 1; i < seqs.length; i++) {\n    seqs[i] = seqs[i].replace(/\\r/g, '')\n\n    let seq = {}\n      , fas = seqs[i].split('\\n')\n      , head = fas[0]\n\n    seq.contig = head.split('|')[0].trim()\n    seq.blast = head.split('|')[1] || 'No blast result'\n    seq.uniprot = head.split('|')[2] || 'No uniprot match'\n    seq.kegg = head.split('|')[3] || 'No kegg match'\n    seq.blast = seq.blast.trim()\n    seq.uniprot = seq.uniprot.trim()\n    seq.kegg = seq.kegg.trim()\n    seq.sequence = ''\n\n    for (let j = 1; j < fas.length; j++) {\n      seq.sequence = seq.sequence + fas[j]\n    }\n\n    seq.protein = proteins.filter((obj) => {\n      let proteinId = obj.head.split('|')[1]\n      return proteinId === seq.uniprot\n    })[0] || 'No uniprot match'\n\n    fasta.push(seq)\n  }\n\n  return fasta\n}\n\nspecies = fasta2json.ReadFasta('../data/boidinii/boidinii_working.fa')\n\nMongoClient.connect(url, (err, db) => {\n  if (err) console.log('ERROR: ' + err)\n  let collection = db.collection('boidinii')\n  collection.drop()\n\n  collection.insertMany(species, (err, result) => {\n    if (err) console.log('ERROR: ' + err)\n    db.close()\n  })\n})\n```\nThis gives provides the following data:\n\n```\n> db.boidinii.findOne({ uniprot: \"K4AC16\" })\n{\n        \"_id\" : ObjectId(\"58b96c298660061466e9be53\"),\n        \"contig\" : \"C69229  4.0\",\n        \"blast\" : \"XP_004983205.1 91.7  36  3 0 146 39  311 346 6.1e-09 68.2\",\n        \"uniprot\" : \"K4AC16\",\n        \"kegg\" : \"sita:101760397\",\n        \"sequence\" : \"GAGGATCCTAACAATCTAGTAAGGCTAG...\",\n        \"protein\" : {\n                \"head\" : \"tr|K4AC16|K4AC16_SETIT Uncharacterized protein...\",\n                \"seq\" : \"MNIASAALVFLAHCLLLHRCMGSEA...\"\n        }\n}\n>\n```\n\n\n## Build a web front end\nThen I just have to make a web front end to make this data accessible, including viewing, searching and comparing genes across the species.\n\nThis is my next big challenge. I will create a list of stories for this task.  \n","mobiledoc":null,"html":"<p>This is the set of steps I have followed in an attempt to annotate the data I have been given, and put it into a database. At the moment is is almost entirely a manual task, but if the scope for my project allows I would like to make this into a fully automated process that is compatible with the web front end that I produce. </p>\n\n<h2 id=\"rawcontigs\">Raw contigs</h2>\n\n<p>First set of data is the reads from the sequencer, assembled into many contigs.</p>\n\n<p>This produces <code>candida_boidinii.fa</code>.</p>\n\n<h2 id=\"diamondblastagainstncbinonredundantdatabase\">Diamond blast against NCBI non-redundant database</h2>\n\n<p>Second set of data is generated by using diamond to compare the contigs you have against the nr database to find known genes.</p>\n\n<pre><code>./diamond makedb --in nr -d nr_ref\n./diamond blastx -d nr_ref.dmnd -q candida_boidinii.fa -o blastx_nr_boidinii.m8 -p 8\n</code></pre>\n\n<p>This produces <code>blastx_nr_boidinii.m8</code>.</p>\n\n<h2 id=\"selectbestmatchesfromblast\">Select best matches from blast</h2>\n\n<p>Using awk pull out only the best matches from diamond. I need a proper bioinformatician to tell me if this is okay or not.</p>\n\n<pre><code>awk '!_[$1]++ {print}' blastx_nr_boidinii.m8 &gt; boidinii_best.m8  \n</code></pre>\n\n<p>This produces <code>boidinii_best.m8</code>.</p>\n\n<h2 id=\"getuniprotkeggidsandproteins\">Get uniprot &amp; Kegg IDs and proteins</h2>\n\n<p>Use awk to get the list of RefSeq protein IDs from the blast results</p>\n\n<pre><code>awk '{print $2}' boidinii_best.m8 | xclip  \n</code></pre>\n\n<p>Then paste it into the <a href=\"http://www.uniprot.org/uploadlists/\">uniprot look up</a> and search for RefSeq Protein -> UniProtKB </p>\n\n<p>Download the Mapping Table file, to get a list of the IDs that correspond to uniprot IDs.</p>\n\n<p>Also download the fasta format of all the proteins found.</p>\n\n<p>This produces <code>boidinii_uniprot.fa</code> &amp; <code>boidinii_uniprot_ids.lst</code>.</p>\n\n<p>Take the uniprot ids and get the conversion to kegg Id's in the same way. This produces <code>boidinii_kegg_ids.lst</code>.</p>\n\n<h2 id=\"mergethedataintoaworkingfile\">Merge the data into a working file</h2>\n\n<p>Using Vim macro's it is simple to combine the found data into a copy of the original fasta file.</p>\n\n<p>The gene is now annotated with the original scaffold, the blast result, and the uniprot &amp; kegg ID.</p>\n\n<pre><code>&gt;C76265 63.0 | XP_002553495.1 23.7  219 154 5 696 1331  25  237 4.1e-05 58.9 | C5DFV2 | lth:KLTH0D18194g\nAAAAAAAAAAAAATGTTCAGTCAAAAATAAGCTAATTTACCGTACAATGGCATGCATATGCGACAAGGTTCTTTTTTTCTGTTGTTTAGCAAATGCAGTA  \nAACCAGTGGTTATACATTCATCATTAGGTGGTACTCTAAATCTGTCTTTATAATCCATCTTTTATCCATAAGTGAAGCTGAAAAGGCTGAAAGTCCTTTT  \n</code></pre>\n\n<p>This produces <code>boidinii_working.fa</code>.</p>\n\n<h2 id=\"createadatabasewiththefounddata\">Create a database with the found data</h2>\n\n<p>Now we have two files that need to be ingested into a database. The <code>boidinii_working.fa</code> &amp; <code>boidinii_uniprot.fa</code> files should contain all the data that the website needs. </p>\n\n<p>I have created a quick and nasty script to put this data into MongoDB. </p>\n\n<pre><code>const fasta2json = require('fasta2json')  \n    , MongoClient = require('mongodb').MongoClient\n    , url = 'mongodb://localhost:27017/candida'\n\nlet proteins = fasta2json.ReadFasta('../data/boidinii/boidinii_uniprot.fa')  \n  , species = []\n\nfasta2json.ParseFasta = (str) =&gt; {  \n  let fasta = []\n    , seqs = str.split('&gt;')\n\n  for (let i = 1; i &lt; seqs.length; i++) {\n    seqs[i] = seqs[i].replace(/\\r/g, '')\n\n    let seq = {}\n      , fas = seqs[i].split('\\n')\n      , head = fas[0]\n\n    seq.contig = head.split('|')[0].trim()\n    seq.blast = head.split('|')[1] || 'No blast result'\n    seq.uniprot = head.split('|')[2] || 'No uniprot match'\n    seq.kegg = head.split('|')[3] || 'No kegg match'\n    seq.blast = seq.blast.trim()\n    seq.uniprot = seq.uniprot.trim()\n    seq.kegg = seq.kegg.trim()\n    seq.sequence = ''\n\n    for (let j = 1; j &lt; fas.length; j++) {\n      seq.sequence = seq.sequence + fas[j]\n    }\n\n    seq.protein = proteins.filter((obj) =&gt; {\n      let proteinId = obj.head.split('|')[1]\n      return proteinId === seq.uniprot\n    })[0] || 'No uniprot match'\n\n    fasta.push(seq)\n  }\n\n  return fasta\n}\n\nspecies = fasta2json.ReadFasta('../data/boidinii/boidinii_working.fa')\n\nMongoClient.connect(url, (err, db) =&gt; {  \n  if (err) console.log('ERROR: ' + err)\n  let collection = db.collection('boidinii')\n  collection.drop()\n\n  collection.insertMany(species, (err, result) =&gt; {\n    if (err) console.log('ERROR: ' + err)\n    db.close()\n  })\n})\n</code></pre>\n\n<p>This gives provides the following data:</p>\n\n<pre><code>&gt; db.boidinii.findOne({ uniprot: \"K4AC16\" })\n{\n        \"_id\" : ObjectId(\"58b96c298660061466e9be53\"),\n        \"contig\" : \"C69229  4.0\",\n        \"blast\" : \"XP_004983205.1 91.7  36  3 0 146 39  311 346 6.1e-09 68.2\",\n        \"uniprot\" : \"K4AC16\",\n        \"kegg\" : \"sita:101760397\",\n        \"sequence\" : \"GAGGATCCTAACAATCTAGTAAGGCTAG...\",\n        \"protein\" : {\n                \"head\" : \"tr|K4AC16|K4AC16_SETIT Uncharacterized protein...\",\n                \"seq\" : \"MNIASAALVFLAHCLLLHRCMGSEA...\"\n        }\n}\n&gt;\n</code></pre>\n\n<h2 id=\"buildawebfrontend\">Build a web front end</h2>\n\n<p>Then I just have to make a web front end to make this data accessible, including viewing, searching and comparing genes across the species.</p>\n\n<p>This is my next big challenge. I will create a list of stories for this task.  </p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-24 18:29:38","created_by":1,"updated_at":"2017-03-03 13:16:04","updated_by":1,"published_at":"2017-03-03 13:06:05","published_by":1},{"id":14,"uuid":"2acd5052-2d90-4b85-8611-27d10bfc3dd1","title":"Github style diff in terminal with icdiff","slug":"github-style-diff-in-terminal-with-icdiff","markdown":"Improved Colour Diff or [icdiff](https://github.com/jeffkaufman/icdiff) gives you nice github style diffs in the terminal. It does work well, however getting it to work with git smoothly was a little fiddly so I thought I would share. Just add this to your `~/.gitconfig`.\n\n```\n[alias]\n  showtool = \"!f() { git difftool $1^ $1; }; f\"\n  added = difftool --cached\n[diff]\n  tool = icdiff\n[difftool]\n  prompt = false\n[difftool \"icdiff\"]\n  cmd = /usr/bin/icdiff --line-numbers $LOCAL $REMOTE\n[pager]\n  difftool = true\n```\n\nThis lets your run `git difftool` to view your current unstaged changes, and view commits with `git showtool <commit>`.\n\n![Example output from a show](https://i.imgur.com/p2sJtJy.png)\n\nIf you are used to working with github, this is quite a nice feature as you don't have to adjust your eyes when reviewing a PR, or looking at your local changes. \n\n:wq","mobiledoc":null,"html":"<p>Improved Colour Diff or <a href=\"https://github.com/jeffkaufman/icdiff\">icdiff</a> gives you nice github style diffs in the terminal. It does work well, however getting it to work with git smoothly was a little fiddly so I thought I would share. Just add this to your <code>~/.gitconfig</code>.</p>\n\n<pre><code>[alias]\n  showtool = \"!f() { git difftool $1^ $1; }; f\"\n  added = difftool --cached\n[diff]\n  tool = icdiff\n[difftool]\n  prompt = false\n[difftool \"icdiff\"]\n  cmd = /usr/bin/icdiff --line-numbers $LOCAL $REMOTE\n[pager]\n  difftool = true\n</code></pre>\n\n<p>This lets your run <code>git difftool</code> to view your current unstaged changes, and view commits with <code>git showtool &lt;commit&gt;</code>.</p>\n\n<p><img src=\"https://i.imgur.com/p2sJtJy.png\" alt=\"Example output from a show\" /></p>\n\n<p>If you are used to working with github, this is quite a nice feature as you don't have to adjust your eyes when reviewing a PR, or looking at your local changes. </p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-28 12:40:31","created_by":1,"updated_at":"2017-10-19 15:35:16","updated_by":1,"published_at":"2017-02-28 13:38:41","published_by":1},{"id":15,"uuid":"25cccfad-5044-473c-b194-9cfd4be68973","title":"Vim text objects, extend Vim's natural language!","slug":"vim-text-objects-extend-vims-natural-language-2","markdown":"One of the magical things about Vim is that it uses nouns and verbs to construct an editing language. For example `d` (delete) is a verb and `w` (word) is a noun. By combining a noun & verb we make an edit. Learning this language is key to getting the most out of your editing, I recommend this [great talk](https://www.youtube.com/watch?v=wlR5gYd6um0) by [Chris Toomey](https://twitter.com/christoomey) if this concept is new to you. \n\nOnce you have the basics down you know how to operate on the standard text objects that vim provides you might want to start adding your own. Thankfully there are some excellent plugins to add a whole host of extra objects. What is nice about these extensions to the language is they feel natural and intuitive and don't take much investment to learn at all. \n\n## Examples\nBelow I have listed a few of my favourite extensions with a link to the plugin on Github as well as the Plug line for them. I've also added a very simple \"selling point\" on what the plugins do, but if one piques your interest do check out the full docs on the github page because a lot of these are a lot more powerful than the simple examples I am listing. Also pipe (`|`) denotes cursor position.\n\n## Surround\nThis is probably the most essential plugin for Vim, it feels totally natural and whenever I encounter vanilla Vim I inevitably try to use it forgetting that it isn't there by default!\n\nThis allows us to select `(`surrounding`)` brackets, braces, quotes, etc. So `cs\"'` would change surrounding `\"`'s to `'`'s. \n\n`\"b|ar\"` -> `cs\"'` -> `'bar'`\n\n**Plug ['tpope/surround'](https://github.com/tpope/vim-surround)**\n\n## Targets\nVim allows us to do things like `ci\"` to change text inside quotes, but what about other markers? Targets lets us do this to pretty much everything else that would encapsulate text, such as `,`'s or `+`'s. \n\nFor examples to delete a string from a concatenation `da+`, will remove the string and `+` from under the cursor. \n\n`foo + 'str|ing' + bar` -> `da+` -> `foo + bar`\n\n \n**Plug ['wellle/targets.vim'](https://github.com/wellle/targets.vim)**\n\n\n## Text Object User\nThis isn't in itself a text object, but it provides an easy framework for other users to create their own. This means that it is a pre-requisite for all of the following objects. \n\nI will list my favourite ones, but I recommend you check out [this list](https://github.com/kana/vim-textobj-user/wiki) of all the existing objects that have been created for this framework, as I suspect there are some that might appeal to you and not me!\n\n**Plug '[kana/vim-textobj-user](https://github.com/kana/vim-textobj-user)'**\n\n## Indent\nEver wanted to select a block of code by it's indentation level? Well this allows you to do just that, with `ii` and `ai`. \n\n```\nfoo                      foo\n  b|ar   ->  `dii`  ->   foo\n  bar\nfoo\n```\n**Plug '[kana/vim-textobj-indent](https://github.com/kana/vim-textobj-indent)'**\n\n## Comments\nThis is really handy, especially for multi-line comments. Simply provides `ic` and `ac` to edit comments.\n\n`// Co|mment` -> `cic` -> `// |...`\n\n**Plug '[glts/vim-textobj-comment](https://github.com/glts/vim-textobj-comment)'**\n\n\n## Functions\nThis works for Java and C, however there is most likely a language specific version that will provide the same functionality. I use [this one](https://github.com/thinca/vim-textobj-function-javascript) for JavaScript.\n\nYou can now use `if` and `af` to select the contents of a function or the whole function itself. \n\n```\n void foo() {                    void foo() {\n   return bar;   -> `dif` ->     }\n }\n```\n\n**Plug '[kana/vim-textobj-function](https://github.com/kana/vim-textobj-function)'**\n\n## Conclusions\nThere are *a lot* more of these extensions out there, for your specific language or for that common repeating text pattern that you want to operate on, but can never find a nice way of selecting it. \n\nI usually advise against adding lots of plugins at once, but hopefully with the use of the vim language these should seem like second nature as soon as you are aware of the new objects you can operate on. \n\n:wq","mobiledoc":null,"html":"<p>One of the magical things about Vim is that it uses nouns and verbs to construct an editing language. For example <code>d</code> (delete) is a verb and <code>w</code> (word) is a noun. By combining a noun &amp; verb we make an edit. Learning this language is key to getting the most out of your editing, I recommend this <a href=\"https://www.youtube.com/watch?v=wlR5gYd6um0\">great talk</a> by <a href=\"https://twitter.com/christoomey\">Chris Toomey</a> if this concept is new to you. </p>\n\n<p>Once you have the basics down you know how to operate on the standard text objects that vim provides you might want to start adding your own. Thankfully there are some excellent plugins to add a whole host of extra objects. What is nice about these extensions to the language is they feel natural and intuitive and don't take much investment to learn at all. </p>\n\n<h2 id=\"examples\">Examples</h2>\n\n<p>Below I have listed a few of my favourite extensions with a link to the plugin on Github as well as the Plug line for them. I've also added a very simple \"selling point\" on what the plugins do, but if one piques your interest do check out the full docs on the github page because a lot of these are a lot more powerful than the simple examples I am listing. Also pipe (<code>|</code>) denotes cursor position.</p>\n\n<h2 id=\"surround\">Surround</h2>\n\n<p>This is probably the most essential plugin for Vim, it feels totally natural and whenever I encounter vanilla Vim I inevitably try to use it forgetting that it isn't there by default!</p>\n\n<p>This allows us to select <code>(</code>surrounding<code>)</code> brackets, braces, quotes, etc. So <code>cs\"'</code> would change surrounding <code>\"</code>'s to <code>'</code>'s. </p>\n\n<p><code>\"b|ar\"</code> -> <code>cs\"'</code> -> <code>'bar'</code></p>\n\n<p><strong>Plug <a href=\"https://github.com/tpope/vim-surround\">'tpope/surround'</a></strong></p>\n\n<h2 id=\"targets\">Targets</h2>\n\n<p>Vim allows us to do things like <code>ci\"</code> to change text inside quotes, but what about other markers? Targets lets us do this to pretty much everything else that would encapsulate text, such as <code>,</code>'s or <code>+</code>'s. </p>\n\n<p>For examples to delete a string from a concatenation <code>da+</code>, will remove the string and <code>+</code> from under the cursor. </p>\n\n<p><code>foo + 'str|ing' + bar</code> -> <code>da+</code> -> <code>foo + bar</code></p>\n\n<p><strong>Plug <a href=\"https://github.com/wellle/targets.vim\">'wellle/targets.vim'</a></strong></p>\n\n<h2 id=\"textobjectuser\">Text Object User</h2>\n\n<p>This isn't in itself a text object, but it provides an easy framework for other users to create their own. This means that it is a pre-requisite for all of the following objects. </p>\n\n<p>I will list my favourite ones, but I recommend you check out <a href=\"https://github.com/kana/vim-textobj-user/wiki\">this list</a> of all the existing objects that have been created for this framework, as I suspect there are some that might appeal to you and not me!</p>\n\n<p><strong>Plug '<a href=\"https://github.com/kana/vim-textobj-user\">kana/vim-textobj-user</a>'</strong></p>\n\n<h2 id=\"indent\">Indent</h2>\n\n<p>Ever wanted to select a block of code by it's indentation level? Well this allows you to do just that, with <code>ii</code> and <code>ai</code>. </p>\n\n<pre><code>foo                      foo  \n  b|ar   -&gt;  `dii`  -&gt;   foo\n  bar\nfoo  \n</code></pre>\n\n<p><strong>Plug '<a href=\"https://github.com/kana/vim-textobj-indent\">kana/vim-textobj-indent</a>'</strong></p>\n\n<h2 id=\"comments\">Comments</h2>\n\n<p>This is really handy, especially for multi-line comments. Simply provides <code>ic</code> and <code>ac</code> to edit comments.</p>\n\n<p><code>// Co|mment</code> -> <code>cic</code> -> <code>// |...</code></p>\n\n<p><strong>Plug '<a href=\"https://github.com/glts/vim-textobj-comment\">glts/vim-textobj-comment</a>'</strong></p>\n\n<h2 id=\"functions\">Functions</h2>\n\n<p>This works for Java and C, however there is most likely a language specific version that will provide the same functionality. I use <a href=\"https://github.com/thinca/vim-textobj-function-javascript\">this one</a> for JavaScript.</p>\n\n<p>You can now use <code>if</code> and <code>af</code> to select the contents of a function or the whole function itself. </p>\n\n<pre><code> void foo() {                    void foo() {\n   return bar;   -&gt; `dif` -&gt;     }\n }\n</code></pre>\n\n<p><strong>Plug '<a href=\"https://github.com/kana/vim-textobj-function\">kana/vim-textobj-function</a>'</strong></p>\n\n<h2 id=\"conclusions\">Conclusions</h2>\n\n<p>There are <em>a lot</em> more of these extensions out there, for your specific language or for that common repeating text pattern that you want to operate on, but can never find a nice way of selecting it. </p>\n\n<p>I usually advise against adding lots of plugins at once, but hopefully with the use of the vim language these should seem like second nature as soon as you are aware of the new objects you can operate on. </p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-04-06 21:08:20","created_by":1,"updated_at":"2017-04-07 13:40:54","updated_by":1,"published_at":"2017-04-06 22:12:42","published_by":1},{"id":16,"uuid":"06bf27b8-3de6-49a1-96ad-74a52c36c998","title":"[Project log #4] Finally a chance to build something!","slug":"project-log-4-finally-a-chance-to-build-something","markdown":"After looking at the data I was given, I have been using my limited biology knowledge to come up with theories as to how the data was created, what it means, and how it would best be used. \n\nThis process has taken about three weeks, and in that time I spent good chunk of it lamenting over the blast2go outputs that I had been given. I *thought* they were the key to the puzzle. \n\nHowever it soon became apparent that what I was in fact looking at was just blast results in XML format! Something I could have easily replicated in seconds. Reeling from this I had a good sit down with my tutor and discovered that included in the data was actually all of the annotated proteins, and the coding sequences for them! \n\nI had it all a long! \n\n## Progress\nNow that I knew I had pretty much all the data I needed it was time to start building, but after talking with the researchers about how they use the [candida genome database](http://www.candidagenome.org/), I thought it would be a good idea to ensure that any genes found could be linked to that as a reference. \n\nTo get this data I used diamond to blast the coding sequences I had for each species against the proteins for the very maturely annotated *C. albicans* from the Candida Genome Database.\n\n```\nrm albicans_ref.dmnd\nrm ../shehate/blastx_shehate_codingseq_albicans_proteins.json\nrm ../tropicalis/blastx_tropicalis_codingseq_albicans_proteins.json\nrm ../boidinii/blastx_boidinii_codingseq_albicans_proteins.json\n\n./diamond makedb --in candida_albicans_proteins.fa -d albicans_ref -p 8\n\n./diamond blastx -d albicans_ref.dmnd -q ../shehate/candida_shehate_codingseq.fa -o ../shehate/blastx_shehate_codingseq_albicans_proteins.xml -p 8 -f 5 -k 1\n./diamond blastx -d albicans_ref.dmnd -q ../tropicalis/candida_tropicalis_codingseq.fa -o ../tropicalis/blastx_tropicalis_codingseq_albicans_proteins.xml -p 8 -f 5 -k 1\n./diamond blastx -d albicans_ref.dmnd -q ../boidinii/candida_boidinii_codingseq.fa -o ../boidinii/blastx_boidinii_codingseq_albicans_proteins.xml -p 8 -f 5 -k 1\n\nxml2json ../shehate/blastx_shehate_codingseq_albicans_proteins.xml ../shehate/blastx_shehate_codingseq_albicans_proteins.json\nxml2json ../tropicalis/blastx_tropicalis_codingseq_albicans_proteins.xml ../tropicalis/blastx_tropicalis_codingseq_albicans_proteins.json\nxml2json ../boidinii/blastx_boidinii_codingseq_albicans_proteins.xml ../boidinii/blastx_boidinii_codingseq_albicans_proteins.json\n\nrm ../shehate/blastx_shehate_codingseq_albicans_proteins.xml\nrm ../tropicalis/blastx_tropicalis_codingseq_albicans_proteins.xml\nrm ../boidinii/blastx_boidinii_codingseq_albicans_proteins.xml\n```\n\nThis gave me a link to CGD for almost every gene that had been found in the three species. With some mapping-fu, I was able to create a JSON file that mapped out every ID with a description, name and even a uniprot ID. \n\n```\n{\"CGDID\":\"CAL0000196141\",\"GeneName\":\"AAF1\",\"GeneID\":\"C3_06470W_A\",\"uniprot\":\"P46589\"},\n{\"CGDID\":\"CAL0000194200\",\"GeneName\":\"AAH1\",\"GeneID\":\"C2_06970W_A\",\"uniprot\":\"A0A1D8\"},\n{\"CGDID\":\"CAL0000188193\",\"GeneName\":\"AAP1\",\"GeneID\":\"C3_03990C_A\",\"uniprot\":\"A0A1D8\"},\n{\"CGDID\":\"CAL0000198574\",\"GeneName\":\"AAT1\",\"GeneID\":\"C2_05250C_A\",\"uniprot\":\"A0A1D8\"},\n{\"CGDID\":\"CAL0000174616\",\"GeneName\":\"AAT21\",\"GeneID\":\"CR_07620W_A\",\"uniprot\":\"Q59N40\"},\n{\"CGDID\":\"CAL0000188482\",\"GeneName\":\"AAT22\",\"GeneID\":\"C4_01200C_A\",\"uniprot\":\"A0A1D8\"},\n```\n\nNow the fun can begin... I have all the data in one place!\n\n## Building the database\nI had already created a couple of database importing scripts, but now I had to modify those to accept the new data. This wasn't a trouble at all, but now that I had the coding sequences there was a new challenge. Highlighting the coding sequence in it's place in the contig. \n\nThis was one of the more difficult parts of the project as I had to come up with a way to as efficiently as possible but as accurately as possible select the required areas in the contigs. I played around with a few ideas, but the one that stuck was arguably the most simple.\n\nBy simply taking the first and last twelve bases in the coding sequence and searching for them in the contig then marking their positions, I was able to get over half of them highlighted in the contigs. Not ideal, but to get a better percentage I would have to account for any introns (non-coding regions), or use a more dynamic method of selection which would have made it much less efficient. It only takes about two minutes to import all of the genes from the three species with my chosen method. \n\n## Front end needs some love\nWith the data in the database, my attention turned to the front end of the website. There were three clear tasks:\n\n* Make everything look a little prettier, and work well with mobile\n* Highlight coding regions in contigs in red\n* Copy the coding regions with +/- bases around it to the clipboard\n\nFor the first task I used bootstrap, to layout my form and data tables, it's CSS really makes a project look so much better just by adding it to the project! I also made a logo for the project when my mind wasn't up to much more than colouring!\n\n![Logo](/content/images/2017/04/logo.png)\n\nThen I fixed a lot of the small niggles that you notice when you interact with a webpage a lot. Things like the searches not persisting in the form fields after they have been ran, and a couple of other small UX bugs.\n\n![](/content/images/2017/04/shot.png)\n\nCreating the highlighting proved a little tricky to get done nicely. But with a bit of regex and the use of some span tags it was possible! I did have to go back and change my schema a little to include more information about the positions, but I'm rather pleased with my end solution. \n\nThe next feature I'm really happy with as I don't think the researchers will have expected this, but I bet they will love it (fingers crossed!), I've added a button to copy not only the coding sequence to the clipboard, but if needed +/- a user defined amount of bases up and down stream of the coding sequence in the contig. \n\n## Adjusting the search\nI also felt like the search could do with some love, so I updated how it works. Before it was using a really slow and unelegant solution of a regex for every search field, for example a search might have looked like this: \n\n    { description: /arabinose/i, name: /SEN1/i, uniprot /KVY86X/i }\n\nThis had one upside, which is that you could get a very granular search looking for very specific combinations of fields in the entire database. The issue was though that it is terribly inefficient as it effectively is doing a regex on the whole database every time there is a query!\n\nInstead I opted to use a text search field that had weighted indexes for, name, candida genome id and description. This made one super search field that would return meaningful results based on several strings, without a huge slow down. \n\nThis was then enhanced by adding a regex field for coding sequences, so you can narrow down your search with a sequence of nucleotide bases that you might find in a coding sequence. There is also now an option to filter the results by species, and limit the number of results. \n\n## Conclusions\nI could go into a lot more detail about how this was all done but I think I will save that for my report, which I can hopefully crack on with now as the project appears to be at least in a semi-functional state now. Although I do need to check with my tutor and the researchers that I haven't missed a key feature!\n\n:wq","mobiledoc":null,"html":"<p>After looking at the data I was given, I have been using my limited biology knowledge to come up with theories as to how the data was created, what it means, and how it would best be used. </p>\n\n<p>This process has taken about three weeks, and in that time I spent good chunk of it lamenting over the blast2go outputs that I had been given. I <em>thought</em> they were the key to the puzzle. </p>\n\n<p>However it soon became apparent that what I was in fact looking at was just blast results in XML format! Something I could have easily replicated in seconds. Reeling from this I had a good sit down with my tutor and discovered that included in the data was actually all of the annotated proteins, and the coding sequences for them! </p>\n\n<p>I had it all a long! </p>\n\n<h2 id=\"progress\">Progress</h2>\n\n<p>Now that I knew I had pretty much all the data I needed it was time to start building, but after talking with the researchers about how they use the <a href=\"http://www.candidagenome.org/\">candida genome database</a>, I thought it would be a good idea to ensure that any genes found could be linked to that as a reference. </p>\n\n<p>To get this data I used diamond to blast the coding sequences I had for each species against the proteins for the very maturely annotated <em>C. albicans</em> from the Candida Genome Database.</p>\n\n<pre><code>rm albicans_ref.dmnd  \nrm ../shehate/blastx_shehate_codingseq_albicans_proteins.json  \nrm ../tropicalis/blastx_tropicalis_codingseq_albicans_proteins.json  \nrm ../boidinii/blastx_boidinii_codingseq_albicans_proteins.json\n\n./diamond makedb --in candida_albicans_proteins.fa -d albicans_ref -p 8\n\n./diamond blastx -d albicans_ref.dmnd -q ../shehate/candida_shehate_codingseq.fa -o ../shehate/blastx_shehate_codingseq_albicans_proteins.xml -p 8 -f 5 -k 1\n./diamond blastx -d albicans_ref.dmnd -q ../tropicalis/candida_tropicalis_codingseq.fa -o ../tropicalis/blastx_tropicalis_codingseq_albicans_proteins.xml -p 8 -f 5 -k 1\n./diamond blastx -d albicans_ref.dmnd -q ../boidinii/candida_boidinii_codingseq.fa -o ../boidinii/blastx_boidinii_codingseq_albicans_proteins.xml -p 8 -f 5 -k 1\n\nxml2json ../shehate/blastx_shehate_codingseq_albicans_proteins.xml ../shehate/blastx_shehate_codingseq_albicans_proteins.json  \nxml2json ../tropicalis/blastx_tropicalis_codingseq_albicans_proteins.xml ../tropicalis/blastx_tropicalis_codingseq_albicans_proteins.json  \nxml2json ../boidinii/blastx_boidinii_codingseq_albicans_proteins.xml ../boidinii/blastx_boidinii_codingseq_albicans_proteins.json\n\nrm ../shehate/blastx_shehate_codingseq_albicans_proteins.xml  \nrm ../tropicalis/blastx_tropicalis_codingseq_albicans_proteins.xml  \nrm ../boidinii/blastx_boidinii_codingseq_albicans_proteins.xml  \n</code></pre>\n\n<p>This gave me a link to CGD for almost every gene that had been found in the three species. With some mapping-fu, I was able to create a JSON file that mapped out every ID with a description, name and even a uniprot ID. </p>\n\n<pre><code>{\"CGDID\":\"CAL0000196141\",\"GeneName\":\"AAF1\",\"GeneID\":\"C3_06470W_A\",\"uniprot\":\"P46589\"},\n{\"CGDID\":\"CAL0000194200\",\"GeneName\":\"AAH1\",\"GeneID\":\"C2_06970W_A\",\"uniprot\":\"A0A1D8\"},\n{\"CGDID\":\"CAL0000188193\",\"GeneName\":\"AAP1\",\"GeneID\":\"C3_03990C_A\",\"uniprot\":\"A0A1D8\"},\n{\"CGDID\":\"CAL0000198574\",\"GeneName\":\"AAT1\",\"GeneID\":\"C2_05250C_A\",\"uniprot\":\"A0A1D8\"},\n{\"CGDID\":\"CAL0000174616\",\"GeneName\":\"AAT21\",\"GeneID\":\"CR_07620W_A\",\"uniprot\":\"Q59N40\"},\n{\"CGDID\":\"CAL0000188482\",\"GeneName\":\"AAT22\",\"GeneID\":\"C4_01200C_A\",\"uniprot\":\"A0A1D8\"},\n</code></pre>\n\n<p>Now the fun can begin... I have all the data in one place!</p>\n\n<h2 id=\"buildingthedatabase\">Building the database</h2>\n\n<p>I had already created a couple of database importing scripts, but now I had to modify those to accept the new data. This wasn't a trouble at all, but now that I had the coding sequences there was a new challenge. Highlighting the coding sequence in it's place in the contig. </p>\n\n<p>This was one of the more difficult parts of the project as I had to come up with a way to as efficiently as possible but as accurately as possible select the required areas in the contigs. I played around with a few ideas, but the one that stuck was arguably the most simple.</p>\n\n<p>By simply taking the first and last twelve bases in the coding sequence and searching for them in the contig then marking their positions, I was able to get over half of them highlighted in the contigs. Not ideal, but to get a better percentage I would have to account for any introns (non-coding regions), or use a more dynamic method of selection which would have made it much less efficient. It only takes about two minutes to import all of the genes from the three species with my chosen method. </p>\n\n<h2 id=\"frontendneedssomelove\">Front end needs some love</h2>\n\n<p>With the data in the database, my attention turned to the front end of the website. There were three clear tasks:</p>\n\n<ul>\n<li>Make everything look a little prettier, and work well with mobile</li>\n<li>Highlight coding regions in contigs in red</li>\n<li>Copy the coding regions with +/- bases around it to the clipboard</li>\n</ul>\n\n<p>For the first task I used bootstrap, to layout my form and data tables, it's CSS really makes a project look so much better just by adding it to the project! I also made a logo for the project when my mind wasn't up to much more than colouring!</p>\n\n<p><img src=\"/content/images/2017/04/logo.png\" alt=\"Logo\" /></p>\n\n<p>Then I fixed a lot of the small niggles that you notice when you interact with a webpage a lot. Things like the searches not persisting in the form fields after they have been ran, and a couple of other small UX bugs.</p>\n\n<p><img src=\"/content/images/2017/04/shot.png\" alt=\"\" /></p>\n\n<p>Creating the highlighting proved a little tricky to get done nicely. But with a bit of regex and the use of some span tags it was possible! I did have to go back and change my schema a little to include more information about the positions, but I'm rather pleased with my end solution. </p>\n\n<p>The next feature I'm really happy with as I don't think the researchers will have expected this, but I bet they will love it (fingers crossed!), I've added a button to copy not only the coding sequence to the clipboard, but if needed +/- a user defined amount of bases up and down stream of the coding sequence in the contig. </p>\n\n<h2 id=\"adjustingthesearch\">Adjusting the search</h2>\n\n<p>I also felt like the search could do with some love, so I updated how it works. Before it was using a really slow and unelegant solution of a regex for every search field, for example a search might have looked like this: </p>\n\n<pre><code>{ description: /arabinose/i, name: /SEN1/i, uniprot /KVY86X/i }\n</code></pre>\n\n<p>This had one upside, which is that you could get a very granular search looking for very specific combinations of fields in the entire database. The issue was though that it is terribly inefficient as it effectively is doing a regex on the whole database every time there is a query!</p>\n\n<p>Instead I opted to use a text search field that had weighted indexes for, name, candida genome id and description. This made one super search field that would return meaningful results based on several strings, without a huge slow down. </p>\n\n<p>This was then enhanced by adding a regex field for coding sequences, so you can narrow down your search with a sequence of nucleotide bases that you might find in a coding sequence. There is also now an option to filter the results by species, and limit the number of results. </p>\n\n<h2 id=\"conclusions\">Conclusions</h2>\n\n<p>I could go into a lot more detail about how this was all done but I think I will save that for my report, which I can hopefully crack on with now as the project appears to be at least in a semi-functional state now. Although I do need to check with my tutor and the researchers that I haven't missed a key feature!</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-04-15 02:09:42","created_by":1,"updated_at":"2017-04-15 14:13:10","updated_by":1,"published_at":"2017-04-15 02:34:00","published_by":1},{"id":17,"uuid":"679a035a-26e6-472f-b297-3b3774c1a3c3","title":"If I were standing for office...","slug":"if-i-were-standing-for-office","markdown":"With the general election suddenly looming and seeing how none of the parties running really represent my set of ideals, I thought I would write down what I really want to see represented. \n\nIdeally I would have research conducted on all of these areas and follow their findings. Science comes before tradition. My ill informed policies so far would be:\n\n## ￼Democracy\nAbolish the House of Lords, build a new parliament that is fit for purpose. Implement STV as the method of determining MP's. Hold quarterly non-binding referendums on current issues, ideally utilising technology to make it more accessible. Create a constitution, that includes all human rights as well as higher education, universal healthcare, privacy, free speech, internet access.\n\nLower voting age to 16. \n\n## ￼Crime\nLegalise, tax and regulate all recreational drugs so they are treated the same as alcohol & tobacco. Only place restrictions on opioids, which will require a doctors prescription, and must be taken at a harm reduction clinic in combination with recovery therapy. \n\nFocus incarceration on rehabilitation, similar to Norway.\n\n## ￼Economy\nRemove VAT, as it isn't a proportional tax. Replace it with more and higher tax bands. Attempt a real crack down on tax avoidance. Increase the minimum wage to be level with the living wage. Cap executive pay to Xtimes that of the minimum wage. \n\nBan Zero hour contracts, replace with Xhours minimum contracts. \n\n## ￼Education\nZero tuition fees and grants for students to live. Increase research funding. \n\nTake a Finnish approach to lower education, and teach current social issues and life skills, such as computer literacy, and sex education. Education is the key to solving most problems in society.\n\nRemove faith schools. \n\n## ￼Environment\nInvest heavily in renewable technology, and build nuclear for the near future, until we have a stable and substantial renewable source of energy. Subsidies for EV's and solar.\n\nConsider creating a national battery grid to replace petrol stations. \n\n## ￼Europe\nStay in the EU. Support an EU army.\n\n## ￼Foreign Policy / Defence\nKeep a strong core, but shrink the scale of the army. Work closer with the EU and NATO to become a key piece in a greater force. \n\nStay neutral and not intervene in foreign conflicts where possible. However working with the EU and NATO push for sanctions and even intervention where human rights abuses are happening. \n\n## ￼Health / NHS\nMake universal healthcare a part of a constitution that ensures the NHS gets all the money and resources it needs to function. \n\n## ￼Immigration\nAssess migrants from non EU members and accept them based on our needs. \n\n## ￼Welfare\nReplace benefits with a basic income for all citizens. Smaller administration needs can then focus on those who need help the most. \n\n## Other\nRe-nationalise railways, and other essential services such as water, gas, electric, internet and the postal system. \n\nLegalise and regulate brothels. \n\nEqual paternity and maternity leave.\n\nUniversal childcare.\n\nEnd all mass surveillance, and domestic spying. \n\nChange motorcycle licensing restrictions back to a more sensible approach. They are better for the environment and traffic, and the current system discourages them. \n\nCement and protect the rights of LGBTQ+ people in the constitution. \n\nImpose significant fines, and enforce corrections on media outlets that print objective lies.\n\nThe monarchy dies with the Queen.\n\nAnd one stupid thing that bothers me, tweak current firearms and knife laws to remove [pointless](https://en.wikipedia.org/wiki/Butterfly_knife#Legal_status), [restrictions](http://thefirearmsforum.s3.amazonaws.com/2014/08/155880_a28e72c22d2299a724c889a19d34a066.jpg).","mobiledoc":null,"html":"<p>With the general election suddenly looming and seeing how none of the parties running really represent my set of ideals, I thought I would write down what I really want to see represented. </p>\n\n<p>Ideally I would have research conducted on all of these areas and follow their findings. Science comes before tradition. My ill informed policies so far would be:</p>\n\n<h2 id=\"democracy\">￼Democracy</h2>\n\n<p>Abolish the House of Lords, build a new parliament that is fit for purpose. Implement STV as the method of determining MP's. Hold quarterly non-binding referendums on current issues, ideally utilising technology to make it more accessible. Create a constitution, that includes all human rights as well as higher education, universal healthcare, privacy, free speech, internet access.</p>\n\n<p>Lower voting age to 16. </p>\n\n<h2 id=\"crime\">￼Crime</h2>\n\n<p>Legalise, tax and regulate all recreational drugs so they are treated the same as alcohol &amp; tobacco. Only place restrictions on opioids, which will require a doctors prescription, and must be taken at a harm reduction clinic in combination with recovery therapy. </p>\n\n<p>Focus incarceration on rehabilitation, similar to Norway.</p>\n\n<h2 id=\"economy\">￼Economy</h2>\n\n<p>Remove VAT, as it isn't a proportional tax. Replace it with more and higher tax bands. Attempt a real crack down on tax avoidance. Increase the minimum wage to be level with the living wage. Cap executive pay to Xtimes that of the minimum wage. </p>\n\n<p>Ban Zero hour contracts, replace with Xhours minimum contracts. </p>\n\n<h2 id=\"education\">￼Education</h2>\n\n<p>Zero tuition fees and grants for students to live. Increase research funding. </p>\n\n<p>Take a Finnish approach to lower education, and teach current social issues and life skills, such as computer literacy, and sex education. Education is the key to solving most problems in society.</p>\n\n<p>Remove faith schools. </p>\n\n<h2 id=\"environment\">￼Environment</h2>\n\n<p>Invest heavily in renewable technology, and build nuclear for the near future, until we have a stable and substantial renewable source of energy. Subsidies for EV's and solar.</p>\n\n<p>Consider creating a national battery grid to replace petrol stations. </p>\n\n<h2 id=\"europe\">￼Europe</h2>\n\n<p>Stay in the EU. Support an EU army.</p>\n\n<h2 id=\"foreignpolicydefence\">￼Foreign Policy / Defence</h2>\n\n<p>Keep a strong core, but shrink the scale of the army. Work closer with the EU and NATO to become a key piece in a greater force. </p>\n\n<p>Stay neutral and not intervene in foreign conflicts where possible. However working with the EU and NATO push for sanctions and even intervention where human rights abuses are happening. </p>\n\n<h2 id=\"healthnhs\">￼Health / NHS</h2>\n\n<p>Make universal healthcare a part of a constitution that ensures the NHS gets all the money and resources it needs to function. </p>\n\n<h2 id=\"immigration\">￼Immigration</h2>\n\n<p>Assess migrants from non EU members and accept them based on our needs. </p>\n\n<h2 id=\"welfare\">￼Welfare</h2>\n\n<p>Replace benefits with a basic income for all citizens. Smaller administration needs can then focus on those who need help the most. </p>\n\n<h2 id=\"other\">Other</h2>\n\n<p>Re-nationalise railways, and other essential services such as water, gas, electric, internet and the postal system. </p>\n\n<p>Legalise and regulate brothels. </p>\n\n<p>Equal paternity and maternity leave.</p>\n\n<p>Universal childcare.</p>\n\n<p>End all mass surveillance, and domestic spying. </p>\n\n<p>Change motorcycle licensing restrictions back to a more sensible approach. They are better for the environment and traffic, and the current system discourages them. </p>\n\n<p>Cement and protect the rights of LGBTQ+ people in the constitution. </p>\n\n<p>Impose significant fines, and enforce corrections on media outlets that print objective lies.</p>\n\n<p>The monarchy dies with the Queen.</p>\n\n<p>And one stupid thing that bothers me, tweak current firearms and knife laws to remove <a href=\"https://en.wikipedia.org/wiki/Butterfly_knife#Legal_status\">pointless</a>, <a href=\"http://thefirearmsforum.s3.amazonaws.com/2014/08/155880_a28e72c22d2299a724c889a19d34a066.jpg\">restrictions</a>.</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-04-20 22:24:46","created_by":1,"updated_at":"2017-04-20 23:39:01","updated_by":1,"published_at":"2017-04-20 23:01:22","published_by":1},{"id":18,"uuid":"04fedf36-c210-408b-be9b-16dc34f0b1fd","title":"Everyday Carry","slug":"my-everyday-carry","markdown":"One of my small obsessions and favourite subjects to nerd out on is everyday carry items, or EDC for short. For people like me the idea is that the things you EDC are the things you use most in life, and if you invest in them they can make your life a lot easier and last a lifetime!\n\n## Pocket Carry\nI like to be a minimalist when it comes to what goes in my pockets. I also value titanium over other materials, I've tried out Steel, Copper and Aluminium items but they all have issues. \n\n![Pocket carry](http://i.imgur.com/hA5Lt4t.jpg)\n\n* [Titanium + Brass Custom SAKModder](http://imgur.com/a/mWp6Z) - This is probably my favourite item I own, it is a one off made to order Swiss Army Knife with titanium scales and brass liners. It was made by [SAKModder](https://www.facebook.com/SAKModder/) in Canada. \n* [Zach Wood Micro Ti Pry](https://www.facebook.com/groups/713996752008284/) - This is an unusual tool, it's just a sliver of titanium with a pocket clip that sits in my back pocket. It doesn't have a specific use, but anytime I want to poke, pry or stir something and don't want to risk damaging my SAK it comes in really handy!\n* [SECRID Wallet](https://www.secrid.com/protect-your-cards/) - I had previously had an Alluminium Machine Era Co. wallet, however I was always frustrated by the difficulty to get cards out, and the elastic fraying and the finish wearing off. The SECRID wallet solves all these problems in a slimmer neater package. \n* [u3 Titanium 1GB Sandisk](http://shop.sandisk.com/store/sdiskus/en_US/DisplayProductDetailsPage/CategoryID.13937600/productID.99177600) - 1GB may seem low, but it is enough to put Arch Linux on as well as a bunch of Windows utilities, with 300MB left over! For average office use that is plenty I've found.\n* [Nexus 5](http://www.gsmarena.com/lg_nexus_5-5705.php) - Not pictured, but taking the picture was my trusty Nexus 5. It is getting old now and I've had to replace parts on it quite a few times, I should probably upgrade, but I'm rather attached!\n\n\n## Pouch carry\nFor my less frequently used pocket tools I have a small [Maxpedition Micro](https://www.maxpedition.com/products/Micro-Pocket-Organizer?variant=27868845073) pouch to keep these useful bits all together. \n\n![Pouch insides](http://i.imgur.com/1ugvGU1.jpg)\n\nFrom left to right:\n\n* [Zachwood Pry Bar](https://www.facebook.com/groups/713996752008284/) - Made of A2 steel this does the same job my micro titanium one does, except much much more heavy duty.\n* Bic Lighter - Universally useful, cheap and the most reliable lighter I've had.\n* [Sparrows mini-jim](https://www.sparrowslockpicks.com/product_p/mj.htm) - Small and incredibly useful tool for bypassing unshielded latches.\n* Zip ties - The most useful repair tool! I'm running low actually.\n* [MadBob Carbon Fibre Jacknife](http://www.madbobpicks.co.uk/Carbon-Fibre-Jackknife-p/012.htm) (with home made shim tool) - Locksport is a hobby of mine and this neat little tool makes a nice compact way to carry some picks so that if I ever need to defeat a lock I have something handy. I've actually made another tool for it that is a .015\" think feeler for defeating combination locks. It would be so frustrating to be in a situation where a skill I've spent many hours honing wouldn't be useful!\n* Sharpie - Always useful for making quick notes to people on whatever is laying around.\n* [Thrunite T10T XPL](http://www.thrunite.com/thrunite-t10t-xp-l-max-208-lumen-flashlight/) - This is the old T10T with the good metal clicky tail switch, but with the newer more powerful XPL head!\n* Generic Hex bits + Bit extender - This works in combination with the ZW Pry Bar as it has a hex hole in it. This means I can get loads of leverage behind a bit if I need it. The bit holder has a Phillips and Flat + five sizes of security Torx\n* [Leatherman Charge TTi](http://www.leatherman.com/charge-tti-830682.html) - The undisputed best all round multi-tool, I've had this for many many years and it has yet to fail me!\n\n## Bag carry\nI have a very cool old soviet medics bag that I bought when I visited Red Square in Moscow. I use it for carrying my laptop and pouch.\n\n![Pouch on bag](http://i.imgur.com/6fnzwv8.jpg)\n\nInside you will find:\n\n* Dell Chromebook 11 4GB model - This has been modified to run Arch Linux and is a perfect cheap and effective development machine.\n* Gum & Iburprofen - Always comes in handy but annoyingly consumable!\n* Classic Ray Bans - Bought for my 21st birthday, they are so much cooler than I thought they would be.\n* Logitech Anywhere MX Mouse - The laptops trackpad is very hit or miss which usually isn't a problem as I use the [HJKL for everything](owen.cymru/hjkl-all-the-things/), but occasionally I'm forced to use a mouse so this comes in handy!\n\n![Contents of bag](http://i.imgur.com/HIuIj2g.jpg)\n\n## Conclusions\nThis is quite an odd obsession I admit, but I love pocket tools and making everything as minimal but as functional as possible. Buying high quality items is so much better in the long run too even if it is expensive up front!\n\n:wq\n\n","mobiledoc":null,"html":"<p>One of my small obsessions and favourite subjects to nerd out on is everyday carry items, or EDC for short. For people like me the idea is that the things you EDC are the things you use most in life, and if you invest in them they can make your life a lot easier and last a lifetime!</p>\n\n<h2 id=\"pocketcarry\">Pocket Carry</h2>\n\n<p>I like to be a minimalist when it comes to what goes in my pockets. I also value titanium over other materials, I've tried out Steel, Copper and Aluminium items but they all have issues. </p>\n\n<p><img src=\"http://i.imgur.com/hA5Lt4t.jpg\" alt=\"Pocket carry\" /></p>\n\n<ul>\n<li><a href=\"http://imgur.com/a/mWp6Z\">Titanium + Brass Custom SAKModder</a> - This is probably my favourite item I own, it is a one off made to order Swiss Army Knife with titanium scales and brass liners. It was made by <a href=\"https://www.facebook.com/SAKModder/\">SAKModder</a> in Canada. </li>\n<li><a href=\"https://www.facebook.com/groups/713996752008284/\">Zach Wood Micro Ti Pry</a> - This is an unusual tool, it's just a sliver of titanium with a pocket clip that sits in my back pocket. It doesn't have a specific use, but anytime I want to poke, pry or stir something and don't want to risk damaging my SAK it comes in really handy!</li>\n<li><a href=\"https://www.secrid.com/protect-your-cards/\">SECRID Wallet</a> - I had previously had an Alluminium Machine Era Co. wallet, however I was always frustrated by the difficulty to get cards out, and the elastic fraying and the finish wearing off. The SECRID wallet solves all these problems in a slimmer neater package. </li>\n<li><a href=\"http://shop.sandisk.com/store/sdiskus/en_US/DisplayProductDetailsPage/CategoryID.13937600/productID.99177600\">u3 Titanium 1GB Sandisk</a> - 1GB may seem low, but it is enough to put Arch Linux on as well as a bunch of Windows utilities, with 300MB left over! For average office use that is plenty I've found.</li>\n<li><a href=\"http://www.gsmarena.com/lg_nexus_5-5705.php\">Nexus 5</a> - Not pictured, but taking the picture was my trusty Nexus 5. It is getting old now and I've had to replace parts on it quite a few times, I should probably upgrade, but I'm rather attached!</li>\n</ul>\n\n<h2 id=\"pouchcarry\">Pouch carry</h2>\n\n<p>For my less frequently used pocket tools I have a small <a href=\"https://www.maxpedition.com/products/Micro-Pocket-Organizer?variant=27868845073\">Maxpedition Micro</a> pouch to keep these useful bits all together. </p>\n\n<p><img src=\"http://i.imgur.com/1ugvGU1.jpg\" alt=\"Pouch insides\" /></p>\n\n<p>From left to right:</p>\n\n<ul>\n<li><a href=\"https://www.facebook.com/groups/713996752008284/\">Zachwood Pry Bar</a> - Made of A2 steel this does the same job my micro titanium one does, except much much more heavy duty.</li>\n<li>Bic Lighter - Universally useful, cheap and the most reliable lighter I've had.</li>\n<li><a href=\"https://www.sparrowslockpicks.com/product_p/mj.htm\">Sparrows mini-jim</a> - Small and incredibly useful tool for bypassing unshielded latches.</li>\n<li>Zip ties - The most useful repair tool! I'm running low actually.</li>\n<li><a href=\"http://www.madbobpicks.co.uk/Carbon-Fibre-Jackknife-p/012.htm\">MadBob Carbon Fibre Jacknife</a> (with home made shim tool) - Locksport is a hobby of mine and this neat little tool makes a nice compact way to carry some picks so that if I ever need to defeat a lock I have something handy. I've actually made another tool for it that is a .015\" think feeler for defeating combination locks. It would be so frustrating to be in a situation where a skill I've spent many hours honing wouldn't be useful!</li>\n<li>Sharpie - Always useful for making quick notes to people on whatever is laying around.</li>\n<li><a href=\"http://www.thrunite.com/thrunite-t10t-xp-l-max-208-lumen-flashlight/\">Thrunite T10T XPL</a> - This is the old T10T with the good metal clicky tail switch, but with the newer more powerful XPL head!</li>\n<li>Generic Hex bits + Bit extender - This works in combination with the ZW Pry Bar as it has a hex hole in it. This means I can get loads of leverage behind a bit if I need it. The bit holder has a Phillips and Flat + five sizes of security Torx</li>\n<li><a href=\"http://www.leatherman.com/charge-tti-830682.html\">Leatherman Charge TTi</a> - The undisputed best all round multi-tool, I've had this for many many years and it has yet to fail me!</li>\n</ul>\n\n<h2 id=\"bagcarry\">Bag carry</h2>\n\n<p>I have a very cool old soviet medics bag that I bought when I visited Red Square in Moscow. I use it for carrying my laptop and pouch.</p>\n\n<p><img src=\"http://i.imgur.com/6fnzwv8.jpg\" alt=\"Pouch on bag\" /></p>\n\n<p>Inside you will find:</p>\n\n<ul>\n<li>Dell Chromebook 11 4GB model - This has been modified to run Arch Linux and is a perfect cheap and effective development machine.</li>\n<li>Gum &amp; Iburprofen - Always comes in handy but annoyingly consumable!</li>\n<li>Classic Ray Bans - Bought for my 21st birthday, they are so much cooler than I thought they would be.</li>\n<li>Logitech Anywhere MX Mouse - The laptops trackpad is very hit or miss which usually isn't a problem as I use the <a href=\"owen.cymru/hjkl-all-the-things/\">HJKL for everything</a>, but occasionally I'm forced to use a mouse so this comes in handy!</li>\n</ul>\n\n<p><img src=\"http://i.imgur.com/HIuIj2g.jpg\" alt=\"Contents of bag\" /></p>\n\n<h2 id=\"conclusions\">Conclusions</h2>\n\n<p>This is quite an odd obsession I admit, but I love pocket tools and making everything as minimal but as functional as possible. Buying high quality items is so much better in the long run too even if it is expensive up front!</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-04-22 15:25:43","created_by":1,"updated_at":"2017-04-23 00:12:32","updated_by":1,"published_at":"2017-04-22 16:03:45","published_by":1},{"id":19,"uuid":"a4b8502f-38f1-4623-8ecd-22d581770011","title":"Technical debt has compound interest","slug":"technical-debt-has-compound-interest","markdown":"I was recently tasked with implementing an image processing framework, on a very old node project, where technical debt had never been paid off. \n\nWhen I first started working on this project, I saw a lot of areas that needed improving, modernising and securing; howe","mobiledoc":null,"html":"<p>I was recently tasked with implementing an image processing framework, on a very old node project, where technical debt had never been paid off. </p>\n\n<p>When I first started working on this project, I saw a lot of areas that needed improving, modernising and securing; howe</p>","amp":null,"image":null,"featured":0,"page":0,"status":"draft","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-08-29 08:41:14","created_by":1,"updated_at":"2017-08-29 08:42:52","updated_by":1,"published_at":null,"published_by":null},{"id":20,"uuid":"4aabdd50-37c7-4246-91e6-cca590009817","title":"Halloumi & Mushroom Pie","slug":"pie","markdown":"![pie.jpg](https://lh3.googleusercontent.com/jDuqezarIf-IfQJG46uCvdkMiwTX_dFoMu_biquCw9LYaix0CQJZRehQiQdN4MTpHxgT2OWZ1KWGX_Qdsw2bNeGRQeMaAvyuV5sr__M6GSNmb3TzJJJESyvSxVk74JHBtOImk3V8FBx7bhIT5BQ7C_p2CuBqMkEjjVPKwAc_7pwjjvMH-Z7RFiBY6jSAKgsfkJ9WUXdmJIc-JxY0H3MURNqgd0vneUEUz6pi4i0PpMIdsqz49YiDd4JQlvh9VP4fi8dGfozd75kItnMhVPAVky09-9lfRfEkv01q-35JThHRtxKLVpOQnWh4Igbz0n-Ewi9id2nSZhmCcumCqKFdVu6wEiPBh3VHX9TY7HEBTGOdHiORbShSdG3BkWuCgN7p5LshwppKTx03Hbfe2A6d-QPSl8W0-w5jgjDW7SpXmiRRsXYeBdUuRB0_Y_XosoIhzJeEkQAuzr1ZAaYayiK2jvU5bAK9OWtxQMI1T7bnciylli70f46y3p7sSiBOCDAff_fat-kD9LAqGC46X1hQavRjNg6R_bAKgZr_9Z-bHFKehRtY6W_48uGf-zkY-05wLMRvK7MDIoP9vTElv1U55b0EC8uLkbVBWTOhFHilZrhBnQqAwOagsPGzfS4CqZBWTiE44QwhfJGDNE9J-FF3OyzRZ3WQ5OWa4KH2IyHFBL9oEQ=w912-h684-no)\n\n### Ingredients\n* 2 medium onions\n* 2 medium packs of (different) mushrooms\n* 1 head of garlic\n* 2 red chillies \n* 1 pack of halloumi\n* Flour\n* Oregano\n* Salt\n* Lea & Perrins (Worcestershire Sauce)\n* Pre rolled puff pastry\n* Olive oil\n* Whisky (optional)\n\n### Equipment\n* Big pan (wok even)\n* Pie tray\n\n### Prep\n1. Slice the two onions into thin strands, the idea is to carmelise them, I tend to find thinner longer peices work nicer. \n2. Dice up the head of garlic. \n3. Cut the mushrooms into four or five slices.\n4. Dice the chillies.\n5. Cube the halloumi, 1cm cubes.\n6. Preheat oven to 200C\n\n### Method\n1. Heat up a litte oil in a pan on low heat and add the garlic and onions. \n2. Let them slowly brown for a while, then add some whisky to the pan to deglaze it and add flavour. \n3. Now add the chilli and mushrooms. \n4. Season with salt and orgeano, don't go too crazy, but make sure there is enough to get around them all. \n5. The water from the mushrooms will start to come out, you may want to turn up the heat a little to speed this up. \n6. Once it has reduced a bit, add a healthy dash of Worcestershire sauce, and the halloumi. \n7. Reduce the heat and let to simmer, there should be a great tasting sauce now. \n8. While this has been cooking you can roll out your pastry using some flour and line a pie tin with it, make sure you have enough left for the pie lid!\n9. Once the halloumi is sufficiently goopy looking, give it one last mix and pour into the pie tin.\n10. Put the pie lid on and seal around the edges, stab with a fork to avoid explosions. \n11. Put in the oven for 20 minues or so. \n\n### Serving\n1. Once out of the oven, try to eat whille still hot otherwise the halloumi will harden.\n2. Maybe Mozarella would be more suited, but I think you wouldn't get the balls of cheese effect.\n3. If you lined your pie tin correctly you should be able to lift out the whole pie. \n4. Should give four generous portions.","mobiledoc":null,"html":"<p><img src=\"https://lh3.googleusercontent.com/jDuqezarIf-IfQJG46uCvdkMiwTX_dFoMu_biquCw9LYaix0CQJZRehQiQdN4MTpHxgT2OWZ1KWGX_Qdsw2bNeGRQeMaAvyuV5sr__M6GSNmb3TzJJJESyvSxVk74JHBtOImk3V8FBx7bhIT5BQ7C_p2CuBqMkEjjVPKwAc_7pwjjvMH-Z7RFiBY6jSAKgsfkJ9WUXdmJIc-JxY0H3MURNqgd0vneUEUz6pi4i0PpMIdsqz49YiDd4JQlvh9VP4fi8dGfozd75kItnMhVPAVky09-9lfRfEkv01q-35JThHRtxKLVpOQnWh4Igbz0n-Ewi9id2nSZhmCcumCqKFdVu6wEiPBh3VHX9TY7HEBTGOdHiORbShSdG3BkWuCgN7p5LshwppKTx03Hbfe2A6d-QPSl8W0-w5jgjDW7SpXmiRRsXYeBdUuRB0_Y_XosoIhzJeEkQAuzr1ZAaYayiK2jvU5bAK9OWtxQMI1T7bnciylli70f46y3p7sSiBOCDAff_fat-kD9LAqGC46X1hQavRjNg6R_bAKgZr_9Z-bHFKehRtY6W_48uGf-zkY-05wLMRvK7MDIoP9vTElv1U55b0EC8uLkbVBWTOhFHilZrhBnQqAwOagsPGzfS4CqZBWTiE44QwhfJGDNE9J-FF3OyzRZ3WQ5OWa4KH2IyHFBL9oEQ=w912-h684-no\" alt=\"pie.jpg\" /></p>\n\n<h3 id=\"ingredients\">Ingredients</h3>\n\n<ul>\n<li>2 medium onions</li>\n<li>2 medium packs of (different) mushrooms</li>\n<li>1 head of garlic</li>\n<li>2 red chillies </li>\n<li>1 pack of halloumi</li>\n<li>Flour</li>\n<li>Oregano</li>\n<li>Salt</li>\n<li>Lea &amp; Perrins (Worcestershire Sauce)</li>\n<li>Pre rolled puff pastry</li>\n<li>Olive oil</li>\n<li>Whisky (optional)</li>\n</ul>\n\n<h3 id=\"equipment\">Equipment</h3>\n\n<ul>\n<li>Big pan (wok even)</li>\n<li>Pie tray</li>\n</ul>\n\n<h3 id=\"prep\">Prep</h3>\n\n<ol>\n<li>Slice the two onions into thin strands, the idea is to carmelise them, I tend to find thinner longer peices work nicer.  </li>\n<li>Dice up the head of garlic.  </li>\n<li>Cut the mushrooms into four or five slices.  </li>\n<li>Dice the chillies.  </li>\n<li>Cube the halloumi, 1cm cubes.  </li>\n<li>Preheat oven to 200C</li>\n</ol>\n\n<h3 id=\"method\">Method</h3>\n\n<ol>\n<li>Heat up a litte oil in a pan on low heat and add the garlic and onions.  </li>\n<li>Let them slowly brown for a while, then add some whisky to the pan to deglaze it and add flavour.  </li>\n<li>Now add the chilli and mushrooms.  </li>\n<li>Season with salt and orgeano, don't go too crazy, but make sure there is enough to get around them all.  </li>\n<li>The water from the mushrooms will start to come out, you may want to turn up the heat a little to speed this up.  </li>\n<li>Once it has reduced a bit, add a healthy dash of Worcestershire sauce, and the halloumi.  </li>\n<li>Reduce the heat and let to simmer, there should be a great tasting sauce now.  </li>\n<li>While this has been cooking you can roll out your pastry using some flour and line a pie tin with it, make sure you have enough left for the pie lid!  </li>\n<li>Once the halloumi is sufficiently goopy looking, give it one last mix and pour into the pie tin.  </li>\n<li>Put the pie lid on and seal around the edges, stab with a fork to avoid explosions.  </li>\n<li>Put in the oven for 20 minues or so. </li>\n</ol>\n\n<h3 id=\"serving\">Serving</h3>\n\n<ol>\n<li>Once out of the oven, try to eat whille still hot otherwise the halloumi will harden.  </li>\n<li>Maybe Mozarella would be more suited, but I think you wouldn't get the balls of cheese effect.  </li>\n<li>If you lined your pie tin correctly you should be able to lift out the whole pie.  </li>\n<li>Should give four generous portions.</li>\n</ol>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-09-05 21:10:12","created_by":1,"updated_at":"2017-09-05 22:16:46","updated_by":1,"published_at":"2017-09-05 21:10:37","published_by":1},{"id":21,"uuid":"8d586a0f-ac3a-4b28-aece-5242cdf84e25","title":"Reflection time: What is it, how do you measure it, and how can it be improved?","slug":"reflection-time","markdown":"As I wait for a docker container to restart for the 1001st time, an artifact of poor design decisions made on an old project I have been lumbered with, I can't help but feel the need to try to define in more clear terms what I have been referring to as \"reflection time\". \n\nReflection time is simply the time it takes for a developer to go from a location in an application (a button, an animation, an API call), to identifying where in the code that element is defined, changing its value, seeing those changes reflected in the application and verifying that those changes were indeed caused by your change. For me this is the first crucial step in modifying an application, as until you can see your changes reflected you can't begin serious development work.\n\nSay for example there is an issue on a webpage: \n\n    <div class='fooo'>malformed content</div>\n\nThe first time we attempt to modify the application the reflection time is made up of three parts, the identification, the modification, and the verification.  \n    \n**Identification**: Inspect malformed element, search codebase for `fooo`.\n\n**Modification**: Update `fooo` to `foo`, save changes to index.html, refresh browser.\n\n**Verification**: Inspect malformed element, check that the class is now `foo`. \n\nAfter these three steps you can now be sure that the code you are modifying and the application you are seeing are directly linked. You are now in control of the project and can make the desired changes you need. \n\nThis is of course an extremely simple example and the reality is that most projects will have a much more complicated set of steps to go through this process. I hope to now offer some suggestions for things that architects can do to help give future developers the lowest reflection time possible; as well as offer some suggestions on how developers working on an issue with a long reflection time can hopefully reduce the time wasted by this cycle. \n\n## Identification\nOne theme through all of this is *consistency*, the more consistent a codebase, the easier it is to identify entry points and cut down on the reflection time. When you are debugging a piece of code that is of a unique structure in the code base you have to add significant overhead to account for things not being where you expect them to be. \n\nThis step is in a way less important because when developing a specific feature your tend to only do it once, where as the other two steps, modification and verification, you tend to do many times over while developing. That being said identification can often be an especially time consuming task when dealing with spaghetti code, so here are some things to consider. \n\n`A: Architect - Someone making large design decisions about the project`\n\n`D: Developer - Someone new to the project without knowledge of its history`\n\n#### One repository\nA: It is important to have all of the code for your project in one repository (and ideally one main branch) for many reasons, it makes deployments, pull requests and code reviews much easier, but crucially it means that when searching for something in the codebase whether it is a commit or function name you are going to be looking in the right place to start with. \n\nD: If your organisation uses github, you can search `org:yourcompany <search string>`, then hit the code tab, to find code across all repositories\n\n#### Unique names\nA: Naming is arguably one of the hardest things in programming, take time to consider how variables, functions, files and classes are named. It can be difficult, but resist the urge to have fun names; it might be a great in joke now, but three years down the line when new developers are wondering what on earth the \"pineapple\" module is doing, it isn't so funny. Perhaps add \"sensible naming\" as a step in your QA process.\n\nD: When developing it is easy to think \"I don't have time to worry about proper naming\", and that is often the case; but make sure you go back and review the naming once your feature is complete. \n\n#### Avoid hacks and deprecate\nA: When an old module is going to be deprecated or removed, try to scrub it from the code base and update the docs to reflect that. If you still rely on legacy code clearly mark it as such with class and variable names, don't just name the new module the exact-same-library2.js.\n\nD: Fight for time to refactor hacks into more suitable structures, that match the layout of the project. Fixing something with a quick hack, leads to unexpected spaghetti code. \n\n#### Clear file structure\nA: Pick a file structure and stick to it. Classes go in this folder, templates in this folder etc... It allows developers to quickly narrow down their search area.\n\nD: Break code down into multiple files with clear names to make the filename more relevant. If you have file with 4000 lines in making up 100 different functions, no filename is going to be able to suitably describe that file. \n\n#### Good commit & PR standards\nA: Create and enforce a good standard for commits and pull requests formatting. For example if every pull request is on a branch that links back to a ticket or card, it's far easier to find out *why* a certain line was introduced or modified. \n\nD: When committing be accurate and descriptive, make your commits small and concise. Don't forget you can search through a git log with tools like [fzf](http://owen.cymru/fzf-ripgrep-navigate-with-bash-faster-than-ever-before/) or github. You can also search for commits with `git log -S<string>` to get historical context on a code snippet.\n\n#### Effective free text search and navigation\nA: Despite the best efforts in structuring an application it won't always be obvious where to look in project; so make sure that free text searches can be ran easily by including built and minified files in `.gitignore` or similar files. Also consider adding ctags files and having them regularly updated if your developers utilise them. \n\nD: Make sure you have an effective and easy to use free text search in your IDE / Editor, it's invaluable for jumping around code. Shameless plug for my guide on using [fzf & rg](http://owen.cymru/fzf-ripgrep-navigate-with-bash-faster-than-ever-before/) to make a really quick search in Vim.\n\n## Modification\nThis step is important to focus on as developers will be doing it quite literally thousands of times on a project, so every millisecond here counts. Once the developer has identified where in the project they think the relevant code is, it's time to modify the application itself. Actually modifying the code isn't difficult, but once you hit save how long does it take from that point to the application being updated with your changes and in a working order? This is the modification time and you want to make it really really small. \n\n#### Code watching\nOne of the easiest ways to speed up this time is to ensure that you have a script that is watching the source files for changes being made and will instantly start your build processes as soon as the developer hits save. It isn't always possible, but it's certainly worth looking into if you don't have a watcher setup already. \n\n#### Reducing build times\nI can't really say much about this, as every platform and project is going to have different build steps, but examine the build process for your developers, how long does it take for the application to build? Is it over five seconds? Personally when it gets much over five seconds my mind will tend to wander in the direction of reddit or other distractions, and suddenly what may be a ten second build time is actually a thirty second build time after I've fully enjoyed the latest GIFs of kittens the internet has to offer. \n\nCheck that all the build steps are necessary for development, you could be using the same process for production as you are for development, which often has extra steps that aren't needed during development such as minification of libraries. \n\nIt's really worth investing some time into this, a project may last ten years, how many times will it be built, by how many developers? Seconds make minutes hours and days, so trimming one or two off of the build is so much more economical. \n\n#### View refreshers\nOnce the app is built, do you need to close the old one and open the new one? Do you need to refresh the page, or make that new API call? \n\nPart of the build should include a hook to refresh your view of the application, again I can't be specific here, but investigate if it's possible for your platforms. Ideally a developer can edit a line of code in the project, hit save and see the changes with no manual interaction required.\n\n## Verification\nThe final step in calculating your reflection time is how long it takes you to verify whether the changes you have made have actually changed the right feature in the application. This might just mean that you have added a print statement to a profile view, and when you load the profile view and see the new print statement, you know that the code you have found does in fact get ran on the profile view.\n\nThe issue here is when a developer needs to go through several steps to reach a point where they can verify their changes. A workflow might be; clear cookies, delete session, login, navigate to profile view, update password, *see if cookie has changed*. That is a whole bunch of steps to have to go through, when all we really want to do is the last one. \n\n#### Unit tests w/ watchers\nThe *best* way to avoid long dependency chains of interactions is with good unit tests, as tests can be automated. If you have an existing set of tests for a feature set them up to run when you save your code, and add any new tests you may need to verify that you are in fact working in the right area, save your changes and the tests will hopefully confirm or deny you are in the right place. \n\nThen be a good programmer and flesh them out into real tests once you done and revel in the glory testing brings to a project. They let you test just the thing you want to, and can be done at a keystrokes notice.\n\n#### Developer modes\nHaving a mode where a programmer can enter a special developer session is also a handy way to remove restrictions that might slow down verification, and to include verbose debugging information. \n\nIt is good practice to have your local and production applications matching as closely as possible, however I would suggest making one aspect of the design, say the background colour, of the application different between the two versions. This helps to prevent two things, firstly developers going through the first two stages of reflection, identification and modification, and then going to verify it on the production application. This is far too easy to and can easily be avoided. \n\nThe other benefit of such a change is to prevent people accidentally operating on production data or including test data in a production environment. Not directly related to this article but it is still helpful!\n\n#### Make everything scriptable where possible\nIf there are no tests for the project write some! When the boss doesn't let you, do the next best thing and script your verification. Simply making a quick and dirty bash script to send a request to an API or using xdotool to click the right sequence of buttons can only take a few minutes, but can make verifying your changes so much quicker and reproducible. \n\n## Conclusions\nMy definitions:\n\n* Identification Time = The time it takes to locate an application features code\n* Modification Time = The time it takes to change that code and have the app updated\n* Verification Time = The time it takes to check that the changes have been reflected in the app\n* Reflection Time = Identification Time + Modification Time + Verification Time\n\nIdentification time is important as it pertains to how quickly can you locate bugs, and is often the longest of three. The way to reduce it is by being smart about the architecture of the project. Modification and Verification times are usually much shorter, and can be improved with better use of toolchains to reduce manual effort. They are also crucial to make as small as possible as they tend to be repeated many thousands of times during development.\n\nReflection time as a whole is a great way to measure how friendly your code base is to work on; it is also a way to gauge experience with a project. Find a point in the application and ask the project lead to change a value in it and time how long it takes them. If you then were to then ask someone new to the project to do the same thing, how big is the time difference? If it is huge, consider why that is, did they have trouble understanding the file structure of where the code might be? Did the build fail for them as they were missing some undocumented library? Did the need to have a special development configuration to run that feature locally?\n\nThis is also an interesting way to see how complex different features are, does one feature set require a much greater level of knowledge about the system to be modified compared to another. \n\nThe main thing that improves all of these areas is *consistency*, something that can be achieved by enforcing clear standards, testing and QA practices. Enforce a linting ruleset that will stop someone naming a class with `_`'s in, making sure developers can't push code without the linter and tests passing. These little things make for a much nicer project, not just in reduced reflection time, but in increased test coverage and reduced regressions.\n\nI Hope this has been of some interest, it is a concept I've always thought about and not seen a good term to describe it with so took the liberty to define my own. \n\n:wq","mobiledoc":null,"html":"<p>As I wait for a docker container to restart for the 1001st time, an artifact of poor design decisions made on an old project I have been lumbered with, I can't help but feel the need to try to define in more clear terms what I have been referring to as \"reflection time\". </p>\n\n<p>Reflection time is simply the time it takes for a developer to go from a location in an application (a button, an animation, an API call), to identifying where in the code that element is defined, changing its value, seeing those changes reflected in the application and verifying that those changes were indeed caused by your change. For me this is the first crucial step in modifying an application, as until you can see your changes reflected you can't begin serious development work.</p>\n\n<p>Say for example there is an issue on a webpage: </p>\n\n<pre><code>&lt;div class='fooo'&gt;malformed content&lt;/div&gt;\n</code></pre>\n\n<p>The first time we attempt to modify the application the reflection time is made up of three parts, the identification, the modification, and the verification.  </p>\n\n<p><strong>Identification</strong>: Inspect malformed element, search codebase for <code>fooo</code>.</p>\n\n<p><strong>Modification</strong>: Update <code>fooo</code> to <code>foo</code>, save changes to index.html, refresh browser.</p>\n\n<p><strong>Verification</strong>: Inspect malformed element, check that the class is now <code>foo</code>. </p>\n\n<p>After these three steps you can now be sure that the code you are modifying and the application you are seeing are directly linked. You are now in control of the project and can make the desired changes you need. </p>\n\n<p>This is of course an extremely simple example and the reality is that most projects will have a much more complicated set of steps to go through this process. I hope to now offer some suggestions for things that architects can do to help give future developers the lowest reflection time possible; as well as offer some suggestions on how developers working on an issue with a long reflection time can hopefully reduce the time wasted by this cycle. </p>\n\n<h2 id=\"identification\">Identification</h2>\n\n<p>One theme through all of this is <em>consistency</em>, the more consistent a codebase, the easier it is to identify entry points and cut down on the reflection time. When you are debugging a piece of code that is of a unique structure in the code base you have to add significant overhead to account for things not being where you expect them to be. </p>\n\n<p>This step is in a way less important because when developing a specific feature your tend to only do it once, where as the other two steps, modification and verification, you tend to do many times over while developing. That being said identification can often be an especially time consuming task when dealing with spaghetti code, so here are some things to consider. </p>\n\n<p><code>A: Architect - Someone making large design decisions about the project</code></p>\n\n<p><code>D: Developer - Someone new to the project without knowledge of its history</code></p>\n\n<h4 id=\"onerepository\">One repository</h4>\n\n<p>A: It is important to have all of the code for your project in one repository (and ideally one main branch) for many reasons, it makes deployments, pull requests and code reviews much easier, but crucially it means that when searching for something in the codebase whether it is a commit or function name you are going to be looking in the right place to start with. </p>\n\n<p>D: If your organisation uses github, you can search <code>org:yourcompany &lt;search string&gt;</code>, then hit the code tab, to find code across all repositories</p>\n\n<h4 id=\"uniquenames\">Unique names</h4>\n\n<p>A: Naming is arguably one of the hardest things in programming, take time to consider how variables, functions, files and classes are named. It can be difficult, but resist the urge to have fun names; it might be a great in joke now, but three years down the line when new developers are wondering what on earth the \"pineapple\" module is doing, it isn't so funny. Perhaps add \"sensible naming\" as a step in your QA process.</p>\n\n<p>D: When developing it is easy to think \"I don't have time to worry about proper naming\", and that is often the case; but make sure you go back and review the naming once your feature is complete. </p>\n\n<h4 id=\"avoidhacksanddeprecate\">Avoid hacks and deprecate</h4>\n\n<p>A: When an old module is going to be deprecated or removed, try to scrub it from the code base and update the docs to reflect that. If you still rely on legacy code clearly mark it as such with class and variable names, don't just name the new module the exact-same-library2.js.</p>\n\n<p>D: Fight for time to refactor hacks into more suitable structures, that match the layout of the project. Fixing something with a quick hack, leads to unexpected spaghetti code. </p>\n\n<h4 id=\"clearfilestructure\">Clear file structure</h4>\n\n<p>A: Pick a file structure and stick to it. Classes go in this folder, templates in this folder etc... It allows developers to quickly narrow down their search area.</p>\n\n<p>D: Break code down into multiple files with clear names to make the filename more relevant. If you have file with 4000 lines in making up 100 different functions, no filename is going to be able to suitably describe that file. </p>\n\n<h4 id=\"goodcommitprstandards\">Good commit &amp; PR standards</h4>\n\n<p>A: Create and enforce a good standard for commits and pull requests formatting. For example if every pull request is on a branch that links back to a ticket or card, it's far easier to find out <em>why</em> a certain line was introduced or modified. </p>\n\n<p>D: When committing be accurate and descriptive, make your commits small and concise. Don't forget you can search through a git log with tools like <a href=\"http://owen.cymru/fzf-ripgrep-navigate-with-bash-faster-than-ever-before/\">fzf</a> or github. You can also search for commits with <code>git log -S&lt;string&gt;</code> to get historical context on a code snippet.</p>\n\n<h4 id=\"effectivefreetextsearchandnavigation\">Effective free text search and navigation</h4>\n\n<p>A: Despite the best efforts in structuring an application it won't always be obvious where to look in project; so make sure that free text searches can be ran easily by including built and minified files in <code>.gitignore</code> or similar files. Also consider adding ctags files and having them regularly updated if your developers utilise them. </p>\n\n<p>D: Make sure you have an effective and easy to use free text search in your IDE / Editor, it's invaluable for jumping around code. Shameless plug for my guide on using <a href=\"http://owen.cymru/fzf-ripgrep-navigate-with-bash-faster-than-ever-before/\">fzf &amp; rg</a> to make a really quick search in Vim.</p>\n\n<h2 id=\"modification\">Modification</h2>\n\n<p>This step is important to focus on as developers will be doing it quite literally thousands of times on a project, so every millisecond here counts. Once the developer has identified where in the project they think the relevant code is, it's time to modify the application itself. Actually modifying the code isn't difficult, but once you hit save how long does it take from that point to the application being updated with your changes and in a working order? This is the modification time and you want to make it really really small. </p>\n\n<h4 id=\"codewatching\">Code watching</h4>\n\n<p>One of the easiest ways to speed up this time is to ensure that you have a script that is watching the source files for changes being made and will instantly start your build processes as soon as the developer hits save. It isn't always possible, but it's certainly worth looking into if you don't have a watcher setup already. </p>\n\n<h4 id=\"reducingbuildtimes\">Reducing build times</h4>\n\n<p>I can't really say much about this, as every platform and project is going to have different build steps, but examine the build process for your developers, how long does it take for the application to build? Is it over five seconds? Personally when it gets much over five seconds my mind will tend to wander in the direction of reddit or other distractions, and suddenly what may be a ten second build time is actually a thirty second build time after I've fully enjoyed the latest GIFs of kittens the internet has to offer. </p>\n\n<p>Check that all the build steps are necessary for development, you could be using the same process for production as you are for development, which often has extra steps that aren't needed during development such as minification of libraries. </p>\n\n<p>It's really worth investing some time into this, a project may last ten years, how many times will it be built, by how many developers? Seconds make minutes hours and days, so trimming one or two off of the build is so much more economical. </p>\n\n<h4 id=\"viewrefreshers\">View refreshers</h4>\n\n<p>Once the app is built, do you need to close the old one and open the new one? Do you need to refresh the page, or make that new API call? </p>\n\n<p>Part of the build should include a hook to refresh your view of the application, again I can't be specific here, but investigate if it's possible for your platforms. Ideally a developer can edit a line of code in the project, hit save and see the changes with no manual interaction required.</p>\n\n<h2 id=\"verification\">Verification</h2>\n\n<p>The final step in calculating your reflection time is how long it takes you to verify whether the changes you have made have actually changed the right feature in the application. This might just mean that you have added a print statement to a profile view, and when you load the profile view and see the new print statement, you know that the code you have found does in fact get ran on the profile view.</p>\n\n<p>The issue here is when a developer needs to go through several steps to reach a point where they can verify their changes. A workflow might be; clear cookies, delete session, login, navigate to profile view, update password, <em>see if cookie has changed</em>. That is a whole bunch of steps to have to go through, when all we really want to do is the last one. </p>\n\n<h4 id=\"unittestswwatchers\">Unit tests w/ watchers</h4>\n\n<p>The <em>best</em> way to avoid long dependency chains of interactions is with good unit tests, as tests can be automated. If you have an existing set of tests for a feature set them up to run when you save your code, and add any new tests you may need to verify that you are in fact working in the right area, save your changes and the tests will hopefully confirm or deny you are in the right place. </p>\n\n<p>Then be a good programmer and flesh them out into real tests once you done and revel in the glory testing brings to a project. They let you test just the thing you want to, and can be done at a keystrokes notice.</p>\n\n<h4 id=\"developermodes\">Developer modes</h4>\n\n<p>Having a mode where a programmer can enter a special developer session is also a handy way to remove restrictions that might slow down verification, and to include verbose debugging information. </p>\n\n<p>It is good practice to have your local and production applications matching as closely as possible, however I would suggest making one aspect of the design, say the background colour, of the application different between the two versions. This helps to prevent two things, firstly developers going through the first two stages of reflection, identification and modification, and then going to verify it on the production application. This is far too easy to and can easily be avoided. </p>\n\n<p>The other benefit of such a change is to prevent people accidentally operating on production data or including test data in a production environment. Not directly related to this article but it is still helpful!</p>\n\n<h4 id=\"makeeverythingscriptablewherepossible\">Make everything scriptable where possible</h4>\n\n<p>If there are no tests for the project write some! When the boss doesn't let you, do the next best thing and script your verification. Simply making a quick and dirty bash script to send a request to an API or using xdotool to click the right sequence of buttons can only take a few minutes, but can make verifying your changes so much quicker and reproducible. </p>\n\n<h2 id=\"conclusions\">Conclusions</h2>\n\n<p>My definitions:</p>\n\n<ul>\n<li>Identification Time = The time it takes to locate an application features code</li>\n<li>Modification Time = The time it takes to change that code and have the app updated</li>\n<li>Verification Time = The time it takes to check that the changes have been reflected in the app</li>\n<li>Reflection Time = Identification Time + Modification Time + Verification Time</li>\n</ul>\n\n<p>Identification time is important as it pertains to how quickly can you locate bugs, and is often the longest of three. The way to reduce it is by being smart about the architecture of the project. Modification and Verification times are usually much shorter, and can be improved with better use of toolchains to reduce manual effort. They are also crucial to make as small as possible as they tend to be repeated many thousands of times during development.</p>\n\n<p>Reflection time as a whole is a great way to measure how friendly your code base is to work on; it is also a way to gauge experience with a project. Find a point in the application and ask the project lead to change a value in it and time how long it takes them. If you then were to then ask someone new to the project to do the same thing, how big is the time difference? If it is huge, consider why that is, did they have trouble understanding the file structure of where the code might be? Did the build fail for them as they were missing some undocumented library? Did the need to have a special development configuration to run that feature locally?</p>\n\n<p>This is also an interesting way to see how complex different features are, does one feature set require a much greater level of knowledge about the system to be modified compared to another. </p>\n\n<p>The main thing that improves all of these areas is <em>consistency</em>, something that can be achieved by enforcing clear standards, testing and QA practices. Enforce a linting ruleset that will stop someone naming a class with <code>_</code>'s in, making sure developers can't push code without the linter and tests passing. These little things make for a much nicer project, not just in reduced reflection time, but in increased test coverage and reduced regressions.</p>\n\n<p>I Hope this has been of some interest, it is a concept I've always thought about and not seen a good term to describe it with so took the liberty to define my own. </p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-10-17 08:25:57","created_by":1,"updated_at":"2017-10-19 09:33:11","updated_by":1,"published_at":"2017-10-18 14:46:29","published_by":1}],"users":[{"id":1,"uuid":"e3c7f1ca-383c-4106-ae3d-9ecdecea6b00","name":"Owen Garland","slug":"owen","password":"$2a$10$JLHhhSxlx.Yz4LrmLqpbYe4I3XIeMB9jCHUzGh6Nuv61VvXjFhAzm","email":"garland.owen@gmail.com","image":"//www.gravatar.com/avatar/63dda5a2c0e9492977092b0bea398173?s=250&d=mm&r=x","cover":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"accessibility":null,"status":"active","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"tour":null,"last_login":"2017-11-01 18:02:25","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-11-01 18:02:25","updated_by":1}],"roles":[{"id":1,"uuid":"78bd4021-c578-45d5-bd7a-4145ea0733fb","name":"Administrator","description":"Administrators","created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":2,"uuid":"8b4df21d-f9f8-43c8-87e2-789d3ea66075","name":"Editor","description":"Editors","created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":3,"uuid":"c7e51ab2-e692-4178-9a92-ae8c317e4ba1","name":"Author","description":"Authors","created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":4,"uuid":"003f2d21-e6c6-408d-8d7d-c7562b623269","name":"Owner","description":"Blog Owner","created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1}],"roles_users":[{"id":1,"role_id":4,"user_id":1}],"permissions":[{"id":1,"uuid":"8ba3abc3-deaa-46ab-954a-39cdd9e2b69d","name":"Export database","object_type":"db","action_type":"exportContent","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":2,"uuid":"497ea1b0-e66c-4ab1-8e0e-768d25c788f9","name":"Import database","object_type":"db","action_type":"importContent","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":3,"uuid":"1531c201-f15c-4ca8-a1b6-8370105c79ff","name":"Delete all content","object_type":"db","action_type":"deleteAllContent","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":4,"uuid":"d77b6364-9d6b-4581-ae10-3149129b10d4","name":"Send mail","object_type":"mail","action_type":"send","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":5,"uuid":"3f21bc36-8696-4eae-a6a6-d51d450c541e","name":"Browse notifications","object_type":"notification","action_type":"browse","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":6,"uuid":"76732b74-83fa-45a2-977c-10b7fae457d4","name":"Add notifications","object_type":"notification","action_type":"add","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":7,"uuid":"bb8cacfd-fd7c-4b63-8228-021ec57f4018","name":"Delete notifications","object_type":"notification","action_type":"destroy","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":8,"uuid":"7fe38d13-53b2-4fb6-99e7-4d6921cc55b8","name":"Browse posts","object_type":"post","action_type":"browse","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":9,"uuid":"c757b6c7-3446-49fd-8ef9-6d195a87d89d","name":"Read posts","object_type":"post","action_type":"read","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":10,"uuid":"441ac606-7199-4c3c-96c4-69931ec8eded","name":"Edit posts","object_type":"post","action_type":"edit","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":11,"uuid":"1f8de379-17e6-4022-94fe-fb6f179192ae","name":"Add posts","object_type":"post","action_type":"add","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":12,"uuid":"c8fc2071-7f28-48c0-ba36-a1fef0b0220a","name":"Delete posts","object_type":"post","action_type":"destroy","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":13,"uuid":"6e866238-1139-4931-8833-b3938f3b5cfd","name":"Browse settings","object_type":"setting","action_type":"browse","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":14,"uuid":"f933553f-d753-4465-b168-0defc667706e","name":"Read settings","object_type":"setting","action_type":"read","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":15,"uuid":"3b3a45aa-900a-40b0-a4d0-ba88210b9e48","name":"Edit settings","object_type":"setting","action_type":"edit","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":16,"uuid":"23079e9b-c5fe-4431-98ec-cf13fdb4de63","name":"Generate slugs","object_type":"slug","action_type":"generate","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":17,"uuid":"34c1ec7f-4925-429f-8562-452ed7879904","name":"Browse tags","object_type":"tag","action_type":"browse","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":18,"uuid":"b2e827d9-48e2-41ec-92a3-7fb18296407d","name":"Read tags","object_type":"tag","action_type":"read","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":19,"uuid":"df543cf8-6c7d-4d73-8cba-107f741d81ef","name":"Edit tags","object_type":"tag","action_type":"edit","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":20,"uuid":"d0f83610-a7a3-4d13-8432-e83ef7998c85","name":"Add tags","object_type":"tag","action_type":"add","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":21,"uuid":"f069de23-7e51-4fcd-982d-e0f0d19fe0a4","name":"Delete tags","object_type":"tag","action_type":"destroy","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":22,"uuid":"f2cf3dce-1cb8-4ce4-8bb5-24de8bd93583","name":"Browse themes","object_type":"theme","action_type":"browse","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":23,"uuid":"ae5aba05-922d-417a-aa94-56b2c019e1d8","name":"Edit themes","object_type":"theme","action_type":"edit","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":24,"uuid":"677c8fa3-d84e-42e4-918b-223531e0320b","name":"Upload themes","object_type":"theme","action_type":"add","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":25,"uuid":"c248bbd1-3b87-4a13-bbce-ad88d072086e","name":"Download themes","object_type":"theme","action_type":"read","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":26,"uuid":"231f1f24-b420-429e-aea8-b24135c3ecee","name":"Delete themes","object_type":"theme","action_type":"destroy","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":27,"uuid":"e5c35c37-e40c-47ed-8349-c5422dbb1971","name":"Browse users","object_type":"user","action_type":"browse","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":28,"uuid":"57fe6465-ce4c-4014-962e-b460698b30c8","name":"Read users","object_type":"user","action_type":"read","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":29,"uuid":"a7459236-49b6-417b-910b-fad9a53dd3cb","name":"Edit users","object_type":"user","action_type":"edit","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":30,"uuid":"a2ea91da-bc93-4836-bb9d-362461a9ec04","name":"Add users","object_type":"user","action_type":"add","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":31,"uuid":"d6592cfd-074c-49b2-b67f-f091b0e8e837","name":"Delete users","object_type":"user","action_type":"destroy","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":32,"uuid":"0a17980f-7c8b-4ddb-bd62-915273cf6d3c","name":"Assign a role","object_type":"role","action_type":"assign","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":33,"uuid":"ef48121d-25f7-49ad-822a-9cc8cf9f9e78","name":"Browse roles","object_type":"role","action_type":"browse","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":34,"uuid":"e1987ee6-92d4-4e51-ac8f-4d6d8b9ba56f","name":"Browse clients","object_type":"client","action_type":"browse","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":35,"uuid":"6b4bb3f0-86bd-4016-8d7f-8f00755ad440","name":"Read clients","object_type":"client","action_type":"read","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":36,"uuid":"d225f301-954f-4aee-87d9-7131e25db00d","name":"Edit clients","object_type":"client","action_type":"edit","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":37,"uuid":"6ae4a581-816f-4639-acba-704477ea37de","name":"Add clients","object_type":"client","action_type":"add","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":38,"uuid":"6ebe864c-ad06-46b8-b2ff-fdc7ee62868c","name":"Delete clients","object_type":"client","action_type":"destroy","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":39,"uuid":"149d1073-9748-4ba9-bcf8-1f4177cee3ba","name":"Browse subscribers","object_type":"subscriber","action_type":"browse","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":40,"uuid":"3a7e627c-83b3-472f-86a5-e25ffdbc05e6","name":"Read subscribers","object_type":"subscriber","action_type":"read","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":41,"uuid":"01152069-a155-4660-93f5-571a4413e4d7","name":"Edit subscribers","object_type":"subscriber","action_type":"edit","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":42,"uuid":"5790561e-97a8-486e-9daf-d8e3ff261060","name":"Add subscribers","object_type":"subscriber","action_type":"add","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":43,"uuid":"2be52ba9-f7df-4731-9d53-138bb3b0ac77","name":"Delete subscribers","object_type":"subscriber","action_type":"destroy","object_id":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1}],"permissions_users":[],"permissions_roles":[{"id":1,"role_id":1,"permission_id":1},{"id":2,"role_id":1,"permission_id":2},{"id":3,"role_id":1,"permission_id":3},{"id":4,"role_id":1,"permission_id":4},{"id":5,"role_id":1,"permission_id":5},{"id":6,"role_id":1,"permission_id":6},{"id":7,"role_id":1,"permission_id":7},{"id":8,"role_id":1,"permission_id":8},{"id":9,"role_id":1,"permission_id":9},{"id":10,"role_id":1,"permission_id":10},{"id":11,"role_id":1,"permission_id":11},{"id":12,"role_id":1,"permission_id":12},{"id":13,"role_id":1,"permission_id":13},{"id":14,"role_id":1,"permission_id":14},{"id":15,"role_id":1,"permission_id":15},{"id":16,"role_id":1,"permission_id":16},{"id":17,"role_id":1,"permission_id":17},{"id":18,"role_id":1,"permission_id":18},{"id":19,"role_id":1,"permission_id":19},{"id":20,"role_id":1,"permission_id":20},{"id":21,"role_id":1,"permission_id":21},{"id":22,"role_id":1,"permission_id":22},{"id":23,"role_id":1,"permission_id":23},{"id":24,"role_id":1,"permission_id":24},{"id":25,"role_id":1,"permission_id":25},{"id":26,"role_id":1,"permission_id":26},{"id":27,"role_id":1,"permission_id":27},{"id":28,"role_id":1,"permission_id":28},{"id":29,"role_id":1,"permission_id":29},{"id":30,"role_id":1,"permission_id":30},{"id":31,"role_id":1,"permission_id":31},{"id":32,"role_id":1,"permission_id":32},{"id":33,"role_id":1,"permission_id":33},{"id":34,"role_id":1,"permission_id":34},{"id":35,"role_id":1,"permission_id":35},{"id":36,"role_id":1,"permission_id":36},{"id":37,"role_id":1,"permission_id":37},{"id":38,"role_id":1,"permission_id":38},{"id":39,"role_id":1,"permission_id":39},{"id":40,"role_id":1,"permission_id":40},{"id":41,"role_id":1,"permission_id":41},{"id":42,"role_id":1,"permission_id":42},{"id":43,"role_id":1,"permission_id":43},{"id":44,"role_id":2,"permission_id":8},{"id":45,"role_id":2,"permission_id":9},{"id":46,"role_id":2,"permission_id":10},{"id":47,"role_id":2,"permission_id":11},{"id":48,"role_id":2,"permission_id":12},{"id":49,"role_id":2,"permission_id":13},{"id":50,"role_id":2,"permission_id":14},{"id":51,"role_id":2,"permission_id":16},{"id":52,"role_id":2,"permission_id":17},{"id":53,"role_id":2,"permission_id":18},{"id":54,"role_id":2,"permission_id":19},{"id":55,"role_id":2,"permission_id":20},{"id":56,"role_id":2,"permission_id":21},{"id":57,"role_id":2,"permission_id":27},{"id":58,"role_id":2,"permission_id":28},{"id":59,"role_id":2,"permission_id":29},{"id":60,"role_id":2,"permission_id":30},{"id":61,"role_id":2,"permission_id":31},{"id":62,"role_id":2,"permission_id":32},{"id":63,"role_id":2,"permission_id":33},{"id":64,"role_id":2,"permission_id":34},{"id":65,"role_id":2,"permission_id":35},{"id":66,"role_id":2,"permission_id":36},{"id":67,"role_id":2,"permission_id":37},{"id":68,"role_id":2,"permission_id":38},{"id":69,"role_id":2,"permission_id":42},{"id":70,"role_id":3,"permission_id":8},{"id":71,"role_id":3,"permission_id":9},{"id":72,"role_id":3,"permission_id":11},{"id":73,"role_id":3,"permission_id":13},{"id":74,"role_id":3,"permission_id":14},{"id":75,"role_id":3,"permission_id":16},{"id":76,"role_id":3,"permission_id":17},{"id":77,"role_id":3,"permission_id":18},{"id":78,"role_id":3,"permission_id":20},{"id":79,"role_id":3,"permission_id":27},{"id":80,"role_id":3,"permission_id":28},{"id":81,"role_id":3,"permission_id":33},{"id":82,"role_id":3,"permission_id":34},{"id":83,"role_id":3,"permission_id":35},{"id":84,"role_id":3,"permission_id":36},{"id":85,"role_id":3,"permission_id":37},{"id":86,"role_id":3,"permission_id":38},{"id":87,"role_id":3,"permission_id":42}],"permissions_apps":[],"settings":[{"id":1,"uuid":"d5fb05a7-b7b1-452d-8654-b0c2f2a81ad5","key":"databaseVersion","value":"009","type":"core","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-08-17 09:25:26","updated_by":1},{"id":2,"uuid":"986b1fb0-e4b2-4c6a-98c3-6e0a4e4f7ea7","key":"dbHash","value":"cecac882-854a-4913-9616-be49cc9f4cc2","type":"core","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-08-17 09:25:26","updated_by":1},{"id":3,"uuid":"0f7abb2f-32ec-4bf9-9f49-09df003527b6","key":"nextUpdateCheck","value":"1509645806","type":"core","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-11-01 18:02:22","updated_by":1},{"id":4,"uuid":"cc8d9cb9-25d2-4115-9395-9cf422413762","key":"displayUpdateNotification","value":"0.11.12","type":"core","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-11-01 18:02:22","updated_by":1},{"id":5,"uuid":"4564727e-bd79-4634-ada6-443e360634cb","key":"seenNotifications","value":"[]","type":"core","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-08-17 09:25:26","updated_by":1},{"id":6,"uuid":"3d41159c-007d-4fb1-aaf9-7e2f915d2960","key":"migrations","value":"{}","type":"core","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-08-17 09:25:26","updated_by":1},{"id":7,"uuid":"ef7614c5-e604-4540-b3c1-c32e5f2b3428","key":"title","value":"Jazz, Linux & Vim","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":8,"uuid":"924158f0-2d52-4d48-be31-d5224f973296","key":"description","value":"Owen's personal blog, mostly about technical things.","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":9,"uuid":"5553d7f3-6748-46e8-a9ba-6a8b954ceae4","key":"logo","value":"","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":10,"uuid":"8cfab97f-5cb1-4576-9856-992c64f7fecd","key":"cover","value":"/content/images/2017/02/shot-1.png","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":11,"uuid":"31aac66e-776f-456c-ac43-82230f059049","key":"defaultLang","value":"en_US","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":12,"uuid":"ec857d51-714b-45dc-94ea-e9c9a6a4756f","key":"postsPerPage","value":"10","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":13,"uuid":"fb867c8b-3bd9-49ab-9f15-0b29e2e6be23","key":"activeTimezone","value":"Etc/UTC","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":14,"uuid":"7d336658-3d62-4e57-9913-55668fc09527","key":"forceI18n","value":"true","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":15,"uuid":"5bf2dfc9-2efe-488b-ac59-fbb3f1a3ab84","key":"permalinks","value":"/:slug/","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":16,"uuid":"52268618-10e9-489a-97f0-0b26e1238419","key":"amp","value":"true","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":17,"uuid":"6f2cdc83-ca08-4d86-b603-c4bd93ef6372","key":"ghost_head","value":"<link rel=\"icon\" type=\"image/png\" href=\"https://raw.githubusercontent.com/bag-man/nodeup/master/public/assets/imgs/favicon.ico\">\n<script>\n  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n\n  ga('create', 'UA-53020648-3', 'auto');\n  ga('send', 'pageview');\n</script>\n\n<link rel=\"stylesheet\" href=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/default.min.css\">\n<script src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js\"></script>\n\n<style> \n  img {\n    display: block;\n    margin: 0 auto;\n  }\n  .horizontal-img {\n    display: float;\n  }\n</style>","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":18,"uuid":"b4418ed0-92ce-4b54-9187-c0a62fe8ba11","key":"ghost_foot","value":"<script>    \n  $.fn.randomize=function(a){(a?this.find(a):this).parent().each(function(){$(this).children(a).sort(function(){return Math.random()-0.5}).detach().appendTo(this)});return this};\n  $('.posts-list').randomize('article');\n</script>\n\n<script>hljs.initHighlightingOnLoad();</script>","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":19,"uuid":"1b51e23e-0cb5-479f-803c-31203fe974b2","key":"facebook","value":"","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":20,"uuid":"a81bc281-25b1-4d14-842c-c553b8e6b036","key":"twitter","value":"@owen_garland","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":21,"uuid":"c053f9df-f560-4376-aa42-473a0dc2ca1d","key":"labs","value":"{}","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":22,"uuid":"161f1640-51f9-42b6-be0a-43a50f5198ff","key":"navigation","value":"[{\"label\":\"Home\",\"url\":\"http://owen.cymru\"},{\"label\":\"About Me\",\"url\":\"http://owen.cymru/about/\"},{\"label\":\"Github\",\"url\":\"http://github.com/bag-man\"},{\"label\":\"Vimrc\",\"url\":\"https://github.com/bag-man/dotfiles/blob/master/vimrc\"},{\"label\":\"CV\",\"url\":\"https://docs.google.com/viewer?url=https://github.com/bag-man/cv/raw/master/OwenGarlandCV.pdf\"},{\"label\":\"Email\",\"url\":\"mailto://garland.owen@gmail.com\"}]","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":23,"uuid":"2362109f-43c0-44cb-bce6-1b4501cc7ee1","key":"slack","value":"[{\"url\":\"\"}]","type":"blog","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":24,"uuid":"00a9ea8a-f94a-48e0-b459-22e41d1561ce","key":"activeApps","value":"[]","type":"app","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-08-17 09:28:35","updated_by":1},{"id":25,"uuid":"52a8d387-b24e-481d-8d8a-cf769f09804c","key":"installedApps","value":"[]","type":"app","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-09-06 09:04:46","updated_by":1},{"id":26,"uuid":"9938b158-45a2-4d2e-9140-a5076b51788d","key":"isPrivate","value":"false","type":"private","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":27,"uuid":"4b89d200-cee3-48a3-9515-9d67de60df57","key":"password","value":"","type":"private","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1},{"id":28,"uuid":"952b4375-660d-4045-a357-e252c73f3c2c","key":"activeTheme","value":"beautiful-ghost-master","type":"theme","created_at":"2017-08-17 09:25:26","created_by":1,"updated_at":"2017-10-18 15:33:28","updated_by":1}],"tags":[{"id":1,"uuid":"a8155fb7-439a-40f6-ad53-ea781b3851ab","name":"Getting Started","slug":"getting-started","description":null,"image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-17 09:25:25","created_by":1,"updated_at":"2017-08-17 09:25:25","updated_by":1},{"id":2,"uuid":"c395edb0-d251-44d6-badf-a881f78e21be","name":"javascript","slug":"javascript","description":null,"image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-17 09:28:34","created_by":1,"updated_at":"2017-08-17 09:28:34","updated_by":1},{"id":3,"uuid":"99095197-3bda-434d-8d38-f8c297a2d66c","name":"js","slug":"js","description":null,"image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-17 09:28:34","created_by":1,"updated_at":"2017-08-17 09:28:34","updated_by":1},{"id":4,"uuid":"e21f84ed-a15e-4344-936d-cf8013e3cca7","name":"nodejs","slug":"nodejs","description":null,"image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-08-17 09:28:34","created_by":1,"updated_at":"2017-08-17 09:28:34","updated_by":1}],"posts_tags":[],"apps":[],"app_settings":[],"app_fields":[],"subscribers":[]}}]}