{"db":[{"meta":{"exported_on":1491516860573,"version":"009"},"data":{"posts":[{"id":2,"uuid":"3954d38e-553b-4c9d-8c5a-57072b41c7fa","title":"About Me","slug":"about","markdown":"Hello! I'm Owen, I've been studying Software Engineering in the the beautiful town of Aberystwyth for the last few years. I mainly code in NodeJS, Python and C, although I am open to trying out new things like Haskell, Rust and Go. \n\nLast year I worked at [Clock Ltd](https://clock.co.uk), and learned a whole lot of new tech that I had never even considered before; as well as making some amazing friends.\n\nI'm also really passionate about Swing Dance, in all it's forms. So I've spent the last few summers at [Herrang Dance Camp](http://herrang.com), having the time of my life. If you want to talk Trad Jazz, let me know! \n\nOne thing I am really proud of is my Linux and Vim setups, I've actually done a few talks on Vim at BCS meetings and you can find my vimrc [here](https://github.com/bag-man/dotfiles/blob/master/vimrc). If you have any questions or comments let me know I love a chance to nerd out on it.\n\nHere are some of my side projects:\n\n  *  [*It's back*](http://alpha.itsback.at)  **-** Written in NodeJS, this is a website that alerts users in real time when a site comes back up after being offline. \n  *  [*Daily Mail Bot*](http://reddit.com/u/DailMail_Bot) **-**  Protest bot written in Python, that mirrors Daily Mail & Sun articles posted to reddit. \n  *  [*Process Game*](https://github.com/bag-man/process-game) **-** A small C game I made as a learning exercise. Find a way to kill the game without it knowing. \n  *  [*OandXs*](https://github.com/bag-man/oandxs) **-** Noughts and crosses in a recursive manner, so that the game can be played multiple layers deep.\n  * [*Gists*](https://gist.github.com/bag-man) - A few nice snippets of code that I was particularly proud of.\n\n:wq","mobiledoc":null,"html":"<p>Hello! I'm Owen, I've been studying Software Engineering in the the beautiful town of Aberystwyth for the last few years. I mainly code in NodeJS, Python and C, although I am open to trying out new things like Haskell, Rust and Go. </p>\n\n<p>Last year I worked at <a href=\"https://clock.co.uk\">Clock Ltd</a>, and learned a whole lot of new tech that I had never even considered before; as well as making some amazing friends.</p>\n\n<p>I'm also really passionate about Swing Dance, in all it's forms. So I've spent the last few summers at <a href=\"http://herrang.com\">Herrang Dance Camp</a>, having the time of my life. If you want to talk Trad Jazz, let me know! </p>\n\n<p>One thing I am really proud of is my Linux and Vim setups, I've actually done a few talks on Vim at BCS meetings and you can find my vimrc <a href=\"https://github.com/bag-man/dotfiles/blob/master/vimrc\">here</a>. If you have any questions or comments let me know I love a chance to nerd out on it.</p>\n\n<p>Here are some of my side projects:</p>\n\n<ul>\n<li><a href=\"http://alpha.itsback.at\"><em>It's back</em></a>  <strong>-</strong> Written in NodeJS, this is a website that alerts users in real time when a site comes back up after being offline. </li>\n<li><a href=\"http://reddit.com/u/DailMail_Bot\"><em>Daily Mail Bot</em></a> <strong>-</strong>  Protest bot written in Python, that mirrors Daily Mail &amp; Sun articles posted to reddit. </li>\n<li><a href=\"https://github.com/bag-man/process-game\"><em>Process Game</em></a> <strong>-</strong> A small C game I made as a learning exercise. Find a way to kill the game without it knowing. </li>\n<li><a href=\"https://github.com/bag-man/oandxs\"><em>OandXs</em></a> <strong>-</strong> Noughts and crosses in a recursive manner, so that the game can be played multiple layers deep.</li>\n<li><a href=\"https://gist.github.com/bag-man\"><em>Gists</em></a> - A few nice snippets of code that I was particularly proud of.</li>\n</ul>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-12 15:14:11","created_by":1,"updated_at":"2017-02-17 01:18:00","updated_by":1,"published_at":"2017-02-12 15:21:46","published_by":1},{"id":3,"uuid":"0ab125b8-f557-4296-9fe5-ecd9d8e59246","title":"FZF & RipGrep - Navigate with bash faster than ever before","slug":"fzf-ripgrep-navigate-with-bash-faster-than-ever-before","markdown":"I've always had [fzf](https://github.com/junegunn/fzf) and [ripgrep](https://github.com/BurntSushi/ripgrep) on my radar, and I've finally gotten around to using them together. Good lord it makes a world of difference, especially when added to Vim as well as Bash. \n\nAdd the following snippet to your ~/.bashrc, this add's fzf keybindings to bash and gets fzf to use ripgrep by default for faster searching.\n\n    [ -f ~/.fzf.bash ] && source ~/.fzf.bash\n    export FZF_DEFAULT_COMMAND='rg --files --no-ignore --hidden --follow -g \"!{.git,node_modules}/*\" 2> /dev/null'\n    export FZF_CTRL_T_COMMAND=\"$FZF_DEFAULT_COMMAND\"\n    bind -x '\"\\C-p\": vim $(fzf);'\n\nOkay now what can you do? \n\n* **Ctrl + r** - search through bash history with fzf\n* **Ctrl + p** - edit a file in vim from fzf\n* **mv dir/**** - expand a directory with (\\*\\*) and select from fzf\n* **Alt + c** - change directory from fzf - see the update at the bottom for faster search with `bfs`.\n* **Ctrl + t** - insert file from fzf into command\n\nNeat right! Now if you are a vim user there is more, add the fzf plugin to your ~/.vimrc, along with this snippet. Obviously  customise the bindings, and excludes / includes to your workflows!\n\n    let g:rg_command = '\n      \\ rg --column --line-number --no-heading --fixed-strings --ignore-case --no-ignore --hidden --follow --color \"always\"\n      \\ -g \"*.{js,json,php,md,styl,jade,html,config,py,cpp,c,go,hs,rb,conf}\"\n      \\ -g \"!{.git,node_modules,vendor}/*\" '\n\n    command! -bang -nargs=* F call fzf#vim#grep(g:rg_command .shellescape(<q-args>), 1, <bang>0)\n\n\nYou now have a killer free text search with `:F` that uses ripgrep and is faster than any I've seen before.\n\nI've done more with this, but want to leave it there for now. There are even more goodies in my [.vimrc](https://github.com/bag-man/dotfiles/blob/master/vimrc), and in my [.bashrc](https://github.com/bag-man/dotfiles/blob/master/bashrc), including auto installing fzf and ripgrep (admittedly hackily) from the .vimrc and a nice snippet that uses fzf for git logs. \n\n## Update\nJust made this nice snippet for tmux:\n\n    tm() {\n      local session\n      newsession=${1:-new}\n      session=$(tmux list-sessions -F \"#{session_name}\" | \\\n        fzf --query=\"$1\" --select-1 --exit-0) &&\n        tmux attach-session -t \"$session\" || tmux new-session -s $newsession\n    }\n\n* `tm` with no sessions open it will create a session called \"new\".\n* `tm irc` it will attach to the irc session (if it exists), else it will create it.\n* `tm` with one session open, it will attach to that session.\n* `tm` with more than one session open it will let you select the session via fzf.\n\nAnd here is a nice snippet for looking through git logs:\n\n```\nfzf_log() {\n  hash=$(git log --color=always --format=\"%C(auto)%h%d %s %C(black)%C(bold)%cr\" \"$@\" |  fzf | awk '{print $1}')\n  echo $hash | xclip\n  git showtool $hash\n}\n```\n\nIt will let you select a commit, and display the diff off it, and put the commit hash on your clipboard using xclip. I also have it set to use icdiff via `git showtool`.\n\n## Update update...\nA few people have pointed out that doing this doesn't work for fzf's Ctrl+T completion or the Alt+C completion. Thanks to [@mikepqr](https://twitter.com/mikepqr), for letting me know the work around for Ctrl+T. I have updated the configurations at the top of the post with what he sent me. \n\nAlt+C has proved a bit tricky to get working with ripgrep, as rg doesn't natively support searching just for directories. Instead I have been using [bfs](https://github.com/tavianator/bfs) by adding the following to me config. \n\n```\nexport FZF_ALT_C_COMMAND=\"bfs -type d -nohidden\"\n```\n\nAfter a bit of quick testing it appears to run faster and give slightly nicer results that the [ripgrep solutions](https://github.com/BurntSushi/ripgrep/issues/388) I've tried, although it does mean installing another tool!\n\n:wq","mobiledoc":null,"html":"<p>I've always had <a href=\"https://github.com/junegunn/fzf\">fzf</a> and <a href=\"https://github.com/BurntSushi/ripgrep\">ripgrep</a> on my radar, and I've finally gotten around to using them together. Good lord it makes a world of difference, especially when added to Vim as well as Bash. </p>\n\n<p>Add the following snippet to your ~/.bashrc, this add's fzf keybindings to bash and gets fzf to use ripgrep by default for faster searching.</p>\n\n<pre><code>[ -f ~/.fzf.bash ] &amp;&amp; source ~/.fzf.bash\nexport FZF_DEFAULT_COMMAND='rg --files --no-ignore --hidden --follow -g \"!{.git,node_modules}/*\" 2&gt; /dev/null'\nexport FZF_CTRL_T_COMMAND=\"$FZF_DEFAULT_COMMAND\"\nbind -x '\"\\C-p\": vim $(fzf);'\n</code></pre>\n\n<p>Okay now what can you do? </p>\n\n<ul>\n<li><strong>Ctrl + r</strong> - search through bash history with fzf</li>\n<li><strong>Ctrl + p</strong> - edit a file in vim from fzf</li>\n<li><strong>mv dir/**</strong> - expand a directory with (**) and select from fzf</li>\n<li><strong>Alt + c</strong> - change directory from fzf - see the update at the bottom for faster search with <code>bfs</code>.</li>\n<li><strong>Ctrl + t</strong> - insert file from fzf into command</li>\n</ul>\n\n<p>Neat right! Now if you are a vim user there is more, add the fzf plugin to your ~/.vimrc, along with this snippet. Obviously  customise the bindings, and excludes / includes to your workflows!</p>\n\n<pre><code>let g:rg_command = '\n  \\ rg --column --line-number --no-heading --fixed-strings --ignore-case --no-ignore --hidden --follow --color \"always\"\n  \\ -g \"*.{js,json,php,md,styl,jade,html,config,py,cpp,c,go,hs,rb,conf}\"\n  \\ -g \"!{.git,node_modules,vendor}/*\" '\n\ncommand! -bang -nargs=* F call fzf#vim#grep(g:rg_command .shellescape(&lt;q-args&gt;), 1, &lt;bang&gt;0)\n</code></pre>\n\n<p>You now have a killer free text search with <code>:F</code> that uses ripgrep and is faster than any I've seen before.</p>\n\n<p>I've done more with this, but want to leave it there for now. There are even more goodies in my <a href=\"https://github.com/bag-man/dotfiles/blob/master/vimrc\">.vimrc</a>, and in my <a href=\"https://github.com/bag-man/dotfiles/blob/master/bashrc\">.bashrc</a>, including auto installing fzf and ripgrep (admittedly hackily) from the .vimrc and a nice snippet that uses fzf for git logs. </p>\n\n<h2 id=\"update\">Update</h2>\n\n<p>Just made this nice snippet for tmux:</p>\n\n<pre><code>tm() {\n  local session\n  newsession=${1:-new}\n  session=$(tmux list-sessions -F \"#{session_name}\" | \\\n    fzf --query=\"$1\" --select-1 --exit-0) &amp;&amp;\n    tmux attach-session -t \"$session\" || tmux new-session -s $newsession\n}\n</code></pre>\n\n<ul>\n<li><code>tm</code> with no sessions open it will create a session called \"new\".</li>\n<li><code>tm irc</code> it will attach to the irc session (if it exists), else it will create it.</li>\n<li><code>tm</code> with one session open, it will attach to that session.</li>\n<li><code>tm</code> with more than one session open it will let you select the session via fzf.</li>\n</ul>\n\n<p>And here is a nice snippet for looking through git logs:</p>\n\n<pre><code>fzf_log() {  \n  hash=$(git log --color=always --format=\"%C(auto)%h%d %s %C(black)%C(bold)%cr\" \"$@\" |  fzf | awk '{print $1}')\n  echo $hash | xclip\n  git showtool $hash\n}\n</code></pre>\n\n<p>It will let you select a commit, and display the diff off it, and put the commit hash on your clipboard using xclip. I also have it set to use icdiff via <code>git showtool</code>.</p>\n\n<h2 id=\"updateupdate\">Update update...</h2>\n\n<p>A few people have pointed out that doing this doesn't work for fzf's Ctrl+T completion or the Alt+C completion. Thanks to <a href=\"https://twitter.com/mikepqr\">@mikepqr</a>, for letting me know the work around for Ctrl+T. I have updated the configurations at the top of the post with what he sent me. </p>\n\n<p>Alt+C has proved a bit tricky to get working with ripgrep, as rg doesn't natively support searching just for directories. Instead I have been using <a href=\"https://github.com/tavianator/bfs\">bfs</a> by adding the following to me config. </p>\n\n<pre><code>export FZF_ALT_C_COMMAND=\"bfs -type d -nohidden\"  \n</code></pre>\n\n<p>After a bit of quick testing it appears to run faster and give slightly nicer results that the <a href=\"https://github.com/BurntSushi/ripgrep/issues/388\">ripgrep solutions</a> I've tried, although it does mean installing another tool!</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":1,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-12 15:23:48","created_by":1,"updated_at":"2017-03-13 01:29:53","updated_by":1,"published_at":"2017-02-12 15:23:54","published_by":1},{"id":4,"uuid":"2c321f40-c2c5-4fd9-a8ca-0daa624b8990","title":"MongoDB Performance on ZFS and Linux","slug":"mongodb-performance-on-zfs-and-linux","markdown":"*This was written during my time at Clock.*\n\nHere at Clock we love ZFS, and have been running it in production on our Linux file servers for several years. It provides us with [numerous excellent features](https://wiki.ubuntu.com/ZFS), such as snapshotting, incremental send/receive, and transparent compression. With the recent release of [Ubuntu Xenial 16.04](https://wiki.ubuntu.com/XenialXerus/ReleaseNotes) official support for [ZFS is now here](https://insights.ubuntu.com/2016/02/16/zfs-is-the-fs-for-containers-in-ubuntu-16-04/), and we are keen to integrate it fully into our next generation hosting stack.\n\nAs a Node.js and MongoDB house, one of our main concerns has been how MongoDB will perform on ZFS on Linux, especially after reading about [potential problems](http://serverfault.com/questions/583688/mongodb-and-zfs-bad-performance-disk-always-busy-with-reads-while-doing-only-wr) other people have faced. There really isn't much data out there to put our minds at rest.\n\nWe decided to setup a method of benchmarking MongoDB with the supported EXT4 and XFS, then compare against ZFS with different options enabled. The idea being that we can hopefully figure out how ZFS compares, and if there are any options we can set that will impact the performance in any noticeable way. \n\nThere are a few caveats to our testing, so we are aware that these results need to be taken with a pinch of salt. They are aimed at just providing an indicator as to the performance between the file systems, not being a definitive guide to which is best to use.\n\n## Setup\n\nThe main variable that may affect the results was the hardware that we chose to use. We spun up a 4GB Linode instance with four cores, and four virtual disks: one for the latest Ubuntu 15.10 image (which we then upgraded to 16.04), and one disk for each of the file systems that we intended to test, EXT4, XFS and ZFS.\n\nThe issue with this approach is that the system is running on a virtualised machine with shared hardware, so there may be variations in the performance available to the machine. In an ideal world we would run this on a physical machine with identical disks, but that wasn't feasible for this investigation.\n\nWe decided to use the latest stable version of MongoDB 3.2.5, ZFS was at version 0.6.5.6 provided by the zfsutils-linux package for Xenial.\n\nTo benchmark the performance we investigated a few options, such as [YCSB](https://github.com/brianfrankcooper/YCSB), and even writing our own benchmark based on examples of our real world data and queries. However we settled on using a Java-based tool, [sysbench-mongodb](https://github.com/tmcallaghan/sysbench-mongodb). This made it easy to configure and run consistent and repeatable tests that would push the database to its limits. \n\n## Methodology\n\nFirst the drives were mounted to directories reflecting their filesystems, this made it easy to switch the file system that MongoDB was using.\n\n```\nFilesystem  Type  Size  Used  Avail  Use%  Mounted on\n/dev/sda    ext4  7.7G  1.8G  5.5G   25%   /\n/dev/sdc    ext4   20G  44M   19G    1%    /ext4\n/dev/sdd    xfs    20G  33M   20G    1%    /xfs\ntank        zfs    19G  0M    19G    0%    /zfs\n```\n\nThe drives were setup and formatted with the default options of `mkfs.ext4` and `mkfs.xfs` and `zpool create`. I then wrote a script, [that can be found here](https://gist.github.com/bag-man/95cc7cc7ad7046bbe2bc30f01c0f73bd), to utilise these disks with the sysbench-mongodb utility, and log the results. If you want to see the specific commands that we used, please have a look at the script.\n\nThe way the script works is by destroying and recreating the ZFS volume with the option that is being tested, then starting a mongod instance, using the filesystems mount point as the dbpath. For example `mongod --directoryperdb --dbpath /zfs`. Then we simply run the sysbench-mongo script, and pull out the results of the run.\n\nThe parameters we decided to test for ZFS are listed below:\n\n```\nDefaults (ashift = 0, recordsize = 128K, compression = off)\nDefaults & ashift = {9,12}        \nDefaults & recordsize = {8KB,64KB}        \nDefaults & compression = {lz4,gzip}        \n```\n\nWe also edited the sysbench-mongodb config ever so slightly. We opted to use the `FSYNC_SAFE` write concern to ensure that the data was getting written to disk, and not just stored in RAM. We also reduced the number of documents per collection to `1,000,000` tenfold less than the default `10,000,000`. This was simply to save time on each “Load” step, something we aren't too concerned with as our applications are principally read-heavy.\n\nAfter running the benchmarks for each of the separate filesystems ten times and recording the  last cumulative average of the inserts per second for the “Load” stage of the benchmark, and the last cumulative average of the transactions per second for the “Execute” stage, we could create a representative average of the performance for each filesystem. \n\n\n## Results\n![Results](https://i.imgur.com/or6Lskm.png)\n\n\nYou can download the [raw data here](http://downloads.clock.co.uk/mongo_on_zol-results.tar.xz) if you want to perform your own analysis of the results.\n\nAs we suspected, ZFS doesn’t perform quite as well as the other filesystems, but it is worth noting that with the default settings it is only slightly slower. Most importantly, we didn’t uncover any show-stopping performance issues, as hinted in the discussions that are linked above. Unless you are looking to get the utmost performance in your queries, then ZFS certainly looks to be a viable option. Moreover, we feel that the benefits gained by utilising ZFS are more than worth the minor performance penalties. \n\nThis investigation has been far from definitive, but hopefully has provided you with a rough overview of how these filesystems perform. If you know of ways to help us improve the results, or performance of MongoDB on ZFS, please do let us know, we are keen to hear your experiences!\n\n:wq","mobiledoc":null,"html":"<p><em>This was written during my time at Clock.</em></p>\n\n<p>Here at Clock we love ZFS, and have been running it in production on our Linux file servers for several years. It provides us with <a href=\"https://wiki.ubuntu.com/ZFS\">numerous excellent features</a>, such as snapshotting, incremental send/receive, and transparent compression. With the recent release of <a href=\"https://wiki.ubuntu.com/XenialXerus/ReleaseNotes\">Ubuntu Xenial 16.04</a> official support for <a href=\"https://insights.ubuntu.com/2016/02/16/zfs-is-the-fs-for-containers-in-ubuntu-16-04/\">ZFS is now here</a>, and we are keen to integrate it fully into our next generation hosting stack.</p>\n\n<p>As a Node.js and MongoDB house, one of our main concerns has been how MongoDB will perform on ZFS on Linux, especially after reading about <a href=\"http://serverfault.com/questions/583688/mongodb-and-zfs-bad-performance-disk-always-busy-with-reads-while-doing-only-wr\">potential problems</a> other people have faced. There really isn't much data out there to put our minds at rest.</p>\n\n<p>We decided to setup a method of benchmarking MongoDB with the supported EXT4 and XFS, then compare against ZFS with different options enabled. The idea being that we can hopefully figure out how ZFS compares, and if there are any options we can set that will impact the performance in any noticeable way. </p>\n\n<p>There are a few caveats to our testing, so we are aware that these results need to be taken with a pinch of salt. They are aimed at just providing an indicator as to the performance between the file systems, not being a definitive guide to which is best to use.</p>\n\n<h2 id=\"setup\">Setup</h2>\n\n<p>The main variable that may affect the results was the hardware that we chose to use. We spun up a 4GB Linode instance with four cores, and four virtual disks: one for the latest Ubuntu 15.10 image (which we then upgraded to 16.04), and one disk for each of the file systems that we intended to test, EXT4, XFS and ZFS.</p>\n\n<p>The issue with this approach is that the system is running on a virtualised machine with shared hardware, so there may be variations in the performance available to the machine. In an ideal world we would run this on a physical machine with identical disks, but that wasn't feasible for this investigation.</p>\n\n<p>We decided to use the latest stable version of MongoDB 3.2.5, ZFS was at version 0.6.5.6 provided by the zfsutils-linux package for Xenial.</p>\n\n<p>To benchmark the performance we investigated a few options, such as <a href=\"https://github.com/brianfrankcooper/YCSB\">YCSB</a>, and even writing our own benchmark based on examples of our real world data and queries. However we settled on using a Java-based tool, <a href=\"https://github.com/tmcallaghan/sysbench-mongodb\">sysbench-mongodb</a>. This made it easy to configure and run consistent and repeatable tests that would push the database to its limits. </p>\n\n<h2 id=\"methodology\">Methodology</h2>\n\n<p>First the drives were mounted to directories reflecting their filesystems, this made it easy to switch the file system that MongoDB was using.</p>\n\n<pre><code>Filesystem  Type  Size  Used  Avail  Use%  Mounted on  \n/dev/sda    ext4  7.7G  1.8G  5.5G   25%   /\n/dev/sdc    ext4   20G  44M   19G    1%    /ext4\n/dev/sdd    xfs    20G  33M   20G    1%    /xfs\ntank        zfs    19G  0M    19G    0%    /zfs  \n</code></pre>\n\n<p>The drives were setup and formatted with the default options of <code>mkfs.ext4</code> and <code>mkfs.xfs</code> and <code>zpool create</code>. I then wrote a script, <a href=\"https://gist.github.com/bag-man/95cc7cc7ad7046bbe2bc30f01c0f73bd\">that can be found here</a>, to utilise these disks with the sysbench-mongodb utility, and log the results. If you want to see the specific commands that we used, please have a look at the script.</p>\n\n<p>The way the script works is by destroying and recreating the ZFS volume with the option that is being tested, then starting a mongod instance, using the filesystems mount point as the dbpath. For example <code>mongod --directoryperdb --dbpath /zfs</code>. Then we simply run the sysbench-mongo script, and pull out the results of the run.</p>\n\n<p>The parameters we decided to test for ZFS are listed below:</p>\n\n<pre><code>Defaults (ashift = 0, recordsize = 128K, compression = off)  \nDefaults &amp; ashift = {9,12}  \nDefaults &amp; recordsize = {8KB,64KB}  \nDefaults &amp; compression = {lz4,gzip}  \n</code></pre>\n\n<p>We also edited the sysbench-mongodb config ever so slightly. We opted to use the <code>FSYNC_SAFE</code> write concern to ensure that the data was getting written to disk, and not just stored in RAM. We also reduced the number of documents per collection to <code>1,000,000</code> tenfold less than the default <code>10,000,000</code>. This was simply to save time on each “Load” step, something we aren't too concerned with as our applications are principally read-heavy.</p>\n\n<p>After running the benchmarks for each of the separate filesystems ten times and recording the  last cumulative average of the inserts per second for the “Load” stage of the benchmark, and the last cumulative average of the transactions per second for the “Execute” stage, we could create a representative average of the performance for each filesystem. </p>\n\n<h2 id=\"results\">Results</h2>\n\n<p><img src=\"https://i.imgur.com/or6Lskm.png\" alt=\"Results\" /></p>\n\n<p>You can download the <a href=\"http://downloads.clock.co.uk/mongo_on_zol-results.tar.xz\">raw data here</a> if you want to perform your own analysis of the results.</p>\n\n<p>As we suspected, ZFS doesn’t perform quite as well as the other filesystems, but it is worth noting that with the default settings it is only slightly slower. Most importantly, we didn’t uncover any show-stopping performance issues, as hinted in the discussions that are linked above. Unless you are looking to get the utmost performance in your queries, then ZFS certainly looks to be a viable option. Moreover, we feel that the benefits gained by utilising ZFS are more than worth the minor performance penalties. </p>\n\n<p>This investigation has been far from definitive, but hopefully has provided you with a rough overview of how these filesystems perform. If you know of ways to help us improve the results, or performance of MongoDB on ZFS, please do let us know, we are keen to hear your experiences!</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-12 15:24:11","created_by":1,"updated_at":"2017-02-16 15:02:32","updated_by":1,"published_at":"2017-02-12 15:24:39","published_by":1},{"id":5,"uuid":"27b2c942-58b0-4233-a026-68f1f7a6c559","title":"Mixxx for Swing DJ's - A quick guide","slug":"mixxx-for-swing-djs-a-quick-guide","markdown":"[Mixxx](http://www.mixxx.org/) is an open source program designed for electronic DJ's, and has a lot of features for specialist DJ hardware, and live mixing. Which is great and all, but for jazz music at a dance event all that stuff isn't really necessary. However it is great to be able to take advantage of some of the more basic functions that Mixxx provides that you won't find in other music players.\n\n### Installation\nMixxx is open source and available for all platforms, you can download it [here](http://www.mixxx.org/download/#stable) or install it via your package manager if you are on Linux. \n\n### Appearance\nOnce you have it installed it is easy to get put off by the large amount of buttons and options, however bear with it, we can make the UI a lot nicer to work with. \n\n![Default Mixxx skin](http://i.imgur.com/8GI3vtR.png)\n\nI recommend installing the [FlatNite theme](https://www.mixxx.org/forums/viewtopic.php?f=8&t=8578) by ronso, and then clicking the hamburger menu by the clock to toggle off the panels that you don't need, then you can make it look like this.\n\n![FlatNite Theme in minimal mode](http://i.imgur.com/OEMTqIc.png)\n\n\n### Usage\nThe way I organise my music on Mixxx is to create .m3u8 playlists, for each genre of music. This lets me manage my library really easily, and make it quick to find tracks for the right moments. \n\nFor the actual playing of the music I use the \"Auto DJ\" to queue up music. This means you don't have to worry about manually hitting play on tracks and managing the decks. Just find the track you want and right click > \"Add to Auto-DJ Queue (bottom)\". Then you can open the Auto-DJ tab and order the tracks in response to the dance floor.\n\nYou can also set a negative fade value to give a pause in between tracks so that dancers can find a new partner.\n\n![Auto-DJ in action](http://i.imgur.com/9fnZ5fs.png)\n\n### Previewing tracks\nOne of the most useful features of Mixxx is the ability to preview a track on a separate device. To do this you need to get a USB audio device for your laptop. I bought [this](https://www.amazon.co.uk/gp/product/B01J3QGU50/ref=oh_aui_detailpage_o00_s00?ie=UTF8&psc=1), which allows me to use my wired headphones to preview music and the laptops line out to play music on the venues system. \n\nTo set this up you need to configure your two audio devices to output the channels. Go to Options > Preferences > Sound Hardware, and select the headphone device.\n\n![Audio settings](http://i.imgur.com/NqFei1U.png)\n\nIf you enable the preview track panel in the FlatNite theme you will get an area above the search where you can scrub through the previewed track and adjust the volume. \n\n### BPM Detection, or lack of\nOne thing you might be tempted to do (as I was) is to use Mixxx's auto BPM detection to fill in the meta data of your jazz library for you. The issue with this is that Mixxx is designed for electronic music with fixed a BPM throughout the track, which means BPM detection doesn't really work for Jazz unfortunately. \n\n### EQ and Gain\nMixxx also lets you easily tweak the EQ and gain for the currently playing track. This is handy if you need to boost the treble or volume on an old recording. \n\n### Conclusion\nHopefully this has given you some reasons to try out Mixxx, I think for me the most daunting thing was the sheer number of options to worry about and having to manually manage the decks. Thankfully with the FlatNite theme, and the Auto-DJ feature it works really nicely for the basic needs of a Jazz DJ. \n\nIf you have any questions please let me know on the reddit thread in [/r/SwingDancing.](https://redd.it/5tiogq)\n\n:wq","mobiledoc":null,"html":"<p><a href=\"http://www.mixxx.org/\">Mixxx</a> is an open source program designed for electronic DJ's, and has a lot of features for specialist DJ hardware, and live mixing. Which is great and all, but for jazz music at a dance event all that stuff isn't really necessary. However it is great to be able to take advantage of some of the more basic functions that Mixxx provides that you won't find in other music players.</p>\n\n<h3 id=\"installation\">Installation</h3>\n\n<p>Mixxx is open source and available for all platforms, you can download it <a href=\"http://www.mixxx.org/download/#stable\">here</a> or install it via your package manager if you are on Linux. </p>\n\n<h3 id=\"appearance\">Appearance</h3>\n\n<p>Once you have it installed it is easy to get put off by the large amount of buttons and options, however bear with it, we can make the UI a lot nicer to work with. </p>\n\n<p><img src=\"http://i.imgur.com/8GI3vtR.png\" alt=\"Default Mixxx skin\" /></p>\n\n<p>I recommend installing the <a href=\"https://www.mixxx.org/forums/viewtopic.php?f=8&amp;t=8578\">FlatNite theme</a> by ronso, and then clicking the hamburger menu by the clock to toggle off the panels that you don't need, then you can make it look like this.</p>\n\n<p><img src=\"http://i.imgur.com/OEMTqIc.png\" alt=\"FlatNite Theme in minimal mode\" /></p>\n\n<h3 id=\"usage\">Usage</h3>\n\n<p>The way I organise my music on Mixxx is to create .m3u8 playlists, for each genre of music. This lets me manage my library really easily, and make it quick to find tracks for the right moments. </p>\n\n<p>For the actual playing of the music I use the \"Auto DJ\" to queue up music. This means you don't have to worry about manually hitting play on tracks and managing the decks. Just find the track you want and right click > \"Add to Auto-DJ Queue (bottom)\". Then you can open the Auto-DJ tab and order the tracks in response to the dance floor.</p>\n\n<p>You can also set a negative fade value to give a pause in between tracks so that dancers can find a new partner.</p>\n\n<p><img src=\"http://i.imgur.com/9fnZ5fs.png\" alt=\"Auto-DJ in action\" /></p>\n\n<h3 id=\"previewingtracks\">Previewing tracks</h3>\n\n<p>One of the most useful features of Mixxx is the ability to preview a track on a separate device. To do this you need to get a USB audio device for your laptop. I bought <a href=\"https://www.amazon.co.uk/gp/product/B01J3QGU50/ref=oh_aui_detailpage_o00_s00?ie=UTF8&amp;psc=1\">this</a>, which allows me to use my wired headphones to preview music and the laptops line out to play music on the venues system. </p>\n\n<p>To set this up you need to configure your two audio devices to output the channels. Go to Options > Preferences > Sound Hardware, and select the headphone device.</p>\n\n<p><img src=\"http://i.imgur.com/NqFei1U.png\" alt=\"Audio settings\" /></p>\n\n<p>If you enable the preview track panel in the FlatNite theme you will get an area above the search where you can scrub through the previewed track and adjust the volume. </p>\n\n<h3 id=\"bpmdetectionorlackof\">BPM Detection, or lack of</h3>\n\n<p>One thing you might be tempted to do (as I was) is to use Mixxx's auto BPM detection to fill in the meta data of your jazz library for you. The issue with this is that Mixxx is designed for electronic music with fixed a BPM throughout the track, which means BPM detection doesn't really work for Jazz unfortunately. </p>\n\n<h3 id=\"eqandgain\">EQ and Gain</h3>\n\n<p>Mixxx also lets you easily tweak the EQ and gain for the currently playing track. This is handy if you need to boost the treble or volume on an old recording. </p>\n\n<h3 id=\"conclusion\">Conclusion</h3>\n\n<p>Hopefully this has given you some reasons to try out Mixxx, I think for me the most daunting thing was the sheer number of options to worry about and having to manually manage the decks. Thankfully with the FlatNite theme, and the Auto-DJ feature it works really nicely for the basic needs of a Jazz DJ. </p>\n\n<p>If you have any questions please let me know on the reddit thread in <a href=\"https://redd.it/5tiogq\">/r/SwingDancing.</a></p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-12 15:25:17","created_by":1,"updated_at":"2017-02-16 15:02:20","updated_by":1,"published_at":"2017-02-12 15:25:26","published_by":1},{"id":6,"uuid":"ccc04a13-9061-44fe-aaa7-4acb991648f9","title":"Traditional Jazz Primer","slug":"traditional-jazz-primer","markdown":"I'm a Lindy Hop dancer and thankfully that has exposed me to the very niche genre of Traditional Jazz, Trad for short. It can also be referred to as Hot Jazz, Dixieland Jazz or NOLA / New Orleans Jazz, although the latter is usually a slightly different sound. Trad Jazz appears to be the most agreed upon term though. I'd also like to say, I'm not an expert, just some guy that loves listening and dancing to some of the best musicians in the world. \n\n## History\nTrad Jazz is the original Jazz that was first played in the early 1900's, some songs even going back to the 1890's such as [Maple Leaf Rag](https://www.youtube.com/watch?v=pMAtL7n_-rc) which was recorded in 1899! These early songs became [Jazz Standards](https://en.wikipedia.org/wiki/Jazz_standard) which are quite universally known by Jazz musicians today. For example here is Maple Leaf Rag [being played by the wonderful Tuba Skinny](https://youtu.be/kYJhgz4L3UU?t=22) a couple of years ago.\n\nPart of the iconic roaring 20's sound was the American Jazz, made popular by artists such as [Bix Beiderbecke](https://en.wikipedia.org/wiki/Bix_Beiderbecke) and [King Oliver](https://en.wikipedia.org/wiki/King_Oliver). \n\n![King Oliver](http://img.timeinc.net/time/2002/bhm/history/images/armstrong.jpg)\n\nAs the popularity of Jazz grew in the 30's, it strayed further from it's roots in New Orleans, and started to grow into bigger bands that could fill much larger venues. This was the start of the Big Band sound, however musicians like [Sidney Bechet](https://en.wikipedia.org/wiki/Sidney_Bechet) still kept the Trad sound with wild solo's and improvisations. \n\nAs we enter the 40's the popular music of the time had transitioned into full a Big Band sound, with the likes of [Glenn Miller](https://en.wikipedia.org/wiki/Glenn_Miller) and [Benny Goodman](https://en.wikipedia.org/wiki/Benny_Goodman). This to me is where Trad Jazz became sidelined to the big bands of the time. \n\nToday, there is a resurgence of Trad Jazz bands, a lot of them cater specifically to the dancing community, and very few get any recognition outside of it. The upside to that is if you go to see a band there is a good chance you can have a beer with them afterwards!\n\n## Recommendations\nIf you want the best of modern recordings and New Orleans style, about as traditional as you can get, [Tuba Skinny](https://tubaskinny.bandcamp.com/) is the place to go. They have an extensive catalogue, and are to me, one of the best bands currently performing. This clip has some mad washboard solo's, which isn't everyone's cup of tea, but it has grown on me!\n\n[![Tuba Skinny Live](https://img.youtube.com/vi/FFChHrOP3D8/0.jpg)](https://www.youtube.com/watch?v=FFChHrOP3D8)\n\nThe video that got me into this style of music was a battle of the bands between the Stockholm Swing All Stars and The Gordon Webster Band at Snowball. \n\n[![Snowball Battle of the bands](https://img.youtube.com/vi/IWr_miwwE3w/0.jpg)](https://www.youtube.com/watch?v=IWr_miwwE3w&feature=youtu.be&t=43m23s)\n\nMy favourite clip is of Gentlemen and Gangsters, jamming with Shirt Tail Stompers, at a Lindy Exchange in Copenhagen. It happens to be my favourite song, and the solos are just so perfect. It is amazing to see them improvising so naturally.\n\n[![CLX Battle of the bands](https://img.youtube.com/vi/QLhcXJ9XBAE/0.jpg)](https://www.youtube.com/watch?v=QLhcXJ9XBAE)\n\n## Listening Resources\nFor original recordings from the era, the best place to look is [Jazz On Line](http://www.jazz-on-line.com/). It has a huge database of music that has been taken from 78's and uploaded to the site. Thankfully the music is (mostly) in the public domain now so it is free to access and use. However the site is rather old and unfriendly to use, so it make take some patience!\n\nModern bands tend to have their music on [bandcamp](https://bandcamp.com/), which is a great way to get DRM free music and directly support the bands that you love. The bands that aren't on it tend to have their music for sale physically via their website or CD reselling sites. \n\nIf you are interested in seeing a band live (I highly recommend it!) you should see if there is a Lindy Hop or Swing Dance event near you (There probably is), as a good event will have drawn out some quality musicians. \n\n## Musicians\nThis is a list of the bands that I listen to most, I've tried to link directly to their music, but often it is quite difficult so where I wasn't able to, I've linked to YouTube.\n\n* **[Aurora Nealand](http://auroranealand.bandcamp.com)** \n* **[Hot Jazz Aliance](https://barkingmadmusic.bandcamp.com/)** \n* **[Bix Beiderbecke](http://jazz-on-line.com/artists/Bix_Beiderbecke.htm)** \n* **[Vince Giordano](https://www.youtube.com/watch?v=8-mw6_W5Vqk)**\n* **[Dizzy Birds](https://dizzybirds.bandcamp.com/)**\n* **[Duke Ellington](http://jazz-on-line.com/artists/Duke_Ellington.htm)**\n* **[Eddie Condon](https://www.youtube.com/watch?v=OZnHaXgVFJY)**\n* **[Gentlemen and Gangsters](https://gentlemenandgangsters.bandcamp.com/)**\n* **[Carling Family Band](https://www.youtube.com/user/CarlingJazz)**\n* **[Gordon Webster](https://www.cdbaby.com/Search/R29yZG9uIFdlYnN0ZXI%3d/0)**\n* **[Stockholm Swing All Stars](http://www.stockholmswingallstars.com/listen/)**\n* **[Kid Ory](http://jazz-on-line.com/artists/Kid_Ory.htm)**\n* **[King Oliver](http://jazz-on-line.com/artists/King_Oliver.htm)**\n* **[Naomi and Her Handsome Devils](http://naomisdevils.bandcamp.com/)**\n* **[Patty and the Buttons](https://pattyandthebuttons.bandcamp.com/)**\n* **[Perseverance Jazz Band](https://perseverancejazzband.bandcamp.com/)**\n* **[Preservation Hall Jazz Band](https://www.preservationhalljazzband.com/releases)**\n* **[Shirt Tail Stompers](https://shirttailstompers.bandcamp.com/album/milenburg-joys)**\n* **[Shotgun Jazz Band](https://shotgunjazzband.bandcamp.com/)**\n* **[Sidney Bechet](https://www.youtube.com/watch?v=m-ZLsyc8EhM)**\n* **[Southside Aces](https://southsideaces.bandcamp.com/)**\n* **[The Fat Babies](http://www.thefatbabies.com/)**\n* **[The Harlem Hamfats](https://www.youtube.com/watch?v=XPNS3ACP9Kw)**\n* **[Thrift Set Orchestra](https://thriftset.bandcamp.com/releases)**\n* **[Tuba Skinny](https://tubaskinny.bandcamp.com/)**\n\nI hope this has been useful to you if you are exploring the world of Trad, or even better it has been eye opening to a whole world of new music to investigate!\n\nDrop a comment on the [reddit thread](https://redd.it/5tmw5h) if you have questions!\n\n:wq","mobiledoc":null,"html":"<p>I'm a Lindy Hop dancer and thankfully that has exposed me to the very niche genre of Traditional Jazz, Trad for short. It can also be referred to as Hot Jazz, Dixieland Jazz or NOLA / New Orleans Jazz, although the latter is usually a slightly different sound. Trad Jazz appears to be the most agreed upon term though. I'd also like to say, I'm not an expert, just some guy that loves listening and dancing to some of the best musicians in the world. </p>\n\n<h2 id=\"history\">History</h2>\n\n<p>Trad Jazz is the original Jazz that was first played in the early 1900's, some songs even going back to the 1890's such as <a href=\"https://www.youtube.com/watch?v=pMAtL7n_-rc\">Maple Leaf Rag</a> which was recorded in 1899! These early songs became <a href=\"https://en.wikipedia.org/wiki/Jazz_standard\">Jazz Standards</a> which are quite universally known by Jazz musicians today. For example here is Maple Leaf Rag <a href=\"https://youtu.be/kYJhgz4L3UU?t=22\">being played by the wonderful Tuba Skinny</a> a couple of years ago.</p>\n\n<p>Part of the iconic roaring 20's sound was the American Jazz, made popular by artists such as <a href=\"https://en.wikipedia.org/wiki/Bix_Beiderbecke\">Bix Beiderbecke</a> and <a href=\"https://en.wikipedia.org/wiki/King_Oliver\">King Oliver</a>. </p>\n\n<p><img src=\"http://img.timeinc.net/time/2002/bhm/history/images/armstrong.jpg\" alt=\"King Oliver\" /></p>\n\n<p>As the popularity of Jazz grew in the 30's, it strayed further from it's roots in New Orleans, and started to grow into bigger bands that could fill much larger venues. This was the start of the Big Band sound, however musicians like <a href=\"https://en.wikipedia.org/wiki/Sidney_Bechet\">Sidney Bechet</a> still kept the Trad sound with wild solo's and improvisations. </p>\n\n<p>As we enter the 40's the popular music of the time had transitioned into full a Big Band sound, with the likes of <a href=\"https://en.wikipedia.org/wiki/Glenn_Miller\">Glenn Miller</a> and <a href=\"https://en.wikipedia.org/wiki/Benny_Goodman\">Benny Goodman</a>. This to me is where Trad Jazz became sidelined to the big bands of the time. </p>\n\n<p>Today, there is a resurgence of Trad Jazz bands, a lot of them cater specifically to the dancing community, and very few get any recognition outside of it. The upside to that is if you go to see a band there is a good chance you can have a beer with them afterwards!</p>\n\n<h2 id=\"recommendations\">Recommendations</h2>\n\n<p>If you want the best of modern recordings and New Orleans style, about as traditional as you can get, <a href=\"https://tubaskinny.bandcamp.com/\">Tuba Skinny</a> is the place to go. They have an extensive catalogue, and are to me, one of the best bands currently performing. This clip has some mad washboard solo's, which isn't everyone's cup of tea, but it has grown on me!</p>\n\n<p><a href=\"https://www.youtube.com/watch?v=FFChHrOP3D8\"><img src=\"https://img.youtube.com/vi/FFChHrOP3D8/0.jpg\" alt=\"Tuba Skinny Live\" title=\"\" /></a></p>\n\n<p>The video that got me into this style of music was a battle of the bands between the Stockholm Swing All Stars and The Gordon Webster Band at Snowball. </p>\n\n<p><a href=\"https://www.youtube.com/watch?v=IWr_miwwE3w&amp;feature=youtu.be&amp;t=43m23s\"><img src=\"https://img.youtube.com/vi/IWr_miwwE3w/0.jpg\" alt=\"Snowball Battle of the bands\" title=\"\" /></a></p>\n\n<p>My favourite clip is of Gentlemen and Gangsters, jamming with Shirt Tail Stompers, at a Lindy Exchange in Copenhagen. It happens to be my favourite song, and the solos are just so perfect. It is amazing to see them improvising so naturally.</p>\n\n<p><a href=\"https://www.youtube.com/watch?v=QLhcXJ9XBAE\"><img src=\"https://img.youtube.com/vi/QLhcXJ9XBAE/0.jpg\" alt=\"CLX Battle of the bands\" title=\"\" /></a></p>\n\n<h2 id=\"listeningresources\">Listening Resources</h2>\n\n<p>For original recordings from the era, the best place to look is <a href=\"http://www.jazz-on-line.com/\">Jazz On Line</a>. It has a huge database of music that has been taken from 78's and uploaded to the site. Thankfully the music is (mostly) in the public domain now so it is free to access and use. However the site is rather old and unfriendly to use, so it make take some patience!</p>\n\n<p>Modern bands tend to have their music on <a href=\"https://bandcamp.com/\">bandcamp</a>, which is a great way to get DRM free music and directly support the bands that you love. The bands that aren't on it tend to have their music for sale physically via their website or CD reselling sites. </p>\n\n<p>If you are interested in seeing a band live (I highly recommend it!) you should see if there is a Lindy Hop or Swing Dance event near you (There probably is), as a good event will have drawn out some quality musicians. </p>\n\n<h2 id=\"musicians\">Musicians</h2>\n\n<p>This is a list of the bands that I listen to most, I've tried to link directly to their music, but often it is quite difficult so where I wasn't able to, I've linked to YouTube.</p>\n\n<ul>\n<li><strong><a href=\"http://auroranealand.bandcamp.com\">Aurora Nealand</a></strong> </li>\n<li><strong><a href=\"https://barkingmadmusic.bandcamp.com/\">Hot Jazz Aliance</a></strong> </li>\n<li><strong><a href=\"http://jazz-on-line.com/artists/Bix_Beiderbecke.htm\">Bix Beiderbecke</a></strong> </li>\n<li><strong><a href=\"https://www.youtube.com/watch?v=8-mw6_W5Vqk\">Vince Giordano</a></strong></li>\n<li><strong><a href=\"https://dizzybirds.bandcamp.com/\">Dizzy Birds</a></strong></li>\n<li><strong><a href=\"http://jazz-on-line.com/artists/Duke_Ellington.htm\">Duke Ellington</a></strong></li>\n<li><strong><a href=\"https://www.youtube.com/watch?v=OZnHaXgVFJY\">Eddie Condon</a></strong></li>\n<li><strong><a href=\"https://gentlemenandgangsters.bandcamp.com/\">Gentlemen and Gangsters</a></strong></li>\n<li><strong><a href=\"https://www.youtube.com/user/CarlingJazz\">Carling Family Band</a></strong></li>\n<li><strong><a href=\"https://www.cdbaby.com/Search/R29yZG9uIFdlYnN0ZXI%3d/0\">Gordon Webster</a></strong></li>\n<li><strong><a href=\"http://www.stockholmswingallstars.com/listen/\">Stockholm Swing All Stars</a></strong></li>\n<li><strong><a href=\"http://jazz-on-line.com/artists/Kid_Ory.htm\">Kid Ory</a></strong></li>\n<li><strong><a href=\"http://jazz-on-line.com/artists/King_Oliver.htm\">King Oliver</a></strong></li>\n<li><strong><a href=\"http://naomisdevils.bandcamp.com/\">Naomi and Her Handsome Devils</a></strong></li>\n<li><strong><a href=\"https://pattyandthebuttons.bandcamp.com/\">Patty and the Buttons</a></strong></li>\n<li><strong><a href=\"https://perseverancejazzband.bandcamp.com/\">Perseverance Jazz Band</a></strong></li>\n<li><strong><a href=\"https://www.preservationhalljazzband.com/releases\">Preservation Hall Jazz Band</a></strong></li>\n<li><strong><a href=\"https://shirttailstompers.bandcamp.com/album/milenburg-joys\">Shirt Tail Stompers</a></strong></li>\n<li><strong><a href=\"https://shotgunjazzband.bandcamp.com/\">Shotgun Jazz Band</a></strong></li>\n<li><strong><a href=\"https://www.youtube.com/watch?v=m-ZLsyc8EhM\">Sidney Bechet</a></strong></li>\n<li><strong><a href=\"https://southsideaces.bandcamp.com/\">Southside Aces</a></strong></li>\n<li><strong><a href=\"http://www.thefatbabies.com/\">The Fat Babies</a></strong></li>\n<li><strong><a href=\"https://www.youtube.com/watch?v=XPNS3ACP9Kw\">The Harlem Hamfats</a></strong></li>\n<li><strong><a href=\"https://thriftset.bandcamp.com/releases\">Thrift Set Orchestra</a></strong></li>\n<li><strong><a href=\"https://tubaskinny.bandcamp.com/\">Tuba Skinny</a></strong></li>\n</ul>\n\n<p>I hope this has been useful to you if you are exploring the world of Trad, or even better it has been eye opening to a whole world of new music to investigate!</p>\n\n<p>Drop a comment on the <a href=\"https://redd.it/5tmw5h\">reddit thread</a> if you have questions!</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-12 16:00:55","created_by":1,"updated_at":"2017-02-16 15:01:42","updated_by":1,"published_at":"2017-02-12 17:59:24","published_by":1},{"id":7,"uuid":"6ae462b2-56f8-446d-966f-16c9d6dd3131","title":"HJKL all the things!","slug":"hjkl-all-the-things","markdown":"If you are a Vim user, you will hopefully have been using HJKL and to navigate your documents, rather than the arrow keys. However I like to take this idea a little further. Well, a lot further. \n\n## But why? \nIt can seem like an odd thing to someone who has never tried it, however the more you use it the more you notice the micro inefficiencies that come from reaching for a mouse, or even the arrow keys. \n\nMy thinking is, if I can save a few seconds every day from having my fingertips where they need to be, over a life time that makes a difference! Plus it looks cool to whizz around your system without moving a muscle from your keyboard.\n\nOn my Chromebook I have three modifier keys, Ctrl + Alt + Shift, when we combine those with HJKL we end up with 32 key combinations. Add to that different contexts in different applications, there should never be a reason to leave the home row!\n\n\n## Vimium / VimFX\nTo use HJKL in your browser, doesn't require that much of a configuration or change to your system at all. Just install [Vimium](https://chrome.google.com/webstore/detail/vimium/dbepggeogbaibhgnhhndojpepiihcmeb?hl=en) for Chrome, or [VimFX](https://addons.mozilla.org/en-GB/firefox/addon/vimfx/) for Firefox. \n\nNow you can scroll pages with `hjkl`, go backwards and forwards with `H` & `L`, and switch tab with `J` and `K`. To click links, you use `f` for current tab or `F` for new tab. Then you type the letters that are on the link that you want to go to. \n\n![Vimium links](/content/images/2017/02/shot-2.png)\n\nIt takes a bit of getting used to, but once you get the hang of it, you can navigate so much quicker for most basic web browsing. It helps you practice touch typing too!\n\n\n\n## Vim\nEveryone's vim setup and workflow is different, but to tie in with my HJKL theme, I've tweaked a few things. Firstly, I mapped `J` and `K` to mimic the changing of tabs in Vimium. This is probably a controversial move, as you have to rebind the `J` key, I chose to use `M`erge lines.\n\n    nnoremap J :tabprev<CR>\n    nnoremap K :tabnext<CR>\n    nnoremap M J\n\nThe next thing I did was to enable `j` & `k` to work in drop down auto complete lists. This makes it easier to select items without moving your fingers.\n\n    inoremap <expr> j ((pumvisible())?(\"\\<C-n>\"):(\"j\"))\n    inoremap <expr> k ((pumvisible())?(\"\\<C-p>\"):(\"k\"))\n    inoremap <expr> <tab> ((pumvisible())?(\"\\<Cr>\"):(\"<Cr>\"))\n\n![Vim auto complete menu](/content/images/2017/02/shot-3.png)\n\nI also found it really handy to map `H` & `L` to jump to the beginning and ends of lines. \n\n    nnoremap H ^\n    nnoremap L $\n\n## Tiling Window Manager / Xmonad\nOn my systems I run a tiling window manager called Xmonad. Below I will give the bindings specific to Xmonad, but hopefully you can see the idea I'm getting at and apply it to your own DE / WM if you  fancy giving this a try. \n\n    -- Adjust split\n    ((mod1Mask, xK_j), sendMessage MirrorShrink),\n    ((mod1Mask, xK_k), sendMessage MirrorExpand),\n    \n    -- Workspaces\n    ((controlMask .|. mod1Mask, xK_l), nextWS),\n    ((controlMask .|. mod1Mask, xK_h), prevWS),\n    ((mod1Mask .|. shiftMask, xK_l), shiftToNext >> nextWS),\n    ((mod1Mask .|. shiftMask, xK_h), shiftToPrev >> prevWS),\n\nWhat this lets me do is resize my current window with `Alt` + `h/j/k/l`, move the current window around the workspace with `Shift` + `Alt` + `J/K`, or move it to another workspace with `Shift` + `Alt` + `H/L`. I can then also shift workspaces with `Ctrl` + `h/l`.\n\nThis means that if I have Vim on one workspace, and Chrome on the other, I can seamlessly move between them and interact with them, without moving my fingers at all! \n\n## Conclusion\nAfter having lived with this setup for the better part of two years, I am pretty happy with it, although I'm always looking for some ways to improve it, as well as a few bugs to solve. One of the most rage inducing bugs is in Chrome, viewing a PDF will stop Vimium from running, meaning you can get stuck on a tab. \n\nIf you give this a try, I'd be interested to hear how you find it, hopefully you will really notice those times you are forced to use the mouse or arrow keys. \n\nMy [dotfiles](https://github.com/bag-man/dotfiles) have a lot more configurations, so if you want to get the bigger picture check them out. \n\n:wq","mobiledoc":null,"html":"<p>If you are a Vim user, you will hopefully have been using HJKL and to navigate your documents, rather than the arrow keys. However I like to take this idea a little further. Well, a lot further. </p>\n\n<h2 id=\"butwhy\">But why?</h2>\n\n<p>It can seem like an odd thing to someone who has never tried it, however the more you use it the more you notice the micro inefficiencies that come from reaching for a mouse, or even the arrow keys. </p>\n\n<p>My thinking is, if I can save a few seconds every day from having my fingertips where they need to be, over a life time that makes a difference! Plus it looks cool to whizz around your system without moving a muscle from your keyboard.</p>\n\n<p>On my Chromebook I have three modifier keys, Ctrl + Alt + Shift, when we combine those with HJKL we end up with 32 key combinations. Add to that different contexts in different applications, there should never be a reason to leave the home row!</p>\n\n<h2 id=\"vimiumvimfx\">Vimium / VimFX</h2>\n\n<p>To use HJKL in your browser, doesn't require that much of a configuration or change to your system at all. Just install <a href=\"https://chrome.google.com/webstore/detail/vimium/dbepggeogbaibhgnhhndojpepiihcmeb?hl=en\">Vimium</a> for Chrome, or <a href=\"https://addons.mozilla.org/en-GB/firefox/addon/vimfx/\">VimFX</a> for Firefox. </p>\n\n<p>Now you can scroll pages with <code>hjkl</code>, go backwards and forwards with <code>H</code> &amp; <code>L</code>, and switch tab with <code>J</code> and <code>K</code>. To click links, you use <code>f</code> for current tab or <code>F</code> for new tab. Then you type the letters that are on the link that you want to go to. </p>\n\n<p><img src=\"/content/images/2017/02/shot-2.png\" alt=\"Vimium links\" /></p>\n\n<p>It takes a bit of getting used to, but once you get the hang of it, you can navigate so much quicker for most basic web browsing. It helps you practice touch typing too!</p>\n\n<h2 id=\"vim\">Vim</h2>\n\n<p>Everyone's vim setup and workflow is different, but to tie in with my HJKL theme, I've tweaked a few things. Firstly, I mapped <code>J</code> and <code>K</code> to mimic the changing of tabs in Vimium. This is probably a controversial move, as you have to rebind the <code>J</code> key, I chose to use <code>M</code>erge lines.</p>\n\n<pre><code>nnoremap J :tabprev&lt;CR&gt;\nnnoremap K :tabnext&lt;CR&gt;\nnnoremap M J\n</code></pre>\n\n<p>The next thing I did was to enable <code>j</code> &amp; <code>k</code> to work in drop down auto complete lists. This makes it easier to select items without moving your fingers.</p>\n\n<pre><code>inoremap &lt;expr&gt; j ((pumvisible())?(\"\\&lt;C-n&gt;\"):(\"j\"))\ninoremap &lt;expr&gt; k ((pumvisible())?(\"\\&lt;C-p&gt;\"):(\"k\"))\ninoremap &lt;expr&gt; &lt;tab&gt; ((pumvisible())?(\"\\&lt;Cr&gt;\"):(\"&lt;Cr&gt;\"))\n</code></pre>\n\n<p><img src=\"/content/images/2017/02/shot-3.png\" alt=\"Vim auto complete menu\" /></p>\n\n<p>I also found it really handy to map <code>H</code> &amp; <code>L</code> to jump to the beginning and ends of lines. </p>\n\n<pre><code>nnoremap H ^\nnnoremap L $\n</code></pre>\n\n<h2 id=\"tilingwindowmanagerxmonad\">Tiling Window Manager / Xmonad</h2>\n\n<p>On my systems I run a tiling window manager called Xmonad. Below I will give the bindings specific to Xmonad, but hopefully you can see the idea I'm getting at and apply it to your own DE / WM if you  fancy giving this a try. </p>\n\n<pre><code>-- Adjust split\n((mod1Mask, xK_j), sendMessage MirrorShrink),\n((mod1Mask, xK_k), sendMessage MirrorExpand),\n\n-- Workspaces\n((controlMask .|. mod1Mask, xK_l), nextWS),\n((controlMask .|. mod1Mask, xK_h), prevWS),\n((mod1Mask .|. shiftMask, xK_l), shiftToNext &gt;&gt; nextWS),\n((mod1Mask .|. shiftMask, xK_h), shiftToPrev &gt;&gt; prevWS),\n</code></pre>\n\n<p>What this lets me do is resize my current window with <code>Alt</code> + <code>h/j/k/l</code>, move the current window around the workspace with <code>Shift</code> + <code>Alt</code> + <code>J/K</code>, or move it to another workspace with <code>Shift</code> + <code>Alt</code> + <code>H/L</code>. I can then also shift workspaces with <code>Ctrl</code> + <code>h/l</code>.</p>\n\n<p>This means that if I have Vim on one workspace, and Chrome on the other, I can seamlessly move between them and interact with them, without moving my fingers at all! </p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>After having lived with this setup for the better part of two years, I am pretty happy with it, although I'm always looking for some ways to improve it, as well as a few bugs to solve. One of the most rage inducing bugs is in Chrome, viewing a PDF will stop Vimium from running, meaning you can get stuck on a tab. </p>\n\n<p>If you give this a try, I'd be interested to hear how you find it, hopefully you will really notice those times you are forced to use the mouse or arrow keys. </p>\n\n<p>My <a href=\"https://github.com/bag-man/dotfiles\">dotfiles</a> have a lot more configurations, so if you want to get the bigger picture check them out. </p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-12 19:09:52","created_by":1,"updated_at":"2017-02-16 15:01:28","updated_by":1,"published_at":"2017-02-12 19:48:57","published_by":1},{"id":8,"uuid":"924af795-a774-440d-9d65-2b90b0a41abf","title":"[Project Log #1] Today I found out rm can only take 100,000 arguments at a time...","slug":"project-log-today-i-found-out-rm-can-only-take-100-000-arguments-at-a-time","markdown":"I've just began working on my final year project, and was advised to document my progress in a diary or blog, so here we go. \n\nMy project is going to be based around genomic data that has been sequenced from three strains of yeast. The plan is to annotate the sequenced contigs of DNA, and then compare them against each other to see where the genes of the yeasts differ. \n\n![Candida Tropicalis](https://classconnection.s3.amazonaws.com/192/flashcards/1534192/png/screen_shot_2013-04-22_at_80924_pm1366675786179.png)\n\nThis will hopefully help the researchers understand what genes are responsible for certain characteristics of the yeasts, and enable them to modify one of the species to perform a more useful function. \n\n## Playing with alignment tools\nAfter getting the data, I began to experiment with different tools and getting used to working with the [fasta](https://en.wikipedia.org/wiki/FASTA_format) format. \n\nThe most commonly used tool for gene alignment is [blast](https://blast.ncbi.nlm.nih.gov/Blast.cgi), however it was written in 1990 originally and is over 600MB's to install. So I would like to look into more modern tools, in the hopes of speeding up the time it takes to align the sequences. \n\nI started by downloading the 66GB [NCBI nr database](https://www.ncbi.nlm.nih.gov/refseq/about/nonredundantproteins), it is a fasta file that contains a collection of known genes that have been annotated. This is what I will use to query the yeast contigs against. \n\nI started out by using [diamond](https://github.com/bbuchfink/diamond), which works just like blast, however it is much more modern and runs a claimed 20,000 times faster! The first step in using diamond for alignment is to take your reference sequences and create a database from that for your queries to be ran against.\n\n![Running diamond on the makedb 33Mins](/content/images/2017/02/shot-4.png)\n\nThis took me 33 minutes to do for the whole NCBI nr database, which didn't seem too bad. I then ran an alignment with the 16MB of sequenced yeast contigs, against this database.\n\n![Running diamond against Candida_Y4 for the first time 75mins](/content/images/2017/02/shot-5.png)\n\nThat took 75 minutes to run and produced some useful (I hope!) data. \n\nI should mention the hardware that I am running this on, as the times are meaningless with out that. My home PC has a i7-6700k @ 4.6Ghz, 16GB of RAM, a GTX 980 and unfortunately I didn't have an SSD big enough for this data, so I'm having to use my HDD which is probably causing a lot of bottlenecks.\n\nNow that I know I can run an alignment with diamond in a reasonable time, I wanted to explore the options of using a GPU accelerated alignment tool in the hopes that this would allow for much faster alignment times. I first tried [BarraCUDA](http://seqbarracuda.sourceforge.net/), it installed fine but would appear to try and read the entire reference database (64GB) into my 16GB of RAM, and then crash, so this wasn't a good start. \n\nI then tried [CLAST](https://github.com/masayano/CLAST), but was unable to successfully compile due to a C++ error that looked like a rabbit hole I really didn't want to go down. Next up was [cudasw++](cudasw.sourceforge.net/), this installed fine but again, like BarraCUDA, it would attempt to read the whole reference file into memory. \n\nStarting to see a theme here... Perhaps having one monolithic 64GB file isn't the best way to go about business. I decided to split the file up into six chunks to make it more manageable. Oddly this proved a lot more difficult than you would think. Several of the solutions I tried like pyfasta would read the whole file into memory again, which seems like a slight design oversight.\n\nI then tried [faSplit](https://github.com/jstjohn/KentLib/blob/master/examples/faSplit/faSplit.c), which appeared to be working well, it created three 12GB files, and then hundreds of thousands of ~300byte files. This is how I found out that `rm` can only take 100,000 arguments at a time. Not wanting to deal with cleaning up nearly a million files again I decided to try and use [genome tools](genometools.org/).\n\nMercifully, it worked perfectly. Although it did take quite a long time, but writing 64GB's to disk is never going to be fast with a mechanical drive. \n\nI now had 11GB chunks of the nr database, so I decided to try cudasw++ again, however it segfaulted as it did before. I then went back to BarraCUDA and it also segfaulted. In one last ditch effort I split one of the 11GB files in half and tried again, but it still segfaulted in both applications.\n\nLooks like there is a lot more work to go into getting GPU accelerated alignment than I had hoped. I'll probably just stick with diamond because of this.\n\n:wq","mobiledoc":null,"html":"<p>I've just began working on my final year project, and was advised to document my progress in a diary or blog, so here we go. </p>\n\n<p>My project is going to be based around genomic data that has been sequenced from three strains of yeast. The plan is to annotate the sequenced contigs of DNA, and then compare them against each other to see where the genes of the yeasts differ. </p>\n\n<p><img src=\"https://classconnection.s3.amazonaws.com/192/flashcards/1534192/png/screen_shot_2013-04-22_at_80924_pm1366675786179.png\" alt=\"Candida Tropicalis\" /></p>\n\n<p>This will hopefully help the researchers understand what genes are responsible for certain characteristics of the yeasts, and enable them to modify one of the species to perform a more useful function. </p>\n\n<h2 id=\"playingwithalignmenttools\">Playing with alignment tools</h2>\n\n<p>After getting the data, I began to experiment with different tools and getting used to working with the <a href=\"https://en.wikipedia.org/wiki/FASTA_format\">fasta</a> format. </p>\n\n<p>The most commonly used tool for gene alignment is <a href=\"https://blast.ncbi.nlm.nih.gov/Blast.cgi\">blast</a>, however it was written in 1990 originally and is over 600MB's to install. So I would like to look into more modern tools, in the hopes of speeding up the time it takes to align the sequences. </p>\n\n<p>I started by downloading the 66GB <a href=\"https://www.ncbi.nlm.nih.gov/refseq/about/nonredundantproteins\">NCBI nr database</a>, it is a fasta file that contains a collection of known genes that have been annotated. This is what I will use to query the yeast contigs against. </p>\n\n<p>I started out by using <a href=\"https://github.com/bbuchfink/diamond\">diamond</a>, which works just like blast, however it is much more modern and runs a claimed 20,000 times faster! The first step in using diamond for alignment is to take your reference sequences and create a database from that for your queries to be ran against.</p>\n\n<p><img src=\"/content/images/2017/02/shot-4.png\" alt=\"Running diamond on the makedb 33Mins\" /></p>\n\n<p>This took me 33 minutes to do for the whole NCBI nr database, which didn't seem too bad. I then ran an alignment with the 16MB of sequenced yeast contigs, against this database.</p>\n\n<p><img src=\"/content/images/2017/02/shot-5.png\" alt=\"Running diamond against Candida_Y4 for the first time 75mins\" /></p>\n\n<p>That took 75 minutes to run and produced some useful (I hope!) data. </p>\n\n<p>I should mention the hardware that I am running this on, as the times are meaningless with out that. My home PC has a i7-6700k @ 4.6Ghz, 16GB of RAM, a GTX 980 and unfortunately I didn't have an SSD big enough for this data, so I'm having to use my HDD which is probably causing a lot of bottlenecks.</p>\n\n<p>Now that I know I can run an alignment with diamond in a reasonable time, I wanted to explore the options of using a GPU accelerated alignment tool in the hopes that this would allow for much faster alignment times. I first tried <a href=\"http://seqbarracuda.sourceforge.net/\">BarraCUDA</a>, it installed fine but would appear to try and read the entire reference database (64GB) into my 16GB of RAM, and then crash, so this wasn't a good start. </p>\n\n<p>I then tried <a href=\"https://github.com/masayano/CLAST\">CLAST</a>, but was unable to successfully compile due to a C++ error that looked like a rabbit hole I really didn't want to go down. Next up was <a href=\"cudasw.sourceforge.net/\">cudasw++</a>, this installed fine but again, like BarraCUDA, it would attempt to read the whole reference file into memory. </p>\n\n<p>Starting to see a theme here... Perhaps having one monolithic 64GB file isn't the best way to go about business. I decided to split the file up into six chunks to make it more manageable. Oddly this proved a lot more difficult than you would think. Several of the solutions I tried like pyfasta would read the whole file into memory again, which seems like a slight design oversight.</p>\n\n<p>I then tried <a href=\"https://github.com/jstjohn/KentLib/blob/master/examples/faSplit/faSplit.c\">faSplit</a>, which appeared to be working well, it created three 12GB files, and then hundreds of thousands of ~300byte files. This is how I found out that <code>rm</code> can only take 100,000 arguments at a time. Not wanting to deal with cleaning up nearly a million files again I decided to try and use <a href=\"genometools.org/\">genome tools</a>.</p>\n\n<p>Mercifully, it worked perfectly. Although it did take quite a long time, but writing 64GB's to disk is never going to be fast with a mechanical drive. </p>\n\n<p>I now had 11GB chunks of the nr database, so I decided to try cudasw++ again, however it segfaulted as it did before. I then went back to BarraCUDA and it also segfaulted. In one last ditch effort I split one of the 11GB files in half and tried again, but it still segfaulted in both applications.</p>\n\n<p>Looks like there is a lot more work to go into getting GPU accelerated alignment than I had hoped. I'll probably just stick with diamond because of this.</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-13 13:03:57","created_by":1,"updated_at":"2017-04-05 13:34:44","updated_by":1,"published_at":"2017-02-15 19:45:51","published_by":1},{"id":9,"uuid":"442a3e73-b7a7-44ae-8cab-0642fee126c8","title":"ES6 boilerplate, with Webpack, Mongoose, Pug, Stylus and a bunch of other goodies","slug":"nodejs-es6-boiler-plate","markdown":"During my industrial year at [Clock Limited](http://clock.co.uk) I was exposed to a lot of new javascript technologies, however working on an existing code base means you can't always use the latest and greatest tools that you want to.\n\nAs a side project myself, [Kenan](https://kyusuf.com/), [Ben](https://github.com/benjaminparnell) and [Matt](https://github.com/maael) decided to work on something a little bit different on friday afternoons to keep the noodles ticking over. \n\nWe came up with [itsback.at](http://alpha.itsback.at), which sadly never got finished; but it did allow us to play with a whole host of new technologies that we hadn't had the chance to use before, including ES6.\n\nFrom that I've extracted the core boilerplate and made a repository for future projects. You can find it all on [Github](https://github.com/bag-man/nodestack).\n\n### Technologies\nHere are some of the core technologies utilised in this boilerplate.\n\n[Node 6.9.0](http://nodejs.org) - Lets us use ES6 on the server side.\n\n[MongoDB 3.2](http://mongodb.com) - NoSQL isn't for everyone but we find it works nicely with Node.\n\n[Webpack](https://webpack.github.io/) - Builds all of our code into production ready bundles.\n\n[SocketIO](http://socket.io) - Web sockets made easy.\n\n[Mongoose](http://mongoosejs.com/) - Database controller.\n\n[Pug](https://pugjs.org/api/getting-started.html) - HTML templating language.\n\n[Stylus](http://stylus-lang.com/) - Minimal CSS.\n\n[ESlint](http://eslint.org/) - Modern linting that supports ES6.\n\n### Build scripts\n\n`npm test` - check that the code passes linting, using [Clock's eslint preset](https://www.npmjs.com/package/eslint-config-clock), run all the tests in the test folder, and produce a coverage report with istanbul.\n\n`npm run build` - builds the project for production, it will trans-compile the stylus down to CSS, and the client side JS to ES5, and then minify it. \n\n`npm run watch` - this does the same as the build, however it will not minify the clientside JS, but will set the project up to rebuild on any changes to JS or Jade files.\n\n### External services\nThe project is designed to be used with [Travis CI](https://travis-ci.org/), [Codecov](https://codecov.io/) and [Heroku](heroku.com). All you need to do to get it up and running is link your Github repository with these services, and set it to build on push. \n\nThis means that when you update your code and push it to Github, it will then build the application and run its tests in Travis CI. If it is successful it will upload the coverage statistics of the tests to Codecov, and then deploy the new build to Heroku for all to see. \n\nI've even included some snazzy badges in the readme, you just need to change the repository links. Click a badge to see what the service looks like!\n\n[![Build Status](https://img.shields.io/travis/bag-man/nodestack.svg?style=flat-square)](https://travis-ci.org/bag-man/nodestack)\n[![Coverage](https://img.shields.io/codecov/c/github/bag-man/nodestack.svg?style=flat-square)](https://codecov.io/github/bag-man/nodestack)\n[![Dependencies](https://img.shields.io/david/bag-man/nodestack.svg?style=flat-square)](https://david-dm.org/bag-man/nodestack)\n[![Code Climate](https://img.shields.io/codeclimate/github/bag-man/nodestack.svg?style=flat-square)](https://codeclimate.com/github/bag-man/nodestack)\n[![Known Vulnerabilities](https://snyk.io/test/github/bag-man/nodestack/badge.svg?style=flat-square)](https://snyk.io/test/github/bag-man/nodestack)\n[![Stories in Backlog](https://img.shields.io/waffle/label/bag-man/nodestack.svg?label=Backlog&title=Backlog&style=flat-square)](http://waffle.io/bag-man/nodestack)\n\n### Thanks, and alternatives\n\nA lot of credit needs to go to the people at Clock as well as those co-workers mentioned above for developing this stack, so please go check them out. This isn't the most polished boilerplate, as it is rather bare bones and doesn't include an MVC framework so it might not be for you. \n\nOne alternative to check out is [Mega Boilerplate](http://megaboilerplate.com/), it allows you to select what technologies you want to use for each part of the stack and bundles it all up for you. My only gripe with it is the generated code isn't ES6 and is a bit oddly laid out. \n\nIf you want to ask me any questions feel free to [email](mailto://garland.owen@gmail.com) me, or comment on a reddit thread.\n\n:wq","mobiledoc":null,"html":"<p>During my industrial year at <a href=\"http://clock.co.uk\">Clock Limited</a> I was exposed to a lot of new javascript technologies, however working on an existing code base means you can't always use the latest and greatest tools that you want to.</p>\n\n<p>As a side project myself, <a href=\"https://kyusuf.com/\">Kenan</a>, <a href=\"https://github.com/benjaminparnell\">Ben</a> and <a href=\"https://github.com/maael\">Matt</a> decided to work on something a little bit different on friday afternoons to keep the noodles ticking over. </p>\n\n<p>We came up with <a href=\"http://alpha.itsback.at\">itsback.at</a>, which sadly never got finished; but it did allow us to play with a whole host of new technologies that we hadn't had the chance to use before, including ES6.</p>\n\n<p>From that I've extracted the core boilerplate and made a repository for future projects. You can find it all on <a href=\"https://github.com/bag-man/nodestack\">Github</a>.</p>\n\n<h3 id=\"technologies\">Technologies</h3>\n\n<p>Here are some of the core technologies utilised in this boilerplate.</p>\n\n<p><a href=\"http://nodejs.org\">Node 6.9.0</a> - Lets us use ES6 on the server side.</p>\n\n<p><a href=\"http://mongodb.com\">MongoDB 3.2</a> - NoSQL isn't for everyone but we find it works nicely with Node.</p>\n\n<p><a href=\"https://webpack.github.io/\">Webpack</a> - Builds all of our code into production ready bundles.</p>\n\n<p><a href=\"http://socket.io\">SocketIO</a> - Web sockets made easy.</p>\n\n<p><a href=\"http://mongoosejs.com/\">Mongoose</a> - Database controller.</p>\n\n<p><a href=\"https://pugjs.org/api/getting-started.html\">Pug</a> - HTML templating language.</p>\n\n<p><a href=\"http://stylus-lang.com/\">Stylus</a> - Minimal CSS.</p>\n\n<p><a href=\"http://eslint.org/\">ESlint</a> - Modern linting that supports ES6.</p>\n\n<h3 id=\"buildscripts\">Build scripts</h3>\n\n<p><code>npm test</code> - check that the code passes linting, using <a href=\"https://www.npmjs.com/package/eslint-config-clock\">Clock's eslint preset</a>, run all the tests in the test folder, and produce a coverage report with istanbul.</p>\n\n<p><code>npm run build</code> - builds the project for production, it will trans-compile the stylus down to CSS, and the client side JS to ES5, and then minify it. </p>\n\n<p><code>npm run watch</code> - this does the same as the build, however it will not minify the clientside JS, but will set the project up to rebuild on any changes to JS or Jade files.</p>\n\n<h3 id=\"externalservices\">External services</h3>\n\n<p>The project is designed to be used with <a href=\"https://travis-ci.org/\">Travis CI</a>, <a href=\"https://codecov.io/\">Codecov</a> and <a href=\"heroku.com\">Heroku</a>. All you need to do to get it up and running is link your Github repository with these services, and set it to build on push. </p>\n\n<p>This means that when you update your code and push it to Github, it will then build the application and run its tests in Travis CI. If it is successful it will upload the coverage statistics of the tests to Codecov, and then deploy the new build to Heroku for all to see. </p>\n\n<p>I've even included some snazzy badges in the readme, you just need to change the repository links. Click a badge to see what the service looks like!</p>\n\n<p><a href=\"https://travis-ci.org/bag-man/nodestack\"><img src=\"https://img.shields.io/travis/bag-man/nodestack.svg?style=flat-square\" alt=\"Build Status\" title=\"\" /></a>\n<a href=\"https://codecov.io/github/bag-man/nodestack\"><img src=\"https://img.shields.io/codecov/c/github/bag-man/nodestack.svg?style=flat-square\" alt=\"Coverage\" title=\"\" /></a>\n<a href=\"https://david-dm.org/bag-man/nodestack\"><img src=\"https://img.shields.io/david/bag-man/nodestack.svg?style=flat-square\" alt=\"Dependencies\" title=\"\" /></a>\n<a href=\"https://codeclimate.com/github/bag-man/nodestack\"><img src=\"https://img.shields.io/codeclimate/github/bag-man/nodestack.svg?style=flat-square\" alt=\"Code Climate\" title=\"\" /></a>\n<a href=\"https://snyk.io/test/github/bag-man/nodestack\"><img src=\"https://snyk.io/test/github/bag-man/nodestack/badge.svg?style=flat-square\" alt=\"Known Vulnerabilities\" title=\"\" /></a>\n<a href=\"http://waffle.io/bag-man/nodestack\"><img src=\"https://img.shields.io/waffle/label/bag-man/nodestack.svg?label=Backlog&amp;title=Backlog&amp;style=flat-square\" alt=\"Stories in Backlog\" title=\"\" /></a></p>\n\n<h3 id=\"thanksandalternatives\">Thanks, and alternatives</h3>\n\n<p>A lot of credit needs to go to the people at Clock as well as those co-workers mentioned above for developing this stack, so please go check them out. This isn't the most polished boilerplate, as it is rather bare bones and doesn't include an MVC framework so it might not be for you. </p>\n\n<p>One alternative to check out is <a href=\"http://megaboilerplate.com/\">Mega Boilerplate</a>, it allows you to select what technologies you want to use for each part of the stack and bundles it all up for you. My only gripe with it is the generated code isn't ES6 and is a bit oddly laid out. </p>\n\n<p>If you want to ask me any questions feel free to <a href=\"mailto://garland.owen@gmail.com\">email</a> me, or comment on a reddit thread.</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":1,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-16 14:19:29","created_by":1,"updated_at":"2017-04-05 17:24:32","updated_by":1,"published_at":"2017-02-16 15:00:50","published_by":1},{"id":10,"uuid":"c035b75e-71bf-409d-ae75-f59a659ecd3b","title":"Evaluate a URL to get it's domain and port","slug":"evaluate-a-url-to-get-its-domain-and-port","markdown":"In NodeJS if you need to take a URL and extract the domain, protocol and port out, you may have noticed it is harder than it sounds. \n\nWe came across this problem when creating [itsback.at](http://alpha.itsback.at), and this is what we came up with. It currently only checks for http(s) and not other protocols like ftp links. It should return you the domain and port number, defaulting to port 80, if it isn't determinable what the port should be.\n\n```\n'use strict'\n\nconst url = require('url')\n\nfunction getUrl (dataUrl) {\n  if (dataUrl.split('://').length === 1 || dataUrl.startsWith('://')) {\n    dataUrl = `http://${dataUrl.replace('://', '')}`\n  }\n  return dataUrl\n}\n\nlet findUrlKey = (rawUrl) => {\n  rawUrl = getUrl(rawUrl)\n\n  let inputUrl = url.parse(rawUrl)\n    , domain = inputUrl.hostname || inputUrl.pathname.split('/')[0]\n    , protocol = inputUrl.protocol || 'http'\n    , port = inputUrl.port || (protocol.indexOf('https') > -1 ? '443' : '80')\n\n  return domain + ':' + port\n}\n\nmodule.exports = findUrlKey\n```\n\nWe did this in a test driven manner and the tests demonstrate quite clearly what this can and can't do. It isn't perfect, and there are some odd edge cases, although it could easily be expanded to include other protocols for example.\n\n```\nconst assert = require('assert')\n    , findUrlKey = require('../lib/find-url-key')\n    , fixtures =\n      [ { url: 'http://google.com', result: 'google.com:80' }\n      , { url: 'https://google.com', result: 'google.com:443' }\n      , { url: 'https://google.com:3000', result: 'google.com:3000' }\n      , { url: 'http://google.com:3000', result: 'google.com:3000' }\n      , { url: 'http://google.com:3000/path', result: 'google.com:3000' }\n      , { url: 'http://google.com:3000', result: 'google.com:3000' }\n      , { url: 'google.com', result: 'google.com:80' }\n      , { url: 'google.com/path', result: 'google.com:80' }\n      , { url: 'google.com:3000/path', result: 'google.com:3000' }\n      , { url: 'google.com:3000', result: 'google.com:3000' }\n      , { url: '://google.com:3000', result: 'google.com:3000' }\n      , { url: '://google.com', result: 'google.com:80' }\n      , { url: 'ftp://google.com:3000', result: 'google.com:3000' }\n      , { url: 'ftp://google.com', result: 'google.com:80' }\n      ]\n\ndescribe('Test URL parsing logic', () => {\n  fixtures.forEach((fixture) => {\n    it('should return: ' + JSON.stringify(fixture.result), (done) => {\n      assert.deepEqual(findUrlKey(fixture.url), fixture.result, 'incorrect domain or port')\n      done()\n    })\n  })\n})\n```\n\n:wq","mobiledoc":null,"html":"<p>In NodeJS if you need to take a URL and extract the domain, protocol and port out, you may have noticed it is harder than it sounds. </p>\n\n<p>We came across this problem when creating <a href=\"http://alpha.itsback.at\">itsback.at</a>, and this is what we came up with. It currently only checks for http(s) and not other protocols like ftp links. It should return you the domain and port number, defaulting to port 80, if it isn't determinable what the port should be.</p>\n\n<pre><code>'use strict'\n\nconst url = require('url')\n\nfunction getUrl (dataUrl) {  \n  if (dataUrl.split('://').length === 1 || dataUrl.startsWith('://')) {\n    dataUrl = `http://${dataUrl.replace('://', '')}`\n  }\n  return dataUrl\n}\n\nlet findUrlKey = (rawUrl) =&gt; {  \n  rawUrl = getUrl(rawUrl)\n\n  let inputUrl = url.parse(rawUrl)\n    , domain = inputUrl.hostname || inputUrl.pathname.split('/')[0]\n    , protocol = inputUrl.protocol || 'http'\n    , port = inputUrl.port || (protocol.indexOf('https') &gt; -1 ? '443' : '80')\n\n  return domain + ':' + port\n}\n\nmodule.exports = findUrlKey  \n</code></pre>\n\n<p>We did this in a test driven manner and the tests demonstrate quite clearly what this can and can't do. It isn't perfect, and there are some odd edge cases, although it could easily be expanded to include other protocols for example.</p>\n\n<pre><code>const assert = require('assert')  \n    , findUrlKey = require('../lib/find-url-key')\n    , fixtures =\n      [ { url: 'http://google.com', result: 'google.com:80' }\n      , { url: 'https://google.com', result: 'google.com:443' }\n      , { url: 'https://google.com:3000', result: 'google.com:3000' }\n      , { url: 'http://google.com:3000', result: 'google.com:3000' }\n      , { url: 'http://google.com:3000/path', result: 'google.com:3000' }\n      , { url: 'http://google.com:3000', result: 'google.com:3000' }\n      , { url: 'google.com', result: 'google.com:80' }\n      , { url: 'google.com/path', result: 'google.com:80' }\n      , { url: 'google.com:3000/path', result: 'google.com:3000' }\n      , { url: 'google.com:3000', result: 'google.com:3000' }\n      , { url: '://google.com:3000', result: 'google.com:3000' }\n      , { url: '://google.com', result: 'google.com:80' }\n      , { url: 'ftp://google.com:3000', result: 'google.com:3000' }\n      , { url: 'ftp://google.com', result: 'google.com:80' }\n      ]\n\ndescribe('Test URL parsing logic', () =&gt; {  \n  fixtures.forEach((fixture) =&gt; {\n    it('should return: ' + JSON.stringify(fixture.result), (done) =&gt; {\n      assert.deepEqual(findUrlKey(fixture.url), fixture.result, 'incorrect domain or port')\n      done()\n    })\n  })\n})\n</code></pre>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-16 16:13:52","created_by":1,"updated_at":"2017-02-20 15:08:37","updated_by":1,"published_at":"2017-02-16 16:23:46","published_by":1},{"id":11,"uuid":"43c4f13d-6cf5-440d-a14a-90cb7b02ea23","title":"[Project Log #2] A better understanding of the task at hand","slug":"project-log-2-a-better-understanding-of-the-task-at-hand","markdown":"Today I was able to meet with two of the researchers who are studying the yeasts that I will be working with. It was great to finally meet them, although they said a lot of long scary words, but were very reassuring!\n\nTheir research has been looking at three species of yeast, *Candida Tropicalis*, *Candida Boidinii*, and *Candida Shehatae*. *Candida Tropicalis* is very good at metabolising Arabinose & Xylose, however the two conflict and the end product isn't that useful. *Candida Boidinii* doesn't process Arabinose, for some unknown reason, but does metabolise Xylose just at a much slower rate. \n\nIf they can figure out what genetics cause *Candida Boidinii* to not react with Arabinose, and then modify *Candida Tropicalis* to have the same characteristics, then they would be able to produce Xylitol, an anti-bacterial sugar, cheaper and easier than before. One other exciting possibility is using it to create an artificial sweetener that can be used by diabetics.\n\n### How do we find this out? \nThe data I have been provided is sequenced and assembled [contigs](https://en.wikipedia.org/wiki/Contig), which are essentially random strings of DNA taken from the samples, for each of the three species. \n\nMy task will be to run analytical tools to compare these contigs against the known genes found in the NCBI non-redundant database. From there we can compare what genes are present in each of the species, and hopefully highlight any differences found. \n\nI'm still a little concerned about this stage of the process as there is a lot of knowledge that I need to extract from my tutors head, but I'm feeling positive that I'm on the right track to understanding the bits I need to. \n\n### What then? \nThe part of the project that I will feel the most comfortable in and be able to harness my skill set in, will be once we have the data in a database and ready to present in a meaningful way. \n\nThe plan at the moment is to produce a website for the researchers that will allow them to search, browse and compare genes between the species, I'm not too worried about this as there is already [database schema's](http://gmod.org/wiki/Main_Page) available as well as JavaScript libraries for [representing](https://github.com/hammerlab/pileup.js/) the data.\n\n","mobiledoc":null,"html":"<p>Today I was able to meet with two of the researchers who are studying the yeasts that I will be working with. It was great to finally meet them, although they said a lot of long scary words, but were very reassuring!</p>\n\n<p>Their research has been looking at three species of yeast, <em>Candida Tropicalis</em>, <em>Candida Boidinii</em>, and <em>Candida Shehatae</em>. <em>Candida Tropicalis</em> is very good at metabolising Arabinose &amp; Xylose, however the two conflict and the end product isn't that useful. <em>Candida Boidinii</em> doesn't process Arabinose, for some unknown reason, but does metabolise Xylose just at a much slower rate. </p>\n\n<p>If they can figure out what genetics cause <em>Candida Boidinii</em> to not react with Arabinose, and then modify <em>Candida Tropicalis</em> to have the same characteristics, then they would be able to produce Xylitol, an anti-bacterial sugar, cheaper and easier than before. One other exciting possibility is using it to create an artificial sweetener that can be used by diabetics.</p>\n\n<h3 id=\"howdowefindthisout\">How do we find this out?</h3>\n\n<p>The data I have been provided is sequenced and assembled <a href=\"https://en.wikipedia.org/wiki/Contig\">contigs</a>, which are essentially random strings of DNA taken from the samples, for each of the three species. </p>\n\n<p>My task will be to run analytical tools to compare these contigs against the known genes found in the NCBI non-redundant database. From there we can compare what genes are present in each of the species, and hopefully highlight any differences found. </p>\n\n<p>I'm still a little concerned about this stage of the process as there is a lot of knowledge that I need to extract from my tutors head, but I'm feeling positive that I'm on the right track to understanding the bits I need to. </p>\n\n<h3 id=\"whatthen\">What then?</h3>\n\n<p>The part of the project that I will feel the most comfortable in and be able to harness my skill set in, will be once we have the data in a database and ready to present in a meaningful way. </p>\n\n<p>The plan at the moment is to produce a website for the researchers that will allow them to search, browse and compare genes between the species, I'm not too worried about this as there is already <a href=\"http://gmod.org/wiki/Main_Page\">database schema's</a> available as well as JavaScript libraries for <a href=\"https://github.com/hammerlab/pileup.js/\">representing</a> the data.</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-17 14:25:51","created_by":1,"updated_at":"2017-03-03 13:02:54","updated_by":1,"published_at":"2017-03-03 13:02:29","published_by":1},{"id":12,"uuid":"78618715-c45c-408f-a632-56251654eda4","title":"Solving reddits missing features with simple PRAW scripts","slug":"solving-reddits-missing-features-with-simple-praw-scripts","markdown":"I love reddit, and let's be honest I'm probably a bit of an addict. When you come to use the site a lot, you will end up noticing that it is missing a few key features. \n\nThankfully with a little bit of Python and the amazing PRAW (Python Reddit API Wrapper) library, you can solve these problems really quickly.\n\n### Search saved links\nHave you ever wanted to search for that funny cat picture you saved a year ago which has suddenly become relevant to your current situation? \n\nWell reddit doesn't let you. You can go to [your saved links](http://reddit.com/u/m/saved), and then look through 25 posts at a time, having to click next each time. Or if you are the lucky owner of reddit gold you can filter by subreddit, which still isn't much use if you know what you are looking for, but not which subreddit.\n\nThis was frustrating me, so I wrote a small script to allow me to search through my saved links. It is a little slow as it gets all 1000 posts each time it runs, however as I run it so infrequently I don't mind waiting!\n\nThe script uses docopt and PRAW so you will need to install those via pip. This can be done with `pip install --user praw docopt`. The [repo](https://github.com/bag-man/savedLinks) has a requirements.txt if you find that easier.\n\n```\n\"\"\"\nUsage:\n  savedLinks [options]\n\nOptions:\n  -t, --title TITLE     Search for links based on link title\n  -d, --domain DOMAIN   Search for links from a certain domain\n  -r, --reddit REDDIT   Search for links based on subreddit\n\"\"\"\n\nfrom docopt import docopt\nimport praw\nimport sys\n\nif __name__ == \"__main__\":\n    args = docopt(__doc__)\n\ncriteria = sum(1 for v in args.values() if v is not None)\n\nif criteria == 0:\n    sys.exit(__doc__)\n\nr = praw.Reddit(user_agent='savedSearch',\n                client_id='OkDyg4-hOs-TbQ',\n                client_secret='******************',\n                username='Midasx',\n                password='**********',)\n\nfor post in r.redditor('Midasx').saved(limit=None):\n    count = 0\n    if not hasattr(post, 'domain'):\n        continue  # Filter out saved comments\n\n    if args['--domain']:\n        if args['--domain'].lower() == post.domain:\n            count += 1\n\n    if args['--reddit']:\n        if args['--reddit'].lower() == post.subreddit.display_name.lower():\n            count += 1\n\n    if args['--title']:\n        if args['--title'].lower() in post.title.lower():\n            count += 1\n\n    if count == criteria:\n        print(post.shortlink, \" \", post.title)\n```\n\nTo get this running you will need to make an app on your reddit account. Just go to [your apps](https://www.reddit.com/prefs/apps/), and hit `create another app...` then give it a name and a redirect URL (Can be anything, we aren't using it), then make sure to select that it is a Script for personal use.\n\n![Search results](/content/images/2017/02/shot-6.png)\n\n### Notifications for small subreddits\nIf you are really interested in a niche subreddit, it would be nice to know when someone posts there. A lot of my smaller subscriptions have posts go unanswered just because no one checks the sub frequently due to its inactivity. \n\nCurrently reddit doesn't offer a way to get alerted when a new post is made in a subreddit so that is why I came up with this nice [little bot](https://github.com/bag-man/NewPost) to do it for you. It only took an hour to write, and appears to work quite nicely. Once setup it will watch subreddits of your choice and PM you with a link to the new post when one is made.\n\n```\nimport sys\nimport praw\nimport time\n\nuser = 'Midasx'\nreddits = ['vim']\nseen = []\n\nr = praw.Reddit(user_agent='NewPost',\n                client_id='RGtz43e2ZuuuoA',\n                client_secret='*******************',\n                username='NewPostAlert',\n                password='***********',)\n\nprint(\"Logged in\")\n\nfirst = True\n\nwhile True:\n    try:\n        for sub in reddits:\n            for post in r.subreddit(sub).new(limit=10):\n                if first is True:\n                    seen.append(post.id)\n                if post.id not in seen:\n                    subject = 'New post in ' + str(post.subreddit)\n                    content = '[' + post.title + '](' + post.shortlink + ')'\n                    r.redditor(user).message(subject, content)\n                    print('New post! Sending PM.')\n                    seen.append(post.id)\n\n        time.sleep(5)\n        first = False\n    except KeyboardInterrupt:\n        print('\\n')\n        sys.exit(0)\n    except Exception as e:\n        print(e)\n```\n\nAgain, as with the saved links script you will need to create an app for a user, this time I decided to create a separate user for the bot as well. \n\nJust edit in the bots details, the user you want to message and the reddits you want it to watch. If I have time in the future I would love to make this an online service where a user can sign up for notifications on subreddits via a third party service. \n\n### Conclusion\nI wish reddit made these features standard and available to everyone, however I am really thankful that the PRAW library is so easy to use. It is a really nice feeling to find a problem in your day to day life, and solve it quickly and simply with a few lines of code!\n\n:wq","mobiledoc":null,"html":"<p>I love reddit, and let's be honest I'm probably a bit of an addict. When you come to use the site a lot, you will end up noticing that it is missing a few key features. </p>\n\n<p>Thankfully with a little bit of Python and the amazing PRAW (Python Reddit API Wrapper) library, you can solve these problems really quickly.</p>\n\n<h3 id=\"searchsavedlinks\">Search saved links</h3>\n\n<p>Have you ever wanted to search for that funny cat picture you saved a year ago which has suddenly become relevant to your current situation? </p>\n\n<p>Well reddit doesn't let you. You can go to <a href=\"http://reddit.com/u/m/saved\">your saved links</a>, and then look through 25 posts at a time, having to click next each time. Or if you are the lucky owner of reddit gold you can filter by subreddit, which still isn't much use if you know what you are looking for, but not which subreddit.</p>\n\n<p>This was frustrating me, so I wrote a small script to allow me to search through my saved links. It is a little slow as it gets all 1000 posts each time it runs, however as I run it so infrequently I don't mind waiting!</p>\n\n<p>The script uses docopt and PRAW so you will need to install those via pip. This can be done with <code>pip install --user praw docopt</code>. The <a href=\"https://github.com/bag-man/savedLinks\">repo</a> has a requirements.txt if you find that easier.</p>\n\n<pre><code>\"\"\"\nUsage:  \n  savedLinks [options]\n\nOptions:  \n  -t, --title TITLE     Search for links based on link title\n  -d, --domain DOMAIN   Search for links from a certain domain\n  -r, --reddit REDDIT   Search for links based on subreddit\n\"\"\"\n\nfrom docopt import docopt  \nimport praw  \nimport sys\n\nif __name__ == \"__main__\":  \n    args = docopt(__doc__)\n\ncriteria = sum(1 for v in args.values() if v is not None)\n\nif criteria == 0:  \n    sys.exit(__doc__)\n\nr = praw.Reddit(user_agent='savedSearch',  \n                client_id='OkDyg4-hOs-TbQ',\n                client_secret='******************',\n                username='Midasx',\n                password='**********',)\n\nfor post in r.redditor('Midasx').saved(limit=None):  \n    count = 0\n    if not hasattr(post, 'domain'):\n        continue  # Filter out saved comments\n\n    if args['--domain']:\n        if args['--domain'].lower() == post.domain:\n            count += 1\n\n    if args['--reddit']:\n        if args['--reddit'].lower() == post.subreddit.display_name.lower():\n            count += 1\n\n    if args['--title']:\n        if args['--title'].lower() in post.title.lower():\n            count += 1\n\n    if count == criteria:\n        print(post.shortlink, \" \", post.title)\n</code></pre>\n\n<p>To get this running you will need to make an app on your reddit account. Just go to <a href=\"https://www.reddit.com/prefs/apps/\">your apps</a>, and hit <code>create another app...</code> then give it a name and a redirect URL (Can be anything, we aren't using it), then make sure to select that it is a Script for personal use.</p>\n\n<p><img src=\"/content/images/2017/02/shot-6.png\" alt=\"Search results\" /></p>\n\n<h3 id=\"notificationsforsmallsubreddits\">Notifications for small subreddits</h3>\n\n<p>If you are really interested in a niche subreddit, it would be nice to know when someone posts there. A lot of my smaller subscriptions have posts go unanswered just because no one checks the sub frequently due to its inactivity. </p>\n\n<p>Currently reddit doesn't offer a way to get alerted when a new post is made in a subreddit so that is why I came up with this nice <a href=\"https://github.com/bag-man/NewPost\">little bot</a> to do it for you. It only took an hour to write, and appears to work quite nicely. Once setup it will watch subreddits of your choice and PM you with a link to the new post when one is made.</p>\n\n<pre><code>import sys  \nimport praw  \nimport time\n\nuser = 'Midasx'  \nreddits = ['vim']  \nseen = []\n\nr = praw.Reddit(user_agent='NewPost',  \n                client_id='RGtz43e2ZuuuoA',\n                client_secret='*******************',\n                username='NewPostAlert',\n                password='***********',)\n\nprint(\"Logged in\")\n\nfirst = True\n\nwhile True:  \n    try:\n        for sub in reddits:\n            for post in r.subreddit(sub).new(limit=10):\n                if first is True:\n                    seen.append(post.id)\n                if post.id not in seen:\n                    subject = 'New post in ' + str(post.subreddit)\n                    content = '[' + post.title + '](' + post.shortlink + ')'\n                    r.redditor(user).message(subject, content)\n                    print('New post! Sending PM.')\n                    seen.append(post.id)\n\n        time.sleep(5)\n        first = False\n    except KeyboardInterrupt:\n        print('\\n')\n        sys.exit(0)\n    except Exception as e:\n        print(e)\n</code></pre>\n\n<p>Again, as with the saved links script you will need to create an app for a user, this time I decided to create a separate user for the bot as well. </p>\n\n<p>Just edit in the bots details, the user you want to message and the reddits you want it to watch. If I have time in the future I would love to make this an online service where a user can sign up for notifications on subreddits via a third party service. </p>\n\n<h3 id=\"conclusion\">Conclusion</h3>\n\n<p>I wish reddit made these features standard and available to everyone, however I am really thankful that the PRAW library is so easy to use. It is a really nice feeling to find a problem in your day to day life, and solve it quickly and simply with a few lines of code!</p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-20 11:50:51","created_by":1,"updated_at":"2017-02-25 14:25:09","updated_by":1,"published_at":"2017-02-20 12:50:00","published_by":1},{"id":13,"uuid":"25e7419c-a1f1-426c-9372-9d41161e7d2a","title":"[Project Log #3] Pipeline for annotating DNA contigs","slug":"project-log-3-pipeline-for-annotating-dna-contigs","markdown":"This is the set of steps I have followed in an attempt to annotate the data I have been given, and put it into a database. At the moment is is almost entirely a manual task, but if the scope for my project allows I would like to make this into a fully automated process that is compatible with the web front end that I produce. \n\n## Raw contigs\nFirst set of data is the reads from the sequencer, assembled into many contigs.\n\nThis produces `candida_boidinii.fa`.\n\n## Diamond blast against NCBI non-redundant database\nSecond set of data is generated by using diamond to compare the contigs you have against the nr database to find known genes.\n\n```\n./diamond makedb --in nr -d nr_ref\n./diamond blastx -d nr_ref.dmnd -q candida_boidinii.fa -o blastx_nr_boidinii.m8 -p 8\n```\n\nThis produces `blastx_nr_boidinii.m8`.\n\n## Select best matches from blast\nUsing awk pull out only the best matches from diamond. I need a proper bioinformatician to tell me if this is okay or not.\n\n```\nawk '!_[$1]++ {print}' blastx_nr_boidinii.m8 > boidinii_best.m8\n```\nThis produces `boidinii_best.m8`.\n\n##  Get uniprot & Kegg IDs and proteins\nUse awk to get the list of RefSeq protein IDs from the blast results\n\n```\nawk '{print $2}' boidinii_best.m8 | xclip\n```\n\nThen paste it into the [uniprot look up](http://www.uniprot.org/uploadlists/) and search for RefSeq Protein -> UniProtKB \n\nDownload the Mapping Table file, to get a list of the IDs that correspond to uniprot IDs.\n\nAlso download the fasta format of all the proteins found.\n\nThis produces `boidinii_uniprot.fa` & `boidinii_uniprot_ids.lst`.\n\nTake the uniprot ids and get the conversion to kegg Id's in the same way. This produces `boidinii_kegg_ids.lst`.\n\n## Merge the data into a working file\nUsing Vim macro's it is simple to combine the found data into a copy of the original fasta file.\n\nThe gene is now annotated with the original scaffold, the blast result, and the uniprot & kegg ID.\n\n```\n>C76265 63.0 | XP_002553495.1 23.7  219 154 5 696 1331  25  237 4.1e-05 58.9 | C5DFV2 | lth:KLTH0D18194g\nAAAAAAAAAAAAATGTTCAGTCAAAAATAAGCTAATTTACCGTACAATGGCATGCATATGCGACAAGGTTCTTTTTTTCTGTTGTTTAGCAAATGCAGTA\nAACCAGTGGTTATACATTCATCATTAGGTGGTACTCTAAATCTGTCTTTATAATCCATCTTTTATCCATAAGTGAAGCTGAAAAGGCTGAAAGTCCTTTT\n```\n\nThis produces `boidinii_working.fa`.\n\n## Create a database with the found data\nNow we have two files that need to be ingested into a database. The `boidinii_working.fa` & `boidinii_uniprot.fa` files should contain all the data that the website needs. \n\nI have created a quick and nasty script to put this data into MongoDB. \n\n```\nconst fasta2json = require('fasta2json')\n    , MongoClient = require('mongodb').MongoClient\n    , url = 'mongodb://localhost:27017/candida'\n\nlet proteins = fasta2json.ReadFasta('../data/boidinii/boidinii_uniprot.fa')\n  , species = []\n\nfasta2json.ParseFasta = (str) => {\n  let fasta = []\n    , seqs = str.split('>')\n\n  for (let i = 1; i < seqs.length; i++) {\n    seqs[i] = seqs[i].replace(/\\r/g, '')\n\n    let seq = {}\n      , fas = seqs[i].split('\\n')\n      , head = fas[0]\n\n    seq.contig = head.split('|')[0].trim()\n    seq.blast = head.split('|')[1] || 'No blast result'\n    seq.uniprot = head.split('|')[2] || 'No uniprot match'\n    seq.kegg = head.split('|')[3] || 'No kegg match'\n    seq.blast = seq.blast.trim()\n    seq.uniprot = seq.uniprot.trim()\n    seq.kegg = seq.kegg.trim()\n    seq.sequence = ''\n\n    for (let j = 1; j < fas.length; j++) {\n      seq.sequence = seq.sequence + fas[j]\n    }\n\n    seq.protein = proteins.filter((obj) => {\n      let proteinId = obj.head.split('|')[1]\n      return proteinId === seq.uniprot\n    })[0] || 'No uniprot match'\n\n    fasta.push(seq)\n  }\n\n  return fasta\n}\n\nspecies = fasta2json.ReadFasta('../data/boidinii/boidinii_working.fa')\n\nMongoClient.connect(url, (err, db) => {\n  if (err) console.log('ERROR: ' + err)\n  let collection = db.collection('boidinii')\n  collection.drop()\n\n  collection.insertMany(species, (err, result) => {\n    if (err) console.log('ERROR: ' + err)\n    db.close()\n  })\n})\n```\nThis gives provides the following data:\n\n```\n> db.boidinii.findOne({ uniprot: \"K4AC16\" })\n{\n        \"_id\" : ObjectId(\"58b96c298660061466e9be53\"),\n        \"contig\" : \"C69229  4.0\",\n        \"blast\" : \"XP_004983205.1 91.7  36  3 0 146 39  311 346 6.1e-09 68.2\",\n        \"uniprot\" : \"K4AC16\",\n        \"kegg\" : \"sita:101760397\",\n        \"sequence\" : \"GAGGATCCTAACAATCTAGTAAGGCTAG...\",\n        \"protein\" : {\n                \"head\" : \"tr|K4AC16|K4AC16_SETIT Uncharacterized protein...\",\n                \"seq\" : \"MNIASAALVFLAHCLLLHRCMGSEA...\"\n        }\n}\n>\n```\n\n\n## Build a web front end\nThen I just have to make a web front end to make this data accessible, including viewing, searching and comparing genes across the species.\n\nThis is my next big challenge. I will create a list of stories for this task.  \n","mobiledoc":null,"html":"<p>This is the set of steps I have followed in an attempt to annotate the data I have been given, and put it into a database. At the moment is is almost entirely a manual task, but if the scope for my project allows I would like to make this into a fully automated process that is compatible with the web front end that I produce. </p>\n\n<h2 id=\"rawcontigs\">Raw contigs</h2>\n\n<p>First set of data is the reads from the sequencer, assembled into many contigs.</p>\n\n<p>This produces <code>candida_boidinii.fa</code>.</p>\n\n<h2 id=\"diamondblastagainstncbinonredundantdatabase\">Diamond blast against NCBI non-redundant database</h2>\n\n<p>Second set of data is generated by using diamond to compare the contigs you have against the nr database to find known genes.</p>\n\n<pre><code>./diamond makedb --in nr -d nr_ref\n./diamond blastx -d nr_ref.dmnd -q candida_boidinii.fa -o blastx_nr_boidinii.m8 -p 8\n</code></pre>\n\n<p>This produces <code>blastx_nr_boidinii.m8</code>.</p>\n\n<h2 id=\"selectbestmatchesfromblast\">Select best matches from blast</h2>\n\n<p>Using awk pull out only the best matches from diamond. I need a proper bioinformatician to tell me if this is okay or not.</p>\n\n<pre><code>awk '!_[$1]++ {print}' blastx_nr_boidinii.m8 &gt; boidinii_best.m8  \n</code></pre>\n\n<p>This produces <code>boidinii_best.m8</code>.</p>\n\n<h2 id=\"getuniprotkeggidsandproteins\">Get uniprot &amp; Kegg IDs and proteins</h2>\n\n<p>Use awk to get the list of RefSeq protein IDs from the blast results</p>\n\n<pre><code>awk '{print $2}' boidinii_best.m8 | xclip  \n</code></pre>\n\n<p>Then paste it into the <a href=\"http://www.uniprot.org/uploadlists/\">uniprot look up</a> and search for RefSeq Protein -> UniProtKB </p>\n\n<p>Download the Mapping Table file, to get a list of the IDs that correspond to uniprot IDs.</p>\n\n<p>Also download the fasta format of all the proteins found.</p>\n\n<p>This produces <code>boidinii_uniprot.fa</code> &amp; <code>boidinii_uniprot_ids.lst</code>.</p>\n\n<p>Take the uniprot ids and get the conversion to kegg Id's in the same way. This produces <code>boidinii_kegg_ids.lst</code>.</p>\n\n<h2 id=\"mergethedataintoaworkingfile\">Merge the data into a working file</h2>\n\n<p>Using Vim macro's it is simple to combine the found data into a copy of the original fasta file.</p>\n\n<p>The gene is now annotated with the original scaffold, the blast result, and the uniprot &amp; kegg ID.</p>\n\n<pre><code>&gt;C76265 63.0 | XP_002553495.1 23.7  219 154 5 696 1331  25  237 4.1e-05 58.9 | C5DFV2 | lth:KLTH0D18194g\nAAAAAAAAAAAAATGTTCAGTCAAAAATAAGCTAATTTACCGTACAATGGCATGCATATGCGACAAGGTTCTTTTTTTCTGTTGTTTAGCAAATGCAGTA  \nAACCAGTGGTTATACATTCATCATTAGGTGGTACTCTAAATCTGTCTTTATAATCCATCTTTTATCCATAAGTGAAGCTGAAAAGGCTGAAAGTCCTTTT  \n</code></pre>\n\n<p>This produces <code>boidinii_working.fa</code>.</p>\n\n<h2 id=\"createadatabasewiththefounddata\">Create a database with the found data</h2>\n\n<p>Now we have two files that need to be ingested into a database. The <code>boidinii_working.fa</code> &amp; <code>boidinii_uniprot.fa</code> files should contain all the data that the website needs. </p>\n\n<p>I have created a quick and nasty script to put this data into MongoDB. </p>\n\n<pre><code>const fasta2json = require('fasta2json')  \n    , MongoClient = require('mongodb').MongoClient\n    , url = 'mongodb://localhost:27017/candida'\n\nlet proteins = fasta2json.ReadFasta('../data/boidinii/boidinii_uniprot.fa')  \n  , species = []\n\nfasta2json.ParseFasta = (str) =&gt; {  \n  let fasta = []\n    , seqs = str.split('&gt;')\n\n  for (let i = 1; i &lt; seqs.length; i++) {\n    seqs[i] = seqs[i].replace(/\\r/g, '')\n\n    let seq = {}\n      , fas = seqs[i].split('\\n')\n      , head = fas[0]\n\n    seq.contig = head.split('|')[0].trim()\n    seq.blast = head.split('|')[1] || 'No blast result'\n    seq.uniprot = head.split('|')[2] || 'No uniprot match'\n    seq.kegg = head.split('|')[3] || 'No kegg match'\n    seq.blast = seq.blast.trim()\n    seq.uniprot = seq.uniprot.trim()\n    seq.kegg = seq.kegg.trim()\n    seq.sequence = ''\n\n    for (let j = 1; j &lt; fas.length; j++) {\n      seq.sequence = seq.sequence + fas[j]\n    }\n\n    seq.protein = proteins.filter((obj) =&gt; {\n      let proteinId = obj.head.split('|')[1]\n      return proteinId === seq.uniprot\n    })[0] || 'No uniprot match'\n\n    fasta.push(seq)\n  }\n\n  return fasta\n}\n\nspecies = fasta2json.ReadFasta('../data/boidinii/boidinii_working.fa')\n\nMongoClient.connect(url, (err, db) =&gt; {  \n  if (err) console.log('ERROR: ' + err)\n  let collection = db.collection('boidinii')\n  collection.drop()\n\n  collection.insertMany(species, (err, result) =&gt; {\n    if (err) console.log('ERROR: ' + err)\n    db.close()\n  })\n})\n</code></pre>\n\n<p>This gives provides the following data:</p>\n\n<pre><code>&gt; db.boidinii.findOne({ uniprot: \"K4AC16\" })\n{\n        \"_id\" : ObjectId(\"58b96c298660061466e9be53\"),\n        \"contig\" : \"C69229  4.0\",\n        \"blast\" : \"XP_004983205.1 91.7  36  3 0 146 39  311 346 6.1e-09 68.2\",\n        \"uniprot\" : \"K4AC16\",\n        \"kegg\" : \"sita:101760397\",\n        \"sequence\" : \"GAGGATCCTAACAATCTAGTAAGGCTAG...\",\n        \"protein\" : {\n                \"head\" : \"tr|K4AC16|K4AC16_SETIT Uncharacterized protein...\",\n                \"seq\" : \"MNIASAALVFLAHCLLLHRCMGSEA...\"\n        }\n}\n&gt;\n</code></pre>\n\n<h2 id=\"buildawebfrontend\">Build a web front end</h2>\n\n<p>Then I just have to make a web front end to make this data accessible, including viewing, searching and comparing genes across the species.</p>\n\n<p>This is my next big challenge. I will create a list of stories for this task.  </p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-24 18:29:38","created_by":1,"updated_at":"2017-03-03 13:16:04","updated_by":1,"published_at":"2017-03-03 13:06:05","published_by":1},{"id":14,"uuid":"2acd5052-2d90-4b85-8611-27d10bfc3dd1","title":"Github style diff in terminal with icdiff","slug":"github-style-diff-in-terminal-with-icdiff","markdown":"Improved Colour Diff or [icdiff](https://github.com/jeffkaufman/icdiff) gives you nice github style diffs in the terminal. It does work well, however getting it to work with git smoothly was a little fiddly so I thought I would share. Just add this to your `~/.gitconfig`.\n\n```\n[alias]\n  showtool = \"!f() { git difftool $1^ $1; }; f\"\n  added = difftool --cached\n[diff]\n  tool = icdiff\n[difftool]\n  prompt = false\n[difftool \"icdiff\"]\n  cmd = /usr/bin/icdiff --line-numbers $LOCAL $REMOTE\n[pager]\n  difftool = true\n```\n\nThis lets your run `git difftool` to view your current unstaged changes, and view commits with `git showtool <commit>`.\n\n![Example output from a show](/content/images/2017/02/shot-8.png)\n\nIf you are used to working with github, this is quite a nice feature as you don't have to adjust your eyes when reviewing a PR, or looking at your local changes. \n\n:wq","mobiledoc":null,"html":"<p>Improved Colour Diff or <a href=\"https://github.com/jeffkaufman/icdiff\">icdiff</a> gives you nice github style diffs in the terminal. It does work well, however getting it to work with git smoothly was a little fiddly so I thought I would share. Just add this to your <code>~/.gitconfig</code>.</p>\n\n<pre><code>[alias]\n  showtool = \"!f() { git difftool $1^ $1; }; f\"\n  added = difftool --cached\n[diff]\n  tool = icdiff\n[difftool]\n  prompt = false\n[difftool \"icdiff\"]\n  cmd = /usr/bin/icdiff --line-numbers $LOCAL $REMOTE\n[pager]\n  difftool = true\n</code></pre>\n\n<p>This lets your run <code>git difftool</code> to view your current unstaged changes, and view commits with <code>git showtool &lt;commit&gt;</code>.</p>\n\n<p><img src=\"/content/images/2017/02/shot-8.png\" alt=\"Example output from a show\" /></p>\n\n<p>If you are used to working with github, this is quite a nice feature as you don't have to adjust your eyes when reviewing a PR, or looking at your local changes. </p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-28 12:40:31","created_by":1,"updated_at":"2017-02-28 13:38:41","updated_by":1,"published_at":"2017-02-28 13:38:41","published_by":1},{"id":16,"uuid":"25cccfad-5044-473c-b194-9cfd4be68973","title":"Vim text objects, extend Vim's natural language!","slug":"vim-text-objects-extend-vims-natural-language-2","markdown":"One of the magical things about Vim is that it uses nouns and verbs to construct an editing language. For example `d` (delete) is a verb and `w` (word) is a noun. By combining a noun & verb we make an edit. Learning this language is key to getting the most out of your editing, I recommend this [great talk](https://www.youtube.com/watch?v=wlR5gYd6um0) by [Chris Toomey](https://twitter.com/christoomey) if this concept is new to you. \n\nOnce you have the basics down you know how to operate on the standard text objects that vim provides you might want to start adding your own. Thankfully there are some excellent plugins to add a whole host of extra objects. What is nice about these extensions to the language is they feel natural and intuitive and don't take much investment to learn at all. \n\n## Examples\nBelow I have listed a few of my favourite extensions with a link to the plugin on Github as well as the Plug line for them. I've also added a very simple \"selling point\" on what the plugins do, but if one piques your interest do check out the full docs on the github page because a lot of these are a lot more powerful than the simple examples I am listing. Also pipe (`|`) denotes cursor position.\n\n## Surround\nThis is probably the most essential plugin for Vim, it feels totally natural and whenever I encounter vanilla Vim I inevitably try to use it forgetting that it isn't there by default!\n\nThis allows us to select `(`surrounding`)` brackets, braces, quotes, etc. So `cs\"'` would change surrounding `\"`'s to `'`'s. \n\n`\"f|oo\"` -> `cs\"'` -> `'bar'`\n\n**Plug ['tpope/surround'](https://github.com/tpope/vim-surround)**\n\n## Targets\nVim allows us to do things like `ci\"` to change text inside quotes, but what about other markers? Targets lets us do this to pretty much everything else that would encapsulate text, such as `,`'s or `+`'s. \n\nFor examples to delete a string from a concatenation `da+`, will remove the string and `+` from under the cursor. \n\n`foo + 'str|ing' + bar` -> `da+` -> `foo + bar`\n\n \n**Plug ['wellle/targets.vim'](https://github.com/wellle/targets.vim)**\n\n\n## Text Object User\nThis isn't in itself a text object, but it provides an easy framework for other users to create their own. This means that it is a pre-requisite for all of the following objects. \n\nI will list my favourite ones, but I recommend you check out [this list](https://github.com/kana/vim-textobj-user/wiki) of all the existing objects that have been created for this framework, as I suspect there are some that might appeal to you and not me!\n\n**Plug '[kana/vim-textobj-user](https://github.com/kana/vim-textobj-user)'**\n\n## Indent\nEver wanted to select a block of code by it's indentation level? Well this allows you to do just that, with `ii` and `ai`. \n\n```\nfoo                      foo\n  b|ar   ->  `dii`  ->   foo\n  bar\nfoo\n```\n**Plug '[kana/vim-textobj-indent](https://github.com/kana/vim-textobj-indent)'**\n\n## Comments\nThis is really handy, especially for multi-line comments. Simply provides `ic` and `ac` to edit comments.\n\n`// Co|mment` -> `cic` -> `// |...`\n\n**Plug '[glts/vim-textobj-comment](https://github.com/glts/vim-textobj-comment)'**\n\n\n## Functions\nThis works for Java and C, however there is most likely a language specific version that will provide the same functionality. I use [this one](https://github.com/thinca/vim-textobj-function-javascript) for JavaScript.\n\nYou can now use `if` and `af` to select the contents of a function or the whole function itself. \n\n```\n void foo() {                    void foo() {\n   return bar;   -> `dif` ->     }\n }\n```\n\n**Plug '[kana/vim-textobj-function](https://github.com/kana/vim-textobj-function)'**\n\n## Conclusions\nThere are *a lot* more of these extensions out there, for your specific language or for that common repeating text pattern that you want to operate on, but can never find a nice way of selecting it. \n\nI usually advise against adding lots of plugins at once, but hopefully with the use of the vim language these should seem like second nature as soon as you are aware of the new objects you can operate on. \n\n:wq","mobiledoc":null,"html":"<p>One of the magical things about Vim is that it uses nouns and verbs to construct an editing language. For example <code>d</code> (delete) is a verb and <code>w</code> (word) is a noun. By combining a noun &amp; verb we make an edit. Learning this language is key to getting the most out of your editing, I recommend this <a href=\"https://www.youtube.com/watch?v=wlR5gYd6um0\">great talk</a> by <a href=\"https://twitter.com/christoomey\">Chris Toomey</a> if this concept is new to you. </p>\n\n<p>Once you have the basics down you know how to operate on the standard text objects that vim provides you might want to start adding your own. Thankfully there are some excellent plugins to add a whole host of extra objects. What is nice about these extensions to the language is they feel natural and intuitive and don't take much investment to learn at all. </p>\n\n<h2 id=\"examples\">Examples</h2>\n\n<p>Below I have listed a few of my favourite extensions with a link to the plugin on Github as well as the Plug line for them. I've also added a very simple \"selling point\" on what the plugins do, but if one piques your interest do check out the full docs on the github page because a lot of these are a lot more powerful than the simple examples I am listing. Also pipe (<code>|</code>) denotes cursor position.</p>\n\n<h2 id=\"surround\">Surround</h2>\n\n<p>This is probably the most essential plugin for Vim, it feels totally natural and whenever I encounter vanilla Vim I inevitably try to use it forgetting that it isn't there by default!</p>\n\n<p>This allows us to select <code>(</code>surrounding<code>)</code> brackets, braces, quotes, etc. So <code>cs\"'</code> would change surrounding <code>\"</code>'s to <code>'</code>'s. </p>\n\n<p><code>\"f|oo\"</code> -> <code>cs\"'</code> -> <code>'bar'</code></p>\n\n<p><strong>Plug <a href=\"https://github.com/tpope/vim-surround\">'tpope/surround'</a></strong></p>\n\n<h2 id=\"targets\">Targets</h2>\n\n<p>Vim allows us to do things like <code>ci\"</code> to change text inside quotes, but what about other markers? Targets lets us do this to pretty much everything else that would encapsulate text, such as <code>,</code>'s or <code>+</code>'s. </p>\n\n<p>For examples to delete a string from a concatenation <code>da+</code>, will remove the string and <code>+</code> from under the cursor. </p>\n\n<p><code>foo + 'str|ing' + bar</code> -> <code>da+</code> -> <code>foo + bar</code></p>\n\n<p><strong>Plug <a href=\"https://github.com/wellle/targets.vim\">'wellle/targets.vim'</a></strong></p>\n\n<h2 id=\"textobjectuser\">Text Object User</h2>\n\n<p>This isn't in itself a text object, but it provides an easy framework for other users to create their own. This means that it is a pre-requisite for all of the following objects. </p>\n\n<p>I will list my favourite ones, but I recommend you check out <a href=\"https://github.com/kana/vim-textobj-user/wiki\">this list</a> of all the existing objects that have been created for this framework, as I suspect there are some that might appeal to you and not me!</p>\n\n<p><strong>Plug '<a href=\"https://github.com/kana/vim-textobj-user\">kana/vim-textobj-user</a>'</strong></p>\n\n<h2 id=\"indent\">Indent</h2>\n\n<p>Ever wanted to select a block of code by it's indentation level? Well this allows you to do just that, with <code>ii</code> and <code>ai</code>. </p>\n\n<pre><code>foo                      foo  \n  b|ar   -&gt;  `dii`  -&gt;   foo\n  bar\nfoo  \n</code></pre>\n\n<p><strong>Plug '<a href=\"https://github.com/kana/vim-textobj-indent\">kana/vim-textobj-indent</a>'</strong></p>\n\n<h2 id=\"comments\">Comments</h2>\n\n<p>This is really handy, especially for multi-line comments. Simply provides <code>ic</code> and <code>ac</code> to edit comments.</p>\n\n<p><code>// Co|mment</code> -> <code>cic</code> -> <code>// |...</code></p>\n\n<p><strong>Plug '<a href=\"https://github.com/glts/vim-textobj-comment\">glts/vim-textobj-comment</a>'</strong></p>\n\n<h2 id=\"functions\">Functions</h2>\n\n<p>This works for Java and C, however there is most likely a language specific version that will provide the same functionality. I use <a href=\"https://github.com/thinca/vim-textobj-function-javascript\">this one</a> for JavaScript.</p>\n\n<p>You can now use <code>if</code> and <code>af</code> to select the contents of a function or the whole function itself. </p>\n\n<pre><code> void foo() {                    void foo() {\n   return bar;   -&gt; `dif` -&gt;     }\n }\n</code></pre>\n\n<p><strong>Plug '<a href=\"https://github.com/kana/vim-textobj-function\">kana/vim-textobj-function</a>'</strong></p>\n\n<h2 id=\"conclusions\">Conclusions</h2>\n\n<p>There are <em>a lot</em> more of these extensions out there, for your specific language or for that common repeating text pattern that you want to operate on, but can never find a nice way of selecting it. </p>\n\n<p>I usually advise against adding lots of plugins at once, but hopefully with the use of the vim language these should seem like second nature as soon as you are aware of the new objects you can operate on. </p>\n\n<p>:wq</p>","amp":null,"image":null,"featured":0,"page":0,"status":"published","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-04-06 21:08:20","created_by":1,"updated_at":"2017-04-06 22:12:42","updated_by":1,"published_at":"2017-04-06 22:12:42","published_by":1}],"users":[{"id":1,"uuid":"d66366f3-750e-4f80-bbf6-8033f6fdfd8d","name":"Owen Garland","slug":"owen","password":"$2a$10$zm4SJnCQn20D24FR7Mh8meCeRGii/quL1wgu.2gwamwUuvn6XCj.e","email":"garland.owen@gmail.com","image":"/content/images/2017/02/shot.png","cover":null,"bio":"I'm a final year Software Engineering student at Aberystwyth University I like dancing, python, Linux, traditional jazz and node. In no particular order.","website":"http://owen.cymru","location":"Aberystwyth","facebook":null,"twitter":null,"accessibility":null,"status":"active","language":"en_US","visibility":"public","meta_title":null,"meta_description":null,"tour":null,"last_login":"2017-04-06 22:06:48","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-04-06 22:06:48","updated_by":1}],"roles":[{"id":1,"uuid":"3d1d634b-afdb-4c19-9899-c5f4b680562c","name":"Administrator","description":"Administrators","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":2,"uuid":"9b39f4a0-7687-4524-a2cc-bc223a65c00c","name":"Editor","description":"Editors","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":3,"uuid":"24551fb8-275d-4e75-b5c1-e4ee873485da","name":"Author","description":"Authors","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":4,"uuid":"af46f34b-8765-4a27-8d9b-f47452a8112d","name":"Owner","description":"Blog Owner","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1}],"roles_users":[{"id":1,"role_id":4,"user_id":1}],"permissions":[{"id":1,"uuid":"37af1a44-1dbc-4936-a48d-d19b5e21c7e3","name":"Export database","object_type":"db","action_type":"exportContent","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":2,"uuid":"7bb743a6-9778-46a0-af17-5a6f31452c36","name":"Import database","object_type":"db","action_type":"importContent","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":3,"uuid":"c37332fc-98d3-48c3-8469-0d8e0ffe77cc","name":"Delete all content","object_type":"db","action_type":"deleteAllContent","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":4,"uuid":"fba7e9eb-5650-429d-9199-e9068e710a20","name":"Send mail","object_type":"mail","action_type":"send","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":5,"uuid":"fc15459f-8309-4187-9375-6834b74b17f5","name":"Browse notifications","object_type":"notification","action_type":"browse","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":6,"uuid":"a8d2a051-4d51-42df-8c18-7c0805754517","name":"Add notifications","object_type":"notification","action_type":"add","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":7,"uuid":"61373465-37f2-4a65-9765-64e515db7811","name":"Delete notifications","object_type":"notification","action_type":"destroy","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":8,"uuid":"942e4ec1-c142-416c-bf1e-99689beeffdc","name":"Browse posts","object_type":"post","action_type":"browse","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":9,"uuid":"8aa5e9c1-59e5-450a-bbac-f52c0893a34d","name":"Read posts","object_type":"post","action_type":"read","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":10,"uuid":"b6a8e7bf-a02c-4ccd-8b6a-79b04fd949fd","name":"Edit posts","object_type":"post","action_type":"edit","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":11,"uuid":"53da4ca0-a829-4b95-a1b7-de26fd04adfe","name":"Add posts","object_type":"post","action_type":"add","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":12,"uuid":"b461dc63-5a23-4509-8ddc-88e4418de31a","name":"Delete posts","object_type":"post","action_type":"destroy","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":13,"uuid":"c5a8d63b-b025-4d9a-bbaf-6b2933763227","name":"Browse settings","object_type":"setting","action_type":"browse","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":14,"uuid":"e8375418-0ea6-4c85-b2f4-465f6d058456","name":"Read settings","object_type":"setting","action_type":"read","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":15,"uuid":"873778cd-bdd7-4287-920d-c8ee94c1cdad","name":"Edit settings","object_type":"setting","action_type":"edit","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":16,"uuid":"5c50d746-3c13-4039-804c-c21ab05e8495","name":"Generate slugs","object_type":"slug","action_type":"generate","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":17,"uuid":"f8b1912c-8973-4002-9b14-6627e2605ab3","name":"Browse tags","object_type":"tag","action_type":"browse","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":18,"uuid":"74ffda28-4ce8-4033-bef6-66ffcb77fbd3","name":"Read tags","object_type":"tag","action_type":"read","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":19,"uuid":"eb4929e8-9d0f-4f57-8ef3-fc86aeb525bb","name":"Edit tags","object_type":"tag","action_type":"edit","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":20,"uuid":"4702d2c6-3d4e-4d6c-80d6-0c38c247df24","name":"Add tags","object_type":"tag","action_type":"add","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":21,"uuid":"d68f318c-b513-4b02-984f-91cb49882c3c","name":"Delete tags","object_type":"tag","action_type":"destroy","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":22,"uuid":"7e39d20e-5ec6-48b5-ac89-9d777f710980","name":"Browse themes","object_type":"theme","action_type":"browse","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":23,"uuid":"0da8ec8d-6754-446e-96a8-65d2b61f55c4","name":"Edit themes","object_type":"theme","action_type":"edit","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":24,"uuid":"e9034f88-b55e-4a92-9e2b-340757af9d6f","name":"Upload themes","object_type":"theme","action_type":"add","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":25,"uuid":"8ca66054-c4cc-4825-9c1d-be8195b9f1ee","name":"Download themes","object_type":"theme","action_type":"read","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":26,"uuid":"7081d0d3-f870-4f48-8857-11c16415a336","name":"Delete themes","object_type":"theme","action_type":"destroy","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":27,"uuid":"b371b339-f10d-4897-931d-05b4e1cf44d8","name":"Browse users","object_type":"user","action_type":"browse","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":28,"uuid":"5bee4f16-e0f9-4cb8-91ed-26dc999c4cdc","name":"Read users","object_type":"user","action_type":"read","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":29,"uuid":"aa43cbdb-b28a-4019-add6-998ee5b03e96","name":"Edit users","object_type":"user","action_type":"edit","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":30,"uuid":"0ba72720-2213-49e2-b8b0-a279dd48b42c","name":"Add users","object_type":"user","action_type":"add","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":31,"uuid":"e2d9d2d0-e5c1-400c-a58b-e52f55c98b43","name":"Delete users","object_type":"user","action_type":"destroy","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":32,"uuid":"cc3f91bc-c7c4-4ae7-a1dd-600169f1422f","name":"Assign a role","object_type":"role","action_type":"assign","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":33,"uuid":"657359c0-3665-4360-9e98-3a0f46a13830","name":"Browse roles","object_type":"role","action_type":"browse","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":34,"uuid":"da60be98-4a99-48ef-8348-2856067313d6","name":"Browse clients","object_type":"client","action_type":"browse","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":35,"uuid":"341a54d2-c133-444b-8e20-8293cd5f09f1","name":"Read clients","object_type":"client","action_type":"read","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":36,"uuid":"3d253414-45ee-46c8-b63c-c1c041bf39d0","name":"Edit clients","object_type":"client","action_type":"edit","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":37,"uuid":"37aeb617-90b9-4546-8bab-b2342721a8fc","name":"Add clients","object_type":"client","action_type":"add","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":38,"uuid":"89ded66e-0587-4a7d-88fe-9b72980969a1","name":"Delete clients","object_type":"client","action_type":"destroy","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":39,"uuid":"17766759-214c-4ed3-82f3-4f095b4e40b2","name":"Browse subscribers","object_type":"subscriber","action_type":"browse","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":40,"uuid":"66ecc29f-bafc-4514-81c9-618cc2e2a243","name":"Read subscribers","object_type":"subscriber","action_type":"read","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":41,"uuid":"aec88ad1-e981-4111-a79c-4e1ac808498b","name":"Edit subscribers","object_type":"subscriber","action_type":"edit","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":42,"uuid":"e2aa36e0-e2f5-4781-a22e-5859ede26905","name":"Add subscribers","object_type":"subscriber","action_type":"add","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":43,"uuid":"8e4427b5-9082-4b8c-bce2-86e0cef3f18e","name":"Delete subscribers","object_type":"subscriber","action_type":"destroy","object_id":null,"created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1}],"permissions_users":[],"permissions_roles":[{"id":1,"role_id":1,"permission_id":1},{"id":2,"role_id":1,"permission_id":2},{"id":3,"role_id":1,"permission_id":3},{"id":4,"role_id":1,"permission_id":4},{"id":5,"role_id":1,"permission_id":5},{"id":6,"role_id":1,"permission_id":6},{"id":7,"role_id":1,"permission_id":7},{"id":8,"role_id":1,"permission_id":8},{"id":9,"role_id":1,"permission_id":9},{"id":10,"role_id":1,"permission_id":10},{"id":11,"role_id":1,"permission_id":11},{"id":12,"role_id":1,"permission_id":12},{"id":13,"role_id":1,"permission_id":13},{"id":14,"role_id":1,"permission_id":14},{"id":15,"role_id":1,"permission_id":15},{"id":16,"role_id":1,"permission_id":16},{"id":17,"role_id":1,"permission_id":17},{"id":18,"role_id":1,"permission_id":18},{"id":19,"role_id":1,"permission_id":19},{"id":20,"role_id":1,"permission_id":20},{"id":21,"role_id":1,"permission_id":21},{"id":22,"role_id":1,"permission_id":22},{"id":23,"role_id":1,"permission_id":23},{"id":24,"role_id":1,"permission_id":24},{"id":25,"role_id":1,"permission_id":25},{"id":26,"role_id":1,"permission_id":26},{"id":27,"role_id":1,"permission_id":27},{"id":28,"role_id":1,"permission_id":28},{"id":29,"role_id":1,"permission_id":29},{"id":30,"role_id":1,"permission_id":30},{"id":31,"role_id":1,"permission_id":31},{"id":32,"role_id":1,"permission_id":32},{"id":33,"role_id":1,"permission_id":33},{"id":34,"role_id":1,"permission_id":34},{"id":35,"role_id":1,"permission_id":35},{"id":36,"role_id":1,"permission_id":36},{"id":37,"role_id":1,"permission_id":37},{"id":38,"role_id":1,"permission_id":38},{"id":39,"role_id":1,"permission_id":39},{"id":40,"role_id":1,"permission_id":40},{"id":41,"role_id":1,"permission_id":41},{"id":42,"role_id":1,"permission_id":42},{"id":43,"role_id":1,"permission_id":43},{"id":44,"role_id":2,"permission_id":8},{"id":45,"role_id":2,"permission_id":9},{"id":46,"role_id":2,"permission_id":10},{"id":47,"role_id":2,"permission_id":11},{"id":48,"role_id":2,"permission_id":12},{"id":49,"role_id":2,"permission_id":13},{"id":50,"role_id":2,"permission_id":14},{"id":51,"role_id":2,"permission_id":16},{"id":52,"role_id":2,"permission_id":17},{"id":53,"role_id":2,"permission_id":18},{"id":54,"role_id":2,"permission_id":19},{"id":55,"role_id":2,"permission_id":20},{"id":56,"role_id":2,"permission_id":21},{"id":57,"role_id":2,"permission_id":27},{"id":58,"role_id":2,"permission_id":28},{"id":59,"role_id":2,"permission_id":29},{"id":60,"role_id":2,"permission_id":30},{"id":61,"role_id":2,"permission_id":31},{"id":62,"role_id":2,"permission_id":32},{"id":63,"role_id":2,"permission_id":33},{"id":64,"role_id":2,"permission_id":34},{"id":65,"role_id":2,"permission_id":35},{"id":66,"role_id":2,"permission_id":36},{"id":67,"role_id":2,"permission_id":37},{"id":68,"role_id":2,"permission_id":38},{"id":69,"role_id":2,"permission_id":42},{"id":70,"role_id":3,"permission_id":8},{"id":71,"role_id":3,"permission_id":9},{"id":72,"role_id":3,"permission_id":11},{"id":73,"role_id":3,"permission_id":13},{"id":74,"role_id":3,"permission_id":14},{"id":75,"role_id":3,"permission_id":16},{"id":76,"role_id":3,"permission_id":17},{"id":77,"role_id":3,"permission_id":18},{"id":78,"role_id":3,"permission_id":20},{"id":79,"role_id":3,"permission_id":27},{"id":80,"role_id":3,"permission_id":28},{"id":81,"role_id":3,"permission_id":33},{"id":82,"role_id":3,"permission_id":34},{"id":83,"role_id":3,"permission_id":35},{"id":84,"role_id":3,"permission_id":36},{"id":85,"role_id":3,"permission_id":37},{"id":86,"role_id":3,"permission_id":38},{"id":87,"role_id":3,"permission_id":42}],"permissions_apps":[],"settings":[{"id":1,"uuid":"043b12ec-d381-441c-a595-7cb21df48ff1","key":"databaseVersion","value":"009","type":"core","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":2,"uuid":"b5a0c978-7a70-4025-a10f-2befa69b651e","key":"dbHash","value":"3c68e01c-43e8-4fde-85f4-8ae3c9a7d29f","type":"core","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:54","updated_by":1},{"id":3,"uuid":"d892f835-0c99-4343-ae5c-8430d10f299e","key":"nextUpdateCheck","value":"1491599224","type":"core","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-04-06 21:06:51","updated_by":1},{"id":4,"uuid":"b5dc407f-31b3-441d-9529-0559c616ced9","key":"displayUpdateNotification","value":"0.11.7","type":"core","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-04-06 21:06:51","updated_by":1},{"id":5,"uuid":"8ed0a0ea-75bc-4e31-9218-b63967015b64","key":"seenNotifications","value":"[]","type":"core","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":6,"uuid":"6a5c27de-1732-4ed4-a8e2-d0a1a3eb11ba","key":"migrations","value":"{}","type":"core","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":7,"uuid":"86ce5ca2-2310-44ea-b630-c962ca2380f9","key":"title","value":"Jazz, Linux & Vim","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":8,"uuid":"14f495da-9f29-4c19-8a89-22b6f8072043","key":"description","value":"Owen's personal blog, mostly about technical things.","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":9,"uuid":"7c58fb04-d760-431c-abc4-05f3feccc725","key":"logo","value":"","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":10,"uuid":"267c2b1e-c908-4088-a182-1915975bfb57","key":"cover","value":"/content/images/2017/02/shot-1.png","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":11,"uuid":"6eb18acf-20bc-4b19-860b-5f19849b4e04","key":"defaultLang","value":"en_US","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":12,"uuid":"0a552abe-c5d5-4441-9c0c-081bb7ad6306","key":"postsPerPage","value":"10","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":13,"uuid":"28047cb9-6bcc-47dd-9663-a9a29b744d2b","key":"activeTimezone","value":"Etc/UTC","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":14,"uuid":"5544cd50-c6ee-49f1-b41f-70a84f6b1757","key":"forceI18n","value":"true","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":15,"uuid":"c1d6ed8c-99b2-4984-a953-2a838ad00444","key":"permalinks","value":"/:slug/","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":16,"uuid":"129064f3-b903-4bb3-874f-38158523cd2a","key":"amp","value":"true","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":17,"uuid":"844ec313-c9c0-402b-9618-f92bdff8411e","key":"ghost_head","value":"<link rel=\"icon\" type=\"image/png\" href=\"https://raw.githubusercontent.com/bag-man/nodeup/master/public/assets/imgs/favicon.ico\">\n<script>\n  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n\n  ga('create', 'UA-53020648-3', 'auto');\n  ga('send', 'pageview');\n</script>\n\n<link rel=\"stylesheet\" href=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/default.min.css\">\n<script src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js\"></script>\n\n<style> \n  img {\n    display: block;\n    margin: 0 auto;\n  }\n  .horizontal-img {\n    display: float;\n  }\n</style>","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":18,"uuid":"f13de127-62f4-48ea-9868-58ab707fc570","key":"ghost_foot","value":"<script>    \n  $.fn.randomize=function(a){(a?this.find(a):this).parent().each(function(){$(this).children(a).sort(function(){return Math.random()-0.5}).detach().appendTo(this)});return this};\n  $('.posts-list').randomize('article');\n</script>\n\n<script>hljs.initHighlightingOnLoad();</script>","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":19,"uuid":"293dbe58-8f3f-4156-a7a1-8272b79a80af","key":"facebook","value":"","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":20,"uuid":"4f1ba3be-e158-4538-a8ea-a3670c9566eb","key":"twitter","value":"@owen_garland","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":21,"uuid":"43c08678-cd77-4dfa-9cf4-259bb2e6b94c","key":"labs","value":"{}","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":22,"uuid":"5e5b4883-1d60-4372-ac67-ae528211b457","key":"navigation","value":"[{\"label\":\"Home\",\"url\":\"http://owen.cymru\"},{\"label\":\"About Me\",\"url\":\"/about/\"},{\"label\":\"Github\",\"url\":\"http://github.com/bag-man\"},{\"label\":\"Vimrc\",\"url\":\"https://github.com/bag-man/dotfiles/blob/master/vimrc\"},{\"label\":\"CV\",\"url\":\"http://files.owen.cymru/cv.html\"},{\"label\":\"Email\",\"url\":\"mailto://garland.owen@gmail.com\"}]","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":23,"uuid":"dfbb2495-3634-470e-8a58-9f20087af0e0","key":"slack","value":"[{\"url\":\"\"}]","type":"blog","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":24,"uuid":"7d96ef56-d4a6-4784-acad-f37197d40db4","key":"activeApps","value":"[]","type":"app","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-12 14:49:53","updated_by":1},{"id":25,"uuid":"34590634-285d-4a45-a76c-488f82359a61","key":"installedApps","value":"[]","type":"app","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:14:06","updated_by":1},{"id":26,"uuid":"e820b3ae-388b-4ebd-b025-21148ba13246","key":"isPrivate","value":"false","type":"private","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":27,"uuid":"065d9600-e4d3-475a-8d09-1b439e46b1ad","key":"password","value":"","type":"private","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1},{"id":28,"uuid":"91349900-ef18-4515-ad0d-b2311252832c","key":"activeTheme","value":"beautiful-ghost","type":"theme","created_at":"2017-02-12 14:49:53","created_by":1,"updated_at":"2017-02-20 15:05:42","updated_by":1}],"tags":[{"id":2,"uuid":"c395edb0-d251-44d6-badf-a881f78e21be","name":"javascript","slug":"javascript","description":null,"image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-02-16 16:26:59","created_by":1,"updated_at":"2017-02-16 16:26:59","updated_by":1},{"id":3,"uuid":"99095197-3bda-434d-8d38-f8c297a2d66c","name":"js","slug":"js","description":null,"image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-02-16 16:26:59","created_by":1,"updated_at":"2017-02-16 16:26:59","updated_by":1},{"id":4,"uuid":"e21f84ed-a15e-4344-936d-cf8013e3cca7","name":"nodejs","slug":"nodejs","description":null,"image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2017-02-16 16:26:59","created_by":1,"updated_at":"2017-02-16 16:26:59","updated_by":1}],"posts_tags":[],"apps":[],"app_settings":[],"app_fields":[],"subscribers":[]}}]}